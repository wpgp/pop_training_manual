<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Introduction to Statistical Modelling with Implementation in R | WorldPop Population Modelling Training Manual, Vol. I</title>
  <meta name="description" content="An open book of WorldPop methods to produce gridded population estimates." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Introduction to Statistical Modelling with Implementation in R | WorldPop Population Modelling Training Manual, Vol. I" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An open book of WorldPop methods to produce gridded population estimates." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Introduction to Statistical Modelling with Implementation in R | WorldPop Population Modelling Training Manual, Vol. I" />
  
  <meta name="twitter:description" content="An open book of WorldPop methods to produce gridded population estimates." />
  

<meta name="author" content="WorldPop, University of Southampton" />


<meta name="date" content="2025-07-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="working-with-spatial-data-in-r.html"/>
<link rel="next" href="probability-theory-and-applications.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/proj4-2.6.2/proj4.min.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.2.2/leaflet.js"></script>
<script src="libs/leaflet-providers-2.0.0/leaflet-providers_2.0.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.2.2/leaflet-providers-plugin.js"></script>
<script src="libs/HomeButton-0.0.1/home-button.js"></script>
<script src="libs/HomeButton-0.0.1/easy-button-src.min.js"></script>
<link href="libs/health_facilities - type-CSS-0.0.1/health_facilities - type_home-button.css" rel="stylesheet" />
<script src="libs/clipboard-0.0.1/setClipboardText.js"></script>
<link href="libs/mapviewCSS-0.0.1/mapview-popup.css" rel="stylesheet" />
<link href="libs/mapviewCSS-0.0.1/mapview.css" rel="stylesheet" />
<link href="libs/states-CSS-0.0.1/states_home-button.css" rel="stylesheet" />
<link href="libs/states_utm-CSS-0.0.1/states_utm_home-button.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#preface"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#book-contents"><i class="fa fa-check"></i>Book Contents</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html"><i class="fa fa-check"></i><b>1</b> Basics of R Programming</a>
<ul>
<li class="chapter" data-level="1.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#overview-of-r"><i class="fa fa-check"></i><b>1.1</b> Overview of R</a>
<ul>
<li class="chapter" data-level="" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#getting-started-with-r"><i class="fa fa-check"></i>Getting started with R</a>
<ul>
<li class="chapter" data-level="" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#downloading-r-and-rstudio"><i class="fa fa-check"></i>Downloading R and RStudio</a></li>
<li class="chapter" data-level="" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#features-of-the-r-gui-environment"><i class="fa fa-check"></i>Features of the R GUI environment</a></li>
<li class="chapter" data-level="" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#features-of-the-rstudio-environment"><i class="fa fa-check"></i>Features of the RStudio environment</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#creating-opening-and-saving-r-scripts"><i class="fa fa-check"></i>Creating, opening and saving R scripts</a></li>
<li class="chapter" data-level="1.1.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#getting-and-setting-the-working-directory"><i class="fa fa-check"></i><b>1.1.1</b> Getting and setting the working directory</a></li>
<li class="chapter" data-level="1.1.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#creating-opening-and-saving-r-projects"><i class="fa fa-check"></i><b>1.1.2</b> Creating, opening and saving R projects</a></li>
<li class="chapter" data-level="1.1.3" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#getting-help-in-r"><i class="fa fa-check"></i><b>1.1.3</b> Getting help in R</a></li>
<li class="chapter" data-level="1.1.4" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#r-coding-best-practices"><i class="fa fa-check"></i><b>1.1.4</b> R coding best practices</a>
<ul>
<li class="chapter" data-level="1.1.4.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#commenting"><i class="fa fa-check"></i><b>1.1.4.1</b> Commenting</a></li>
<li class="chapter" data-level="1.1.4.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#naming-conventions"><i class="fa fa-check"></i><b>1.1.4.2</b> Naming conventions</a></li>
<li class="chapter" data-level="1.1.4.3" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#spacing"><i class="fa fa-check"></i><b>1.1.4.3</b> Spacing</a></li>
<li class="chapter" data-level="1.1.4.4" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#punctuation"><i class="fa fa-check"></i><b>1.1.4.4</b> Punctuation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#data-types-and-key-components"><i class="fa fa-check"></i><b>1.2</b> Data types and key components</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#basic-operations-in-r"><i class="fa fa-check"></i><b>1.2.1</b> Basic operations in R</a>
<ul>
<li class="chapter" data-level="1.2.1.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#arithmetic-operators"><i class="fa fa-check"></i><b>1.2.1.1</b> Arithmetic operators</a></li>
<li class="chapter" data-level="1.2.1.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#logical-operators"><i class="fa fa-check"></i><b>1.2.1.2</b> Logical operators</a></li>
<li class="chapter" data-level="1.2.1.3" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#other-operators"><i class="fa fa-check"></i><b>1.2.1.3</b> Other operators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#key-functions-in-r"><i class="fa fa-check"></i><b>1.3</b> Key functions in R</a></li>
<li class="chapter" data-level="1.4" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#data-structures"><i class="fa fa-check"></i><b>1.4</b> Data structures</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#vectors"><i class="fa fa-check"></i><b>1.4.1</b> Vectors</a></li>
<li class="chapter" data-level="1.4.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#matrices"><i class="fa fa-check"></i><b>1.4.2</b> Matrices</a></li>
<li class="chapter" data-level="1.4.3" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#arrays"><i class="fa fa-check"></i><b>1.4.3</b> Arrays</a></li>
<li class="chapter" data-level="1.4.4" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#data-frames"><i class="fa fa-check"></i><b>1.4.4</b> Data frames</a></li>
<li class="chapter" data-level="1.4.5" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#list"><i class="fa fa-check"></i><b>1.4.5</b> List</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#end-of-module-exercises"><i class="fa fa-check"></i><b>1.5</b> End of module exercises</a></li>
<li class="chapter" data-level="1.6" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#useful-resources"><i class="fa fa-check"></i><b>1.6</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html"><i class="fa fa-check"></i><b>2</b> Working with Data Frames</a>
<ul>
<li class="chapter" data-level="2.1" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#importing-and-exporting-data-in-and-from-r"><i class="fa fa-check"></i><b>2.1</b> Importing and exporting data in and from R</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#installing-and-loading-packages"><i class="fa fa-check"></i><b>2.1.1</b> Installing and loading packages</a></li>
<li class="chapter" data-level="2.1.2" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#reading-data-into-the-r-environment"><i class="fa fa-check"></i><b>2.1.2</b> Reading data into the R environment</a></li>
<li class="chapter" data-level="2.1.3" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#creating-work-paths"><i class="fa fa-check"></i><b>2.1.3</b> Creating work paths</a></li>
<li class="chapter" data-level="2.1.4" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#exploring-data-attributes"><i class="fa fa-check"></i><b>2.1.4</b> Exploring data attributes</a></li>
<li class="chapter" data-level="2.1.5" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#viewing-data"><i class="fa fa-check"></i><b>2.1.5</b> Viewing data</a></li>
<li class="chapter" data-level="2.1.6" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#extracting-data"><i class="fa fa-check"></i><b>2.1.6</b> Extracting data</a></li>
<li class="chapter" data-level="2.1.7" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#attaching-data"><i class="fa fa-check"></i><b>2.1.7</b> Attaching data</a></li>
<li class="chapter" data-level="2.1.8" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#writing-data-to-external-repositories"><i class="fa fa-check"></i><b>2.1.8</b> Writing data to external repositories</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#basic-data-wrangling-methods-for-data-preparation-and-handling-in-r"><i class="fa fa-check"></i><b>2.2</b> Basic data wrangling methods for data preparation and handling in R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#dealing-with-na-not-available-values"><i class="fa fa-check"></i><b>2.2.1</b> Dealing with NA (‘Not Available’) values</a></li>
<li class="chapter" data-level="2.2.2" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#key-data-wrangling-methods"><i class="fa fa-check"></i><b>2.2.2</b> Key data wrangling methods</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#data-visualisation"><i class="fa fa-check"></i><b>2.3</b> Data visualisation</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#bar-plots"><i class="fa fa-check"></i><b>2.3.1</b> Bar plots</a></li>
<li class="chapter" data-level="2.3.2" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#box-plots"><i class="fa fa-check"></i><b>2.3.2</b> Box plots</a></li>
<li class="chapter" data-level="2.3.3" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#histograms"><i class="fa fa-check"></i><b>2.3.3</b> Histograms</a></li>
<li class="chapter" data-level="2.3.4" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#density-plots"><i class="fa fa-check"></i><b>2.3.4</b> Density plots</a></li>
<li class="chapter" data-level="2.3.5" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#scatter-plots"><i class="fa fa-check"></i><b>2.3.5</b> Scatter plots</a></li>
<li class="chapter" data-level="2.3.6" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#violin-plots"><i class="fa fa-check"></i><b>2.3.6</b> Violin plots</a></li>
<li class="chapter" data-level="2.3.7" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#line-graphs"><i class="fa fa-check"></i><b>2.3.7</b> Line graphs</a></li>
<li class="chapter" data-level="2.3.8" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#population-pyramids"><i class="fa fa-check"></i><b>2.3.8</b> Population pyramids</a></li>
<li class="chapter" data-level="2.3.9" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#lollipop-plots"><i class="fa fa-check"></i><b>2.3.9</b> Lollipop plots</a></li>
<li class="chapter" data-level="2.3.10" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#plots-with-an-image-background"><i class="fa fa-check"></i><b>2.3.10</b> Plots with an image background</a></li>
<li class="chapter" data-level="2.3.11" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#viewing-and-saving-plots"><i class="fa fa-check"></i><b>2.3.11</b> Viewing and saving plots</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#end-of-module-exercises-1"><i class="fa fa-check"></i><b>2.4</b> End of module exercises</a></li>
<li class="chapter" data-level="2.5" data-path="working-with-data-frames.html"><a href="working-with-data-frames.html#useful-resources-1"><i class="fa fa-check"></i><b>2.5</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html"><i class="fa fa-check"></i><b>3</b> Working with Spatial Data in R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#spatial-data-overview-and-types"><i class="fa fa-check"></i><b>3.1</b> Spatial data: Overview and types</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#points-data"><i class="fa fa-check"></i><b>3.1.1</b> Points data</a></li>
<li class="chapter" data-level="3.1.2" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#areal-data"><i class="fa fa-check"></i><b>3.1.2</b> Areal data</a></li>
<li class="chapter" data-level="3.1.3" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#vector-data"><i class="fa fa-check"></i><b>3.1.3</b> Vector data</a>
<ul>
<li class="chapter" data-level="3.1.3.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#points"><i class="fa fa-check"></i><b>3.1.3.1</b> Points</a></li>
<li class="chapter" data-level="3.1.3.2" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#polylines"><i class="fa fa-check"></i><b>3.1.3.2</b> Polylines</a></li>
<li class="chapter" data-level="3.1.3.3" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#polygons"><i class="fa fa-check"></i><b>3.1.3.3</b> Polygons</a></li>
</ul></li>
<li class="chapter" data-level="3.1.4" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#raster-data"><i class="fa fa-check"></i><b>3.1.4</b> Raster data</a></li>
<li class="chapter" data-level="3.1.5" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#sources-of-spatial-data"><i class="fa fa-check"></i><b>3.1.5</b> Sources of spatial data</a></li>
<li class="chapter" data-level="3.1.6" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#geospatial-covariates"><i class="fa fa-check"></i><b>3.1.6</b> Geospatial covariates</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#basic-gis-concepts"><i class="fa fa-check"></i><b>3.2</b> Basic GIS concepts</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#geoprocessing"><i class="fa fa-check"></i><b>3.2.1</b> Geoprocessing</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#using-gis-in-r"><i class="fa fa-check"></i><b>3.3</b> Using GIS in R</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#importing-spatial-data-in-r"><i class="fa fa-check"></i><b>3.3.1</b> Importing spatial data in R</a></li>
<li class="chapter" data-level="3.3.2" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#handling-spatial-data-in-r"><i class="fa fa-check"></i><b>3.3.2</b> Handling spatial data in R</a>
<ul>
<li class="chapter" data-level="3.3.2.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#converting-between-vectors-and-rasters-in-r"><i class="fa fa-check"></i><b>3.3.2.1</b> Converting between vectors and rasters in R</a></li>
<li class="chapter" data-level="3.3.2.2" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#checking-the-resolution-and-number-of-cells"><i class="fa fa-check"></i><b>3.3.2.2</b> Checking the resolution and number of cells</a></li>
<li class="chapter" data-level="3.3.2.3" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#exporting-spatial-data-in-various-formats"><i class="fa fa-check"></i><b>3.3.2.3</b> Exporting spatial data in various formats</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#visualisation-of-spatial-data"><i class="fa fa-check"></i><b>3.4</b> Visualisation of spatial data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#static-maps"><i class="fa fa-check"></i><b>3.4.1</b> Static maps</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#interactive-maps"><i class="fa fa-check"></i><b>3.5</b> Interactive maps</a>
<ul>
<li class="chapter" data-level="" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#visualisation-with-tmap-1"><i class="fa fa-check"></i>Visualisation with <code>tmap</code></a></li>
<li class="chapter" data-level="" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#visualisation-with-leaflet"><i class="fa fa-check"></i>Visualisation with <code>leaflet</code></a></li>
<li class="chapter" data-level="" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#visualisation-with-mapview"><i class="fa fa-check"></i>Visualisation with <code>mapview</code></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#basic-geoprocessing"><i class="fa fa-check"></i><b>3.6</b> Basic geoprocessing</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#coordinate-reference-systems-crs"><i class="fa fa-check"></i><b>3.6.1</b> Coordinate reference systems (CRS)</a></li>
<li class="chapter" data-level="3.6.2" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#converting-between-latlong-and-the-universal-transverse-mercator-utm-coordinate-system"><i class="fa fa-check"></i><b>3.6.2</b> Converting between Lat/Long and the Universal Transverse Mercator (UTM) coordinate system</a></li>
<li class="chapter" data-level="3.6.3" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#subsetting-clipping-and-masking"><i class="fa fa-check"></i><b>3.6.3</b> Subsetting, clipping and masking</a></li>
<li class="chapter" data-level="3.6.4" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#buffer-analysis"><i class="fa fa-check"></i><b>3.6.4</b> Buffer analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#end-of-module-exercises-2"><i class="fa fa-check"></i><b>3.7</b> End of module exercises</a></li>
<li class="chapter" data-level="3.8" data-path="working-with-spatial-data-in-r.html"><a href="working-with-spatial-data-in-r.html#useful-resources-2"><i class="fa fa-check"></i><b>3.8</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html"><i class="fa fa-check"></i><b>4</b> Introduction to Statistical Modelling with Implementation in R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#concept-of-statistical-modelling"><i class="fa fa-check"></i><b>4.1</b> Concept of statistical modelling</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#overview-of-statistical-modelling"><i class="fa fa-check"></i><b>4.1.1</b> Overview of statistical modelling</a></li>
<li class="chapter" data-level="4.1.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#correlation"><i class="fa fa-check"></i><b>4.1.2</b> Correlation</a></li>
<li class="chapter" data-level="4.1.3" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#scaled-covariates"><i class="fa fa-check"></i><b>4.1.3</b> Scaled covariates</a></li>
<li class="chapter" data-level="4.1.4" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#uncertainty"><i class="fa fa-check"></i><b>4.1.4</b> Uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#simple-regression"><i class="fa fa-check"></i><b>4.2</b> Simple regression</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#linear-regression"><i class="fa fa-check"></i><b>4.2.1</b> Linear regression</a></li>
<li class="chapter" data-level="4.2.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#polynomial-regression"><i class="fa fa-check"></i><b>4.2.2</b> Polynomial regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#non-linear-regression"><i class="fa fa-check"></i><b>4.2.3</b> Non-linear regression</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#multiple-regression"><i class="fa fa-check"></i><b>4.3</b> Multiple regression</a></li>
<li class="chapter" data-level="4.4" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#generalised-linear-regression"><i class="fa fa-check"></i><b>4.4</b> Generalised linear regression</a></li>
<li class="chapter" data-level="4.5" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#model-predictions"><i class="fa fa-check"></i><b>4.5</b> Model predictions</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#predictions-with-the-formula-and-coefficients"><i class="fa fa-check"></i><b>4.5.1</b> Predictions with the formula and coefficients</a></li>
<li class="chapter" data-level="4.5.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#predictions-with-functions"><i class="fa fa-check"></i><b>4.5.2</b> Predictions with functions</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#model-selection"><i class="fa fa-check"></i><b>4.6</b> Model selection</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#accuracy-and-precision"><i class="fa fa-check"></i><b>4.6.1</b> Accuracy and precision</a></li>
<li class="chapter" data-level="4.6.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#akaike-information-criterion"><i class="fa fa-check"></i><b>4.6.2</b> Akaike information criterion</a></li>
<li class="chapter" data-level="4.6.3" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#bayesian-information-criterion"><i class="fa fa-check"></i><b>4.6.3</b> Bayesian information criterion</a></li>
<li class="chapter" data-level="4.6.4" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#r-squared-statistic"><i class="fa fa-check"></i><b>4.6.4</b> R-squared statistic</a></li>
<li class="chapter" data-level="4.6.5" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#analysis-of-variance"><i class="fa fa-check"></i><b>4.6.5</b> Analysis of variance</a></li>
<li class="chapter" data-level="4.6.6" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#likelihood-ratio-testing"><i class="fa fa-check"></i><b>4.6.6</b> Likelihood ratio testing</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#stepwise-regression"><i class="fa fa-check"></i><b>4.7</b> Stepwise regression</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#forward-stepwise-regression"><i class="fa fa-check"></i><b>4.7.1</b> Forward stepwise regression</a></li>
<li class="chapter" data-level="4.7.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#backward-stepwise-regression"><i class="fa fa-check"></i><b>4.7.2</b> Backward stepwise regression</a></li>
<li class="chapter" data-level="4.7.3" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#both-ways-stepwise-regression"><i class="fa fa-check"></i><b>4.7.3</b> Both ways stepwise regression</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cross-validation"><i class="fa fa-check"></i><b>4.8</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>4.8.1</b> <em>k</em>-fold cross-validation</a></li>
<li class="chapter" data-level="4.8.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>4.8.2</b> Leave-one-out cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#hierarchical-regression"><i class="fa fa-check"></i><b>4.9</b> Hierarchical regression</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#data-structure"><i class="fa fa-check"></i><b>4.9.1</b> Data structure</a></li>
<li class="chapter" data-level="4.9.2" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#variance-partition-coefficient"><i class="fa fa-check"></i><b>4.9.2</b> Variance partition coefficient</a></li>
<li class="chapter" data-level="4.9.3" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#random-intercepts-modelling"><i class="fa fa-check"></i><b>4.9.3</b> Random intercepts modelling</a></li>
<li class="chapter" data-level="4.9.4" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#random-intercepts-mixed-effects-modelling"><i class="fa fa-check"></i><b>4.9.4</b> Random intercepts mixed-effects modelling</a></li>
<li class="chapter" data-level="4.9.5" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#random-slope-mixed-effects-modelling"><i class="fa fa-check"></i><b>4.9.5</b> Random slope mixed-effects modelling</a></li>
<li class="chapter" data-level="4.9.6" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#adding-an-extra-level"><i class="fa fa-check"></i><b>4.9.6</b> Adding an extra level</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="introduction-to-statistical-modelling-with-implementation-in-r.html"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#useful-resources-3"><i class="fa fa-check"></i><b>4.10</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html"><i class="fa fa-check"></i><b>5</b> Probability Theory and Applications</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#introduction-to-probability"><i class="fa fa-check"></i><b>5.1</b> Introduction to probability</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#theoretical-and-experimental-probability"><i class="fa fa-check"></i><b>5.1.1</b> Theoretical and experimental probability</a></li>
<li class="chapter" data-level="5.1.2" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#keywords"><i class="fa fa-check"></i><b>5.1.2</b> Keywords</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#axioms-of-probability"><i class="fa fa-check"></i><b>5.2</b> Axioms of probability</a></li>
<li class="chapter" data-level="5.3" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#joint-probability"><i class="fa fa-check"></i><b>5.3</b> Joint probability</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#joint-probability-table"><i class="fa fa-check"></i><b>5.3.1</b> Joint probability table</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#conditional-probability"><i class="fa fa-check"></i><b>5.4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#multiplication-rule-of-conditional-probability"><i class="fa fa-check"></i><b>5.4.1</b> Multiplication rule of conditional probability</a></li>
<li class="chapter" data-level="5.4.2" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#law-of-total-probability"><i class="fa fa-check"></i><b>5.4.2</b> Law of total probability</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#contingency-tables"><i class="fa fa-check"></i><b>5.5</b> Contingency tables</a></li>
<li class="chapter" data-level="5.6" data-path="probability-theory-and-applications.html"><a href="probability-theory-and-applications.html#useful-resources-4"><i class="fa fa-check"></i><b>5.6</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html"><i class="fa fa-check"></i><b>6</b> Bayesian Statistical Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#bayes-theorem"><i class="fa fa-check"></i><b>6.2</b> Bayes’ theorem</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#bayes-theorem-for-random-variables"><i class="fa fa-check"></i><b>6.2.1</b> Bayes’ theorem for random variables</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#the-likelihood-function"><i class="fa fa-check"></i><b>6.3</b> The likelihood function</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#different-types-and-structures"><i class="fa fa-check"></i><b>6.3.1</b> Different types and structures</a>
<ul>
<li class="chapter" data-level="6.3.1.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#count-data"><i class="fa fa-check"></i><b>6.3.1.1</b> Count data</a></li>
<li class="chapter" data-level="6.3.1.2" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#binary-data"><i class="fa fa-check"></i><b>6.3.1.2</b> Binary data</a></li>
<li class="chapter" data-level="6.3.1.3" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#proportional-data"><i class="fa fa-check"></i><b>6.3.1.3</b> Proportional data</a></li>
<li class="chapter" data-level="6.3.1.4" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#continuous-data"><i class="fa fa-check"></i><b>6.3.1.4</b> Continuous data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#prior-distribution"><i class="fa fa-check"></i><b>6.4</b> Prior distribution</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#conjugate-priors"><i class="fa fa-check"></i><b>6.4.1</b> Conjugate priors</a></li>
<li class="chapter" data-level="6.4.2" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#flat-improper-and-non-informative-priors"><i class="fa fa-check"></i><b>6.4.2</b> Flat, improper and non-informative priors</a></li>
<li class="chapter" data-level="6.4.3" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#informative-prior"><i class="fa fa-check"></i><b>6.4.3</b> Informative prior</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#overview-of-posterior-inference"><i class="fa fa-check"></i><b>6.5</b> Overview of posterior inference</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#markov-chain-monte-carlo-approach"><i class="fa fa-check"></i><b>6.5.1</b> Markov Chain Monte Carlo approach</a></li>
<li class="chapter" data-level="6.5.2" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#integrated-nested-laplace-approximation-approach"><i class="fa fa-check"></i><b>6.5.2</b> Integrated Nested Laplace Approximation approach</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#elicitation-of-priors"><i class="fa fa-check"></i><b>6.6</b> Elicitation of priors</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#priors-inla"><i class="fa fa-check"></i><b>6.6.1</b> Priors INLA</a>
<ul>
<li class="chapter" data-level="6.6.1.1" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#penalised-complexity-priors"><i class="fa fa-check"></i><b>6.6.1.1</b> Penalised Complexity priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#sampling-and-evaluating-the-posterior-density"><i class="fa fa-check"></i><b>6.7</b> Sampling and evaluating the posterior density</a></li>
<li class="chapter" data-level="6.8" data-path="bayesian-statistical-inference.html"><a href="bayesian-statistical-inference.html#useful-resources-5"><i class="fa fa-check"></i><b>6.8</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><i class="fa fa-check"></i><b>7</b> Introduction to Small Area Population Estimation and Modelling (SAPEM)</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html#small-area-population-estimation"><i class="fa fa-check"></i><b>7.1</b> Small area population estimation</a></li>
<li class="chapter" data-level="7.2" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html#direct-estimation"><i class="fa fa-check"></i><b>7.2</b> Direct estimation</a></li>
<li class="chapter" data-level="7.3" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html#indirect-estimation"><i class="fa fa-check"></i><b>7.3</b> Indirect estimation</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html#approaches-for-creating-gridded-population-datasets"><i class="fa fa-check"></i><b>7.3.1</b> Approaches for creating gridded population datasets</a>
<ul>
<li class="chapter" data-level="7.3.1.1" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html#top-down"><i class="fa fa-check"></i><b>7.3.1.1</b> Top-down</a></li>
<li class="chapter" data-level="7.3.1.2" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html#bottom-up"><i class="fa fa-check"></i><b>7.3.1.2</b> Bottom-up</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="introduction-to-small-area-population-estimation-and-modelling-sapem.html"><a href="introduction-to-small-area-population-estimation-and-modelling-sapem.html#useful-resources-6"><i class="fa fa-check"></i><b>7.4</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html"><i class="fa fa-check"></i><b>8</b> Bayesian Hierarchical Population Modelling in R</a>
<ul>
<li class="chapter" data-level="8.1" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#data-sources"><i class="fa fa-check"></i><b>8.1</b> Data sources</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#population-data"><i class="fa fa-check"></i><b>8.1.1</b> Population data</a></li>
<li class="chapter" data-level="8.1.2" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#settlement-data"><i class="fa fa-check"></i><b>8.1.2</b> Settlement data</a></li>
<li class="chapter" data-level="8.1.3" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#other-sources"><i class="fa fa-check"></i><b>8.1.3</b> Other sources</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#data-cleaning-and-covariates-extraction"><i class="fa fa-check"></i><b>8.2</b> Data cleaning and covariates extraction</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#extracting-continuous-rasters"><i class="fa fa-check"></i><b>8.2.1</b> Extracting continuous rasters</a></li>
<li class="chapter" data-level="8.2.2" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#extracting-categorical-rasters"><i class="fa fa-check"></i><b>8.2.2</b> Extracting categorical rasters</a></li>
<li class="chapter" data-level="8.2.3" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#extracting-building-count"><i class="fa fa-check"></i><b>8.2.3</b> Extracting building count</a></li>
<li class="chapter" data-level="8.2.4" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#exracting-building-total-area"><i class="fa fa-check"></i><b>8.2.4</b> Exracting building total area</a></li>
<li class="chapter" data-level="8.2.5" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#adding-admin-area-names-to-the-data"><i class="fa fa-check"></i><b>8.2.5</b> Adding admin area names to the data</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#exploratory-analysis"><i class="fa fa-check"></i><b>8.3</b> Exploratory analysis</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#basic-visualisation"><i class="fa fa-check"></i><b>8.3.1</b> Basic visualisation</a></li>
<li class="chapter" data-level="8.3.2" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#geospatial-visualisation"><i class="fa fa-check"></i><b>8.3.2</b> Geospatial visualisation</a></li>
<li class="chapter" data-level="8.3.3" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#checking-for-nas"><i class="fa fa-check"></i><b>8.3.3</b> Checking for NAs</a></li>
<li class="chapter" data-level="8.3.4" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#checking-for-minimum-and-maximum-values"><i class="fa fa-check"></i><b>8.3.4</b> Checking for minimum and maximum values</a></li>
<li class="chapter" data-level="8.3.5" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#checking-the-distribution-of-categorical-variables"><i class="fa fa-check"></i><b>8.3.5</b> Checking the distribution of categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#model-set-up"><i class="fa fa-check"></i><b>8.4</b> Model set-up</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#simple-linear-regression"><i class="fa fa-check"></i><b>8.4.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="8.4.2" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#multiple-regression-1"><i class="fa fa-check"></i><b>8.4.2</b> Multiple regression</a></li>
<li class="chapter" data-level="8.4.3" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#generalised-linear-regression-1"><i class="fa fa-check"></i><b>8.4.3</b> Generalised linear regression</a></li>
<li class="chapter" data-level="8.4.4" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#fitting-fixed-effects-models-in-r-inla"><i class="fa fa-check"></i><b>8.4.4</b> Fitting fixed effects models in <code>R-INLA</code></a></li>
<li class="chapter" data-level="8.4.5" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#fitting-bayesian-hierarchical-mixed-effects-models-in-r-inla"><i class="fa fa-check"></i><b>8.4.5</b> Fitting Bayesian hierarchical mixed effects models in <code>R-INLA</code></a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#stan-mcmc-approach"><i class="fa fa-check"></i><b>8.5</b> STAN (MCMC) approach</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>8.5.1</b> Metropolis-Hastings algorithm</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#inla-and-inla-spde-approach"><i class="fa fa-check"></i><b>8.6</b> INLA and INLA-SPDE approach</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#mesh-construction"><i class="fa fa-check"></i><b>8.6.1</b> Mesh construction</a></li>
<li class="chapter" data-level="8.6.2" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#building-the-spde"><i class="fa fa-check"></i><b>8.6.2</b> Building the SPDE</a></li>
<li class="chapter" data-level="8.6.3" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#projection-matrix"><i class="fa fa-check"></i><b>8.6.3</b> Projection matrix</a></li>
<li class="chapter" data-level="8.6.4" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#data-location-indexing"><i class="fa fa-check"></i><b>8.6.4</b> Data location indexing</a></li>
<li class="chapter" data-level="8.6.5" data-path="bayesian-hierarchical-population-modelling-in-r.html"><a href="bayesian-hierarchical-population-modelling-in-r.html#projection-data"><i class="fa fa-check"></i><b>8.6.5</b> Projection data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html"><i class="fa fa-check"></i><b>9</b> Model Fit Checks and Cross-Validation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#model-assumption-checking"><i class="fa fa-check"></i><b>9.1</b> Model assumption checking</a></li>
<li class="chapter" data-level="9.2" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#model-selection-1"><i class="fa fa-check"></i><b>9.2</b> Model selection</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#watanabe-akaike-information-criterion-waic"><i class="fa fa-check"></i><b>9.2.1</b> Watanabe-Akaike Information Criterion (WAIC)</a></li>
<li class="chapter" data-level="9.2.2" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>9.2.2</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="9.2.3" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#conditional-predictive-ordinate-cpo"><i class="fa fa-check"></i><b>9.2.3</b> Conditional predictive ordinate (CPO)</a></li>
<li class="chapter" data-level="9.2.4" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#probability-integral-transform-pit"><i class="fa fa-check"></i><b>9.2.4</b> Probability Integral Transform (PIT)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#cross-validation-1"><i class="fa fa-check"></i><b>9.3</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#basic-cross-validation"><i class="fa fa-check"></i><b>9.3.1</b> Basic cross-validation</a></li>
<li class="chapter" data-level="9.3.2" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#k-fold-cross-validation-1"><i class="fa fa-check"></i><b>9.3.2</b> K-Fold Cross-Validation</a></li>
<li class="chapter" data-level="9.3.3" data-path="model-fit-checks-and-cross-validation.html"><a href="model-fit-checks-and-cross-validation.html#useful-resources-7"><i class="fa fa-check"></i><b>9.3.3</b> Useful resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html"><i class="fa fa-check"></i><b>10</b> Population Prediction and Uncertainty Quantification</a>
<ul>
<li class="chapter" data-level="10.1" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#covariate-stacking"><i class="fa fa-check"></i><b>10.1</b> Covariate stacking</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#admin-names"><i class="fa fa-check"></i><b>10.1.1</b> Admin names</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#grid-cellpixel-level-prediction"><i class="fa fa-check"></i><b>10.2</b> Grid cell/pixel level prediction</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#pre-processing"><i class="fa fa-check"></i><b>10.2.1</b> Pre-processing</a></li>
<li class="chapter" data-level="10.2.2" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#inla-spde-approach"><i class="fa fa-check"></i><b>10.2.2</b> INLA-SPDE approach</a>
<ul>
<li class="chapter" data-level="10.2.2.1" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#predictions"><i class="fa fa-check"></i><b>10.2.2.1</b> Predictions</a></li>
</ul></li>
<li class="chapter" data-level="10.2.3" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#posterior-distribution-simulation"><i class="fa fa-check"></i><b>10.2.3</b> Posterior distribution simulation</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#aggregation-to-area-units-of-interest-and-uncertainty-quantification"><i class="fa fa-check"></i><b>10.3</b> Aggregation to area units of interest and uncertainty quantification</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#rasterising-the-predictions-at-grid-cell-level"><i class="fa fa-check"></i><b>10.3.1</b> Rasterising the predictions at grid cell level</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="population-prediction-and-uncertainty-quantification.html"><a href="population-prediction-and-uncertainty-quantification.html#useful-resources-8"><i class="fa fa-check"></i><b>10.4</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="age-sex-disaggregation.html"><a href="age-sex-disaggregation.html"><i class="fa fa-check"></i><b>11</b> Age-Sex Disaggregation</a>
<ul>
<li class="chapter" data-level="11.1" data-path="age-sex-disaggregation.html"><a href="age-sex-disaggregation.html#disaggregation-of-population-totals-by-age-sex-proportions"><i class="fa fa-check"></i><b>11.1</b> Disaggregation of population totals by age-sex proportions</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="age-sex-disaggregation.html"><a href="age-sex-disaggregation.html#unavailable-age-sex-data"><i class="fa fa-check"></i><b>11.1.1</b> Unavailable age-sex data</a></li>
<li class="chapter" data-level="11.1.2" data-path="age-sex-disaggregation.html"><a href="age-sex-disaggregation.html#available-age-sex-data"><i class="fa fa-check"></i><b>11.1.2</b> Available age-sex data</a>
<ul>
<li class="chapter" data-level="11.1.2.1" data-path="age-sex-disaggregation.html"><a href="age-sex-disaggregation.html#age-sex-disaggregation-1"><i class="fa fa-check"></i><b>11.1.2.1</b> Age-sex disaggregation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="age-sex-disaggregation.html"><a href="age-sex-disaggregation.html#useful-resources-9"><i class="fa fa-check"></i><b>11.2</b> Useful resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html"><i class="fa fa-check"></i><b>12</b> Exercise Solutions by Module</a>
<ul>
<li class="chapter" data-level="12.1" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#module-1"><i class="fa fa-check"></i><b>12.1</b> Module 1</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#general-exercises"><i class="fa fa-check"></i><b>12.1.1</b> General exercises</a></li>
<li class="chapter" data-level="12.1.2" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#end-of-module-exercises-3"><i class="fa fa-check"></i><b>12.1.2</b> End of module exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#module-2"><i class="fa fa-check"></i><b>12.2</b> Module 2</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#general-exercises-1"><i class="fa fa-check"></i><b>12.2.1</b> General exercises</a></li>
<li class="chapter" data-level="12.2.2" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#end-of-module-exercises-4"><i class="fa fa-check"></i><b>12.2.2</b> End of module exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#module-3"><i class="fa fa-check"></i><b>12.3</b> Module 3</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#general-exercises-2"><i class="fa fa-check"></i><b>12.3.1</b> General exercises</a></li>
<li class="chapter" data-level="12.3.2" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#end-of-module-exercises-5"><i class="fa fa-check"></i><b>12.3.2</b> End of module exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#module-4"><i class="fa fa-check"></i><b>12.4</b> Module 4</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#general-exercises-3"><i class="fa fa-check"></i><b>12.4.1</b> General exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#module-5"><i class="fa fa-check"></i><b>12.5</b> Module 5</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#general-exercises-4"><i class="fa fa-check"></i><b>12.5.1</b> General exercises</a></li>
<li class="chapter" data-level="12.5.2" data-path="exercise-solutions-by-module.html"><a href="exercise-solutions-by-module.html#general-exercises-5"><i class="fa fa-check"></i><b>12.5.2</b> General exercises</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">WorldPop Population Modelling Training Manual, Vol. I</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-statistical-modelling-with-implementation-in-r" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Introduction to Statistical Modelling with Implementation in R<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#introduction-to-statistical-modelling-with-implementation-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This module contains an introduction to the concepts of statistical modelling, covering the key types of models, starting with simple linear regression and progressing to more complex models with implementation in R. Module 4 also introduces various methodologies for model selection, model prediction and cross-validation.</p>
<div id="concept-of-statistical-modelling" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Concept of statistical modelling<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#concept-of-statistical-modelling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="overview-of-statistical-modelling" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Overview of statistical modelling<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#overview-of-statistical-modelling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Statistical modelling, also known as <strong>regression analysis</strong>, can be described as a statistical technique used for exploring the relationship between a <strong>dependent variable</strong> (also called the outcome or response variable) and one or more <strong>independent variables</strong> (also called the explanatory variable or covariates). Data is viewed as being generated by some random process from which conclusions can be drawn. Statistical models help to understand these processes in greater depth, something that can be of interest for multiple reasons.</p>
<ul>
<li>Future predictions can be made from understanding the random process</li>
<li>Decisions can be made based on the inference from the random process</li>
<li>The random process itself may be of scientific interest</li>
</ul>
<p>For example, statistical modelling can be used to find out about the relationship between rainfall and crop yields, or the relationship between unemployment and poverty.</p>
<p>Suppose for <span class="math inline">\(i=1,\cdots,n\)</span> observations we have the observed responses
<span class="math display">\[
\boldsymbol{y}=\begin{pmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{pmatrix},
\]</span>
where each <span class="math inline">\(y_i\)</span> has an associated vector of values for <span class="math inline">\(p\)</span> independent variables</p>
<p><span class="math display">\[
x_i=\begin{pmatrix}
x_{i1} \\ x_{i2} \\ \vdots \\ x_{in}
\end{pmatrix}.
\]</span></p>
<p>The observed responses <span class="math inline">\(\boldsymbol{y}\)</span> are assumed to be realisations of the random variables denoted by
<span class="math display">\[
\boldsymbol{Y}=\begin{pmatrix}
Y_1 \\ Y_2 \\ \vdots \\ Y_n
\end{pmatrix}.
\]</span>
Alternatively, the random variable <span class="math inline">\(Y_i\)</span> is the predicted (or fitted) value of the observed response <span class="math inline">\(y_i\)</span>.</p>
<p>The use of either upper or lower case is important in statistical modelling as the case used indicates to whether the variable is fixed (e.g. the observed responses <span class="math inline">\(\boldsymbol{y}\)</span> ) or random (e.g. the predicted responses <span class="math inline">\(\boldsymbol{Y}\)</span> ). The variability in the independent variable(s) is not modelled, therefore, it is treated as a fixed (not random) variable, hence given in lower case, <span class="math inline">\(x_i\)</span>.</p>
</div>
<div id="correlation" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Correlation<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#correlation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The relationship between variables can be determined by the extent to which they are related, also known as <strong>correlation</strong>. Correlation can either be positive, negative, or it does not exist (no correlation). What each type of correlation means is as follows:</p>
<ul>
<li>Positive: as the value of one variable increases, the value of another increases</li>
<li>Negative: as the value of one variable decreases, the value of another decreases</li>
<li>No correlation: the value of one variable does not affect the value of another variable</li>
</ul>
<p>A visual example of correlation can be seen in the figure below.</p>
<!-- ![Visual examples of the different types of correlation](/Volumes/worldpop/Projects/WP000008_UNFPA_THA_Phase2/Working/Pop_Modelling_Training_Manual/Module4/images/correlation.png) -->
<!-- ![Visual examples of the different types of correlation](/Projects/WP000008_UNFPA_THA_Phase2/Working/Pop_Modelling_Training_Manual/Module4/images/correlation.png) -->
<div class="figure" style="text-align: center">
<img src="figures/4_images/correlation.png" alt="Visual examples of the different types of correlation" width="80%" />
<p class="caption">
(#fig:image correlation)Visual examples of the different types of correlation
</p>
</div>
<div class="boxed" style="background-color: lightyellow; text-align: left; padding: 10px;">
<p><strong>Exercise:</strong> Identify the dependent and independent variables in the following sentence:</p>
<p>A researcher investigates the effects of school density on the grades of its pupils.</p>
</div>
</div>
<div id="scaled-covariates" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Scaled covariates<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#scaled-covariates" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When using more than one covariate in the modelling, it is important that they are given in the same units for comparison purposes. In the cases where they are not in the same units, covariates can be scaled to ensure the results are comparable.</p>
<p>The two main methods for scaling are as follows:</p>
<ul>
<li>Centring: subtract each value from the mean value</li>
<li>Z-score: subtract each value from the mean value and divide by the standard deviation</li>
</ul>
</div>
<div id="uncertainty" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Uncertainty<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#uncertainty" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Uncertainty and error is unavoidable when estimating and predicting. The less error in your predictions, the more reliable the results are, therefore, it is important to measure the error margin when modelling. This can be done by measuring how close (or far) the predicted value is from the mean value. Alternatively, confidence intervals (in frequentest/classical statistics) or credible intervals (in Bayesian statistics) can be used. In this chapter, the focus is on frequentest statistics so confidence intervals will be used, Bayesian statistics will be introduced in Module 6.</p>
</div>
</div>
<div id="simple-regression" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Simple regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#simple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are some important assumptions required for simple regression modelling, given as follows.</p>
<ol style="list-style-type: decimal">
<li>Normality of the response/residuals (e.g. histograms, Q-Q plot)</li>
<li>Linear relationship between response and predictors (e.g. scatter plot, residuals vs fitted plot)</li>
<li>Homoscedasticity - constant variance of the residuals (e.g. spread-location plot)</li>
<li>Independence between predictors - no multicollinearity (e.g. use <code>Corr(X1, X2)</code> function, should be approximately equal to 1)</li>
</ol>
<p>To check that the response follows the normality assumption, plots can be used. If the normality assumption holds, the shape of the histogram will resemble the shape of a bell curve, as seen in the example below using the <code>birth</code> data. This dataset has the dependent variable <code>Weight</code> for the birth weight (in grams) of 24 newborn babies with 2 independent variables, <code>Sex</code> for the sex and <code>Age</code> for the gestational age (in weeks) of the babies, where <code>Sex</code> is a categorical variable with values</p>
<p><span class="math display">\[\text{Sex} =
\begin{cases}
1 &amp; \text{if male, or} \\
2 &amp; \text{if female}.
\end{cases}\]</span></p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb358-1" tabindex="-1"></a><span class="co">#create birth weight dataset</span></span>
<span id="cb358-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb358-2" tabindex="-1"></a>birth <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb358-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb358-3" tabindex="-1"></a>  <span class="at">Sex=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>),</span>
<span id="cb358-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb358-4" tabindex="-1"></a>  <span class="at">Age=</span><span class="fu">c</span>(<span class="dv">40</span>,<span class="dv">38</span>,<span class="dv">40</span>,<span class="dv">35</span>,<span class="dv">36</span>,<span class="dv">37</span>,<span class="dv">41</span>,<span class="dv">40</span>,<span class="dv">37</span>,<span class="dv">38</span>,<span class="dv">40</span>,<span class="dv">38</span>,<span class="dv">40</span>,<span class="dv">36</span>,<span class="dv">40</span>,<span class="dv">38</span>,<span class="dv">42</span>,<span class="dv">39</span>,<span class="dv">40</span>,<span class="dv">37</span>,<span class="dv">36</span>,<span class="dv">38</span>,<span class="dv">39</span>,<span class="dv">40</span>), </span>
<span id="cb358-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb358-5" tabindex="-1"></a>  <span class="at">Weight=</span><span class="fu">c</span>(<span class="dv">2968</span>,<span class="dv">2795</span>,<span class="dv">3163</span>,<span class="dv">2925</span>,<span class="dv">2625</span>,<span class="dv">2847</span>,<span class="dv">3292</span>,<span class="dv">3473</span>,<span class="dv">2628</span>,<span class="dv">3176</span>,<span class="dv">3421</span>,<span class="dv">2975</span>,<span class="dv">3317</span>,</span>
<span id="cb358-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb358-6" tabindex="-1"></a>           <span class="dv">2729</span>,<span class="dv">2935</span>,<span class="dv">2754</span>,<span class="dv">3210</span>,<span class="dv">2817</span>,<span class="dv">3126</span>,<span class="dv">2539</span>,<span class="dv">2412</span>,<span class="dv">2991</span>,<span class="dv">2875</span>,<span class="dv">3231</span>))</span></code></pre></div>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb359-1" tabindex="-1"></a><span class="co">#plot a histogram of the birth weights</span></span>
<span id="cb359-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb359-2" tabindex="-1"></a><span class="fu">hist</span>(birth<span class="sc">$</span>Weight, <span class="at">breaks=</span><span class="dv">10</span>, </span>
<span id="cb359-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb359-3" tabindex="-1"></a>     <span class="at">main=</span><span class="st">&quot;Histogram of Birth Weight&quot;</span>,</span>
<span id="cb359-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb359-4" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Birth Weight&quot;</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/normality%20check%20histogram-1.png" width="672" /></p>
<p>Alternatively, a Q-Q (quantile-quantile) plot can be used to assess the validity of the normality assumption, which plots the theoretical quantiles against the sample quantiles. If the normality assumption holds, the points on the plot will approximately follow a straight line. To plot this in <code>R</code>, the function <code>qqnorm()</code> can be used with an argument for the response that is being assessed, with the function <code>qqline()</code> being used with the response as an argument to add a reference line, making it easier to see whether the relationship is in fact linear. This is demonstrated below with the <code>birth</code> dataset, where it can be seen that the normality assumption holds given that the points on the Q-Q plot approximately follow the straight line given. However, in the case where the normality assumption does not hold, transformations such as the log-transformation can be used. If transformations are not appropriate, such as when the data is count or binary, alternative methods of modelling are required, leading to generalised linear modelling discussed later in this module.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb360-1" tabindex="-1"></a><span class="co">#qq plot of the birth weight data</span></span>
<span id="cb360-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb360-2" tabindex="-1"></a><span class="fu">qqnorm</span>(birth<span class="sc">$</span>Weight)</span>
<span id="cb360-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb360-3" tabindex="-1"></a></span>
<span id="cb360-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb360-4" tabindex="-1"></a><span class="co">#add a reference line to the plot</span></span>
<span id="cb360-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb360-5" tabindex="-1"></a><span class="fu">qqline</span>(birth<span class="sc">$</span>Weight, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/normality%20assumption%20qq%20plot-1.png" width="672" /></p>
<p>Using the plotting techniques discussed in Module 2, exploratory analysis can be conducted on the data, checking the assumption of a linear relationship between the response and predictors. Through using the <code>plot()</code> function with the response and the predictor you wish to test as arguments, if the resulting scatter plot has a linear trend, then this assumption is met.</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb361-1" tabindex="-1"></a><span class="co">#scatter plot for linear assumption</span></span>
<span id="cb361-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb361-2" tabindex="-1"></a><span class="fu">plot</span>(birth<span class="sc">$</span>Age, birth<span class="sc">$</span>Weight,</span>
<span id="cb361-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb361-3" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Gestational age (in weeks)&quot;</span>,</span>
<span id="cb361-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb361-4" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Birth weight (in grams)&quot;</span>,</span>
<span id="cb361-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb361-5" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Gestational age vs birth weight&quot;</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/scatter%20plot%20linear%20assumption-1.png" width="672" /></p>
<p>The plot of gestational age vs birth weight shows that there is a positive correlation between the two variables, indicating that as gestational age increases, the birth weight also increases, where the points roughly follow a straight line indicating that the assumption of linearity between the response and predictor is met.</p>
<p>Another way to test this assumption is to use the <code>pairs()</code> function in <code>R</code>, where when the dataset of interest is included as an argument, it provides a matrix of scatter plots that show the relationship of each combination of variables available in the data.</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb362-1" tabindex="-1"></a><span class="co">#use the pairs function for the birth dataset</span></span>
<span id="cb362-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb362-2" tabindex="-1"></a><span class="fu">pairs</span>(birth)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/pairs-1.png" width="672" /></p>
<p>The scatter plots for <code>Age</code> and <code>Weight</code> indicate that the relationship between the variables is approximately linear and therefore the assumption is met. However, if this assumption was not upheld, then appropriate transformations could be used, for example, a log-transformation. This is discussed more in the non-linear regression modelling section.</p>
<p>Alternative ways of checking assumptions require for the model to be fitted first, these methods will be discussed in the following sections.</p>
<div id="linear-regression" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Linear regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Simple linear regression is a regression model which has a linear relationship due to the dependent variable depends only on one independent variable, alternatively, the independent variable is conditioned only on one dependent variable. A key concept of the simple linear regression model is that it is assumed each response follows a normal distribution, <span class="math inline">\(Y_i \sim N(\mu_i, \sigma^2)\)</span>. The simple linear regression model can be written as
<span class="math display">\[ Y_i = \beta_0 + \beta_1 x_i + \epsilon_i,\]</span></p>
<p>where <span class="math inline">\(\beta_0\)</span> is the <span class="math inline">\(y-\)</span>intercept, <span class="math inline">\(\beta_1\)</span> is the slope and the errors are independent and identically distributed as <span class="math inline">\(\epsilon\sim N(0, \sigma^2)\)</span> for <span class="math inline">\(i=1,...,n\)</span>. The error can be described as the random difference between the value of <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(\beta_0 +\beta_1 x_i\)</span> which is the value of its conditional mean.</p>
<p>An example of a simple linear regression can be seen below with the <code>birth</code> dataset. The birth weight of each baby can be modelled using either the gestational age or sex of the individual for a simple linear regression model. In this example we will focus on predicting the birth weight of a baby using the gestational age.</p>
<p><span class="math display">\[\text{Weight}_i = \beta_0 + \beta_1\text{Age}_i + \epsilon_i\]</span>
where <span class="math inline">\(\epsilon_i \sim Normal(0, \sigma)\)</span>.</p>
<p>To do linear modelling in <code>R</code>, the function <code>lm()</code> can be used with an argument for the model formula. When fitting a simple linear regression model, the function <code>glm()</code>, used for fitting generalised linear models, yields identical results to the function <code>lm()</code>. Generalised linear models will be discussed later in the module.</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb363-1" tabindex="-1"></a><span class="co">#fit a linear model for birth weight by gestational age</span></span>
<span id="cb363-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb363-2" tabindex="-1"></a>birth_simple_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Weight <span class="sc">~</span> Age, <span class="at">data =</span> birth)</span>
<span id="cb363-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb363-3" tabindex="-1"></a>birth_simple_lm</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Age, data = birth)
## 
## Coefficients:
## (Intercept)          Age  
##     -1485.0        115.5</code></pre>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb365-1" tabindex="-1"></a><span class="co">#fit the linear model using the function glm</span></span>
<span id="cb365-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb365-2" tabindex="-1"></a>birth_simple_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(Weight <span class="sc">~</span> Age, <span class="at">data =</span> birth)</span>
<span id="cb365-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb365-3" tabindex="-1"></a>birth_simple_glm <span class="co">#results are identical to the results from the lm function</span></span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = Weight ~ Age, data = birth)
## 
## Coefficients:
## (Intercept)          Age  
##     -1485.0        115.5  
## 
## Degrees of Freedom: 23 Total (i.e. Null);  22 Residual
## Null Deviance:       1830000 
## Residual Deviance: 816100    AIC: 324.5</code></pre>
<div class="figure" style="text-align: center">
<img src="figures/4_images/coefficient%20output.png" alt="Reading the coefficients from the model output" width="80%" />
<p class="caption">
(#fig:image lm summary)Reading the coefficients from the model output
</p>
</div>
<p>The output of the model gives the resulting coefficients. <code>(Intercept)</code> corresponds to the <span class="math inline">\(y-\)</span>intercept <span class="math inline">\(\beta_0\)</span>, in this case <span class="math inline">\(\beta_0=-1485.0\)</span> meaning that if <span class="math inline">\(\text{Age}=0\)</span> then the birth weight would be -1485.0g. The coefficient <code>Age</code> corresponds to the slope <span class="math inline">\(\beta_1\)</span>, in this case <span class="math inline">\(\beta_1=115.5\)</span>, meaning that for each (1) unit increase in <code>Age</code>, the birth weight will increase by 115.5g.</p>
<p>Including the linear model as an argument in the function <code>summary()</code> in R provides summary statistics for the linear model. These statistics include the previously given coefficients, as well as the corresponding standard errors and p-values (probability values) for the coefficients (among other information). This function is beneficial for exploring whether the independent variables are statistically significant and improve the model, as a small p-value (typically chosen to be less than 0.05) indicates that there is a statistically significant relationship between variables.</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb367-1" tabindex="-1"></a><span class="co">#print summary for linear model</span></span>
<span id="cb367-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb367-2" tabindex="-1"></a><span class="fu">summary</span>(birth_simple_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Age, data = birth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -262.03 -158.29    8.35   88.15  366.50 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -1485.0      852.6  -1.742   0.0955 .  
## Age            115.5       22.1   5.228 3.04e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 192.6 on 22 degrees of freedom
## Multiple R-squared:  0.554,  Adjusted R-squared:  0.5338 
## F-statistic: 27.33 on 1 and 22 DF,  p-value: 3.04e-05</code></pre>
<div class="figure" style="text-align: center">
<img src="figures/4_images/coefficient%20summary.png" alt="Interpreting the summary output" width="80%" />
<p class="caption">
(#fig:image coef summary)Interpreting the summary output
</p>
</div>
<p>In this case, it can be seen that the p-value for the <code>Age</code> covariate is <span class="math inline">\(&lt;0.05\)</span> and is therefore statistically significant to the 5% level and improves the model (and therefore should remain in the model).</p>
<p>A line of best fit using the linear model can be added to the above plot through using the function <code>abline()</code>, adding the entire linear model as an argument of the function.</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb369-1" tabindex="-1"></a><span class="co">#plot birth weight against gestational age</span></span>
<span id="cb369-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb369-2" tabindex="-1"></a><span class="fu">plot</span>(birth<span class="sc">$</span>Weight <span class="sc">~</span> birth<span class="sc">$</span>Age,</span>
<span id="cb369-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb369-3" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Gestational age (in weeks)&quot;</span>,</span>
<span id="cb369-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb369-4" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Birth weight (in grams)&quot;</span>,</span>
<span id="cb369-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb369-5" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Gestational age vs birth weight&quot;</span>) </span>
<span id="cb369-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb369-6" tabindex="-1"></a><span class="co">#add line for linear model</span></span>
<span id="cb369-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb369-7" tabindex="-1"></a><span class="fu">abline</span>(birth_simple_lm)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/plot%20birth%20weight%20gestational%20age%20with%20lm%20line-1.png" width="672" /></p>
<p>To create diagnostic plots for the linear model to check the required assumptions, the function <code>plot()</code> can be used with the model as the argument. This creates four plots, each having a different purpose. To produce only one of the four plots, add an argument for the plot index you wish to show (the fourth plot is combined of Cook’s distance and Residuals vs Leverage plots, to index the fourth plot, include <code>5</code> as an argument).</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb370-1" tabindex="-1"></a><span class="co">#model diagnostic plot</span></span>
<span id="cb370-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb370-2" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb370-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb370-3" tabindex="-1"></a><span class="fu">plot</span>(birth_simple_lm)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/plot%20model%20diagnostic-1.png" width="672" /></p>
<p>The first plot is the <strong>Residuals vs Fitted</strong> plot, used to check the linearity assumption.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb371-1" tabindex="-1"></a><span class="co">#residuals plot</span></span>
<span id="cb371-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb371-2" tabindex="-1"></a><span class="fu">plot</span>(birth_simple_lm, <span class="dv">1</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/residuals%20plot-1.png" width="672" /></p>
<p>In this plot, there should be no pattern and the red line should be approximately horizontal at zero for the normality assumption to hold. The residuals plot for the birth data is quite horizontal and is based around zero, however, there is a slight indication of a pattern meaning that there could be some problem with the linear model. This problem could be many things, possibly indicating that the relationship is not linear and instead quadratic for example.</p>
<p>The second plot is the <strong>Normal Q-Q</strong> plot, similar to that produced by the <code>qqnorm()</code> function discussed previously, but now is used to check the normality assumption of the residuals.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb372-1" tabindex="-1"></a><span class="co">#normal Q-Q plot</span></span>
<span id="cb372-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb372-2" tabindex="-1"></a><span class="fu">plot</span>(birth_simple_lm, <span class="dv">2</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/normal%20q-q-1.png" width="672" /></p>
<p>The plot for the <code>birth</code> data does show some problems with the normality assumption given that the points to not all approximately fall on the reference line. This means that the normality assumption cannot be assumed.</p>
<p>The third plot is the <strong>Scale-Location</strong> plot, or the <strong>Spread-Location</strong> plot, used to verify the homoscedasticity (homogeneity of variance). For the assumption to be upheld, the line should be approximately horizontal with the points equally dispersed.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb373-1" tabindex="-1"></a><span class="co">#scale-location plot</span></span>
<span id="cb373-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb373-2" tabindex="-1"></a><span class="fu">plot</span>(birth_simple_lm, <span class="dv">3</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/scale-location-1.png" width="672" /></p>
<p>In this case, the points are approximately equally spread out with the reference line being mostly horizontal, indicating that the homoscedasticity assumption may be upheld.</p>
<p>Finally, the fourth plot is the <strong>Residuals vs Leverage</strong> plot, used for identifying outlier points that have high leverage. These are points that may impact the results of the regression analysis if they are included or excluded, although not all outliers are influential to alter the results. This plot identifies the 3 most extreme values.</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb374-1" tabindex="-1"></a><span class="co">#residuals vs leverage plot</span></span>
<span id="cb374-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb374-2" tabindex="-1"></a><span class="fu">plot</span>(birth_simple_lm, <span class="dv">5</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/residuals%20vs%20leverage-1.png" width="672" /></p>
<p>This plot identifies the 3 most extreme points (#4, #8 and #21), where point number 4 is identified as influential through using the measure of Cook’s distance. There is evidence that this point will alter the results of the regression analysis so there should be some consideration whether to include this point or not.</p>
<!-- The population dataset `sim_population.csv` introduced in Module 2 can be used for demonstrating these methods too. For example, the relationship between the number of buildings in an area and the corresponding population can be explored through fitting a simple linear regression model to the data and plotting the results with a line of best fit. -->
<!-- ```{r sim pop data, echo=FALSE} -->
<!-- #import simulated population data -->
<!-- Pop_data <- read.csv(file = paste0(data_path, "sim_population.csv"), header = T) -->
<!-- #fit a simple linear regression model -->
<!-- pop_simple_lm <- lm(pop ~ buildings, data = Pop_data) -->
<!-- summary(pop_simple_lm) -->
<!-- #plot the relationship -->
<!-- plot(Pop_data$pop~Pop_data$buildings, -->
<!--      xlab = "Number of buildings", -->
<!--      ylab = "Population", -->
<!--      main = "Building count vs population")  -->
<!-- abline(pop_simple_lm) -->
<!-- ``` -->
<!-- <div -->
<!-- class="boxed" style="background-color: lightyellow; text-align: left; padding: 10px;">  -->
<!--   **Exercise:** Import the dataset `sim_population.csv` into your R script. Fit a linear model exploring the relationship between mean temperature and elevation. Produce a scatter plot of the relationship and add a line of best fit.  -->
<!-- </div> -->
</div>
<div id="polynomial-regression" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Polynomial regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#polynomial-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The data is not always best described by a linear relationship between the dependent and independent variables, for example, there could be a quadratic relationship between the variables.</p>
<p>The following are examples of polynomial regression models:</p>
<ul>
<li>A quadratic function: <span class="math display">\[ Y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \epsilon_i.\]</span></li>
<li>A polynomial of degree 4: <span class="math display">\[Y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \beta_3 x_i^3 + \beta_4 x_i^4+ \epsilon_i.\]</span></li>
</ul>
<p>For example, to fit a simple polynomial regression model with a quadratic function to the birth weight dataset used above, the quadratic term needs to be created and added to the data, then the function <code>lm()</code> can be used inputting the model formula. Alternatively, the quadratic term can be included in the formula within the function <code>I()</code> which lets R know to include that term as a separate term within the model. Another option is to use the function <code>poly()</code> with arguments for the independent variable and the degree of polynomial wanted, making the code more efficient when higher order polynomials are used in particular, instead of typing out a long equation with many terms.</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb375-1" tabindex="-1"></a><span class="co">#create the quadratic term and add to data before modelling</span></span>
<span id="cb375-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb375-2" tabindex="-1"></a>birth<span class="sc">$</span>Age2 <span class="ot">&lt;-</span> birth<span class="sc">$</span>Age<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb375-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb375-3" tabindex="-1"></a>birth_quad_lm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Weight <span class="sc">~</span> Age <span class="sc">+</span> Age2, <span class="at">data =</span> birth)</span>
<span id="cb375-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb375-4" tabindex="-1"></a><span class="fu">summary</span>(birth_quad_lm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Age + Age2, data = birth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -276.86 -156.62    5.87   99.72  340.27 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  7288.668  17631.783   0.413    0.684
## Age          -342.639    919.905  -0.372    0.713
## Age2            5.969     11.980   0.498    0.624
## 
## Residual standard error: 196 on 21 degrees of freedom
## Multiple R-squared:  0.5592, Adjusted R-squared:  0.5173 
## F-statistic: 13.32 on 2 and 21 DF,  p-value: 0.0001837</code></pre>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb377-1" tabindex="-1"></a><span class="co">#alternatively, include quadratic term within I()</span></span>
<span id="cb377-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb377-2" tabindex="-1"></a>birth_quad_lm2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Weight <span class="sc">~</span> Age <span class="sc">+</span> <span class="fu">I</span>(Age<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> birth)</span>
<span id="cb377-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb377-3" tabindex="-1"></a><span class="fu">summary</span>(birth_quad_lm2) <span class="co">#produces the same model</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Age + I(Age^2), data = birth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -276.86 -156.62    5.87   99.72  340.27 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  7288.668  17631.783   0.413    0.684
## Age          -342.639    919.905  -0.372    0.713
## I(Age^2)        5.969     11.980   0.498    0.624
## 
## Residual standard error: 196 on 21 degrees of freedom
## Multiple R-squared:  0.5592, Adjusted R-squared:  0.5173 
## F-statistic: 13.32 on 2 and 21 DF,  p-value: 0.0001837</code></pre>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb379-1" tabindex="-1"></a><span class="co">#alternatively, include quadratic term within poly()</span></span>
<span id="cb379-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb379-2" tabindex="-1"></a>birth_quad_lm3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Weight <span class="sc">~</span> <span class="fu">poly</span>(<span class="at">x =</span> Age, <span class="at">degree =</span> <span class="dv">2</span>, <span class="at">raw =</span> <span class="cn">TRUE</span>),</span>
<span id="cb379-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb379-3" tabindex="-1"></a>                     <span class="at">data =</span> birth)</span>
<span id="cb379-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb379-4" tabindex="-1"></a><span class="fu">summary</span>(birth_quad_lm3) <span class="co">#produces the same model</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ poly(x = Age, degree = 2, raw = TRUE), 
##     data = birth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -276.86 -156.62    5.87   99.72  340.27 
## 
## Coefficients:
##                                         Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)                             7288.668  17631.783   0.413    0.684
## poly(x = Age, degree = 2, raw = TRUE)1  -342.639    919.905  -0.372    0.713
## poly(x = Age, degree = 2, raw = TRUE)2     5.969     11.980   0.498    0.624
## 
## Residual standard error: 196 on 21 degrees of freedom
## Multiple R-squared:  0.5592, Adjusted R-squared:  0.5173 
## F-statistic: 13.32 on 2 and 21 DF,  p-value: 0.0001837</code></pre>
<p>The output from the <code>summary()</code> function works the same for non-linear models as it does for linear, with the coefficient estimates corresponding to the values of <span class="math inline">\(\alpha\)</span> for the intercept and the <span class="math inline">\(\beta\)</span> value(s) for the covariate(s). In this case, it can be seen that adding the quadratic term for age does not improve upon the linear model given that the p-value (<code>Pr(&gt;|t|)</code>) is not statistically significant. This conclusion is reasonable given that the line of best fit for the linear model fits the birth weight data well and the data does not show a quadratic trend.</p>
<p>The welding dataset below contains information from the Welding Institute in Abingdon, providing <span class="math inline">\(n=21\)</span> measurements of currents in amps with the corresponding minimum diameter of the weld. Given that the diameter of the weld depends on the amount of current, <code>Current</code> is the independent variable and <code>Diameter</code> is the dependent variable.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb381-1" tabindex="-1"></a><span class="co">#create welding dataset</span></span>
<span id="cb381-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb381-2" tabindex="-1"></a>welding <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Current =</span> <span class="fu">c</span>(<span class="fl">7.82</span>, <span class="fl">8.00</span>, <span class="fl">7.95</span>, <span class="fl">8.07</span>, <span class="fl">8.08</span>, <span class="fl">8.01</span>, <span class="fl">8.33</span>, </span>
<span id="cb381-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb381-3" tabindex="-1"></a>                                  <span class="fl">8.34</span>, <span class="fl">8.32</span>, <span class="fl">8.64</span>, <span class="fl">8.61</span>, <span class="fl">8.57</span>, <span class="fl">9.01</span>, <span class="fl">8.97</span>, </span>
<span id="cb381-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb381-4" tabindex="-1"></a>                                  <span class="fl">9.05</span>, <span class="fl">9.23</span>, <span class="fl">9.24</span>, <span class="fl">9.24</span>, <span class="fl">9.61</span>, <span class="fl">9.60</span>, <span class="fl">9.61</span>), </span>
<span id="cb381-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb381-5" tabindex="-1"></a>                      <span class="at">Diameter =</span> <span class="fu">c</span>(<span class="fl">3.4</span>, <span class="fl">3.5</span>, <span class="fl">3.3</span>, <span class="fl">3.9</span>, <span class="fl">3.9</span>, <span class="fl">4.1</span>, <span class="fl">4.6</span>, <span class="fl">4.3</span>, <span class="fl">4.5</span>, </span>
<span id="cb381-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb381-6" tabindex="-1"></a>                                   <span class="fl">4.9</span>, <span class="fl">4.9</span>, <span class="fl">5.1</span>, <span class="fl">5.5</span>, <span class="fl">5.5</span>, <span class="fl">5.6</span>, <span class="fl">5.9</span>, <span class="fl">5.8</span>, <span class="fl">6.1</span>,</span>
<span id="cb381-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb381-7" tabindex="-1"></a>                                   <span class="fl">6.3</span>, <span class="fl">6.4</span>, <span class="fl">6.2</span>))</span></code></pre></div>
<p>The welding data can be modelled in the same way as the birth weight dataset, using the function <code>lm()</code>, as seen in the example below.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb382-1" tabindex="-1"></a><span class="co">#simple linear model</span></span>
<span id="cb382-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb382-2" tabindex="-1"></a>weld_simple_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Diameter <span class="sc">~</span> Current, <span class="at">data =</span> welding)</span>
<span id="cb382-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb382-3" tabindex="-1"></a><span class="fu">summary</span>(weld_simple_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Diameter ~ Current, data = welding)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.42623 -0.07282  0.01637  0.08269  0.34586 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -9.45427    0.65526  -14.43 1.09e-11 ***
## Current      1.65793    0.07531   22.01 5.53e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2012 on 19 degrees of freedom
## Multiple R-squared:  0.9623, Adjusted R-squared:  0.9603 
## F-statistic: 484.6 on 1 and 19 DF,  p-value: 5.529e-15</code></pre>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb384-1" tabindex="-1"></a><span class="co">#quadratic model</span></span>
<span id="cb384-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb384-2" tabindex="-1"></a>weld_quad_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Diameter <span class="sc">~</span> Current <span class="sc">+</span> <span class="fu">I</span>(Current<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> welding)</span>
<span id="cb384-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb384-3" tabindex="-1"></a><span class="fu">summary</span>(weld_quad_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Diameter ~ Current + I(Current^2), data = welding)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.31023 -0.10023 -0.00496  0.09880  0.35197 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -41.5662     9.9392  -4.182 0.000560 ***
## Current        9.0430     2.2833   3.960 0.000917 ***
## I(Current^2)  -0.4227     0.1306  -3.236 0.004589 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1644 on 18 degrees of freedom
## Multiple R-squared:  0.9761, Adjusted R-squared:  0.9735 
## F-statistic: 368.3 on 2 and 18 DF,  p-value: 2.501e-15</code></pre>
<p>Unlike with the birth weight quadratic model, the addition of a quadratic term to the model for the welding data improves the fit of the model, given that both the linear and quadratic terms are statistically significant at the 5% significance level. This improved fit can be demonstrated graphically using the function <code>predict()</code> with arguments for the model you wish to predict from and a new dataset with a range of values you wish to predict the values of the dependent variable from (typically a sequence of evenly spaced numbers from the minimum to maximum values of your independent variable).</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-1" tabindex="-1"></a><span class="co">#made a new dataset</span></span>
<span id="cb386-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-2" tabindex="-1"></a>weld.new <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Current =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">min</span>(welding<span class="sc">$</span>Current), </span>
<span id="cb386-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-3" tabindex="-1"></a>                                     <span class="at">to =</span> <span class="fu">max</span>(welding<span class="sc">$</span>Current),</span>
<span id="cb386-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-4" tabindex="-1"></a>                                     <span class="at">length.out =</span> <span class="dv">100</span>))</span>
<span id="cb386-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-5" tabindex="-1"></a></span>
<span id="cb386-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-6" tabindex="-1"></a><span class="co">#use the predict function</span></span>
<span id="cb386-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-7" tabindex="-1"></a>pred_simple_lm <span class="ot">&lt;-</span> <span class="fu">predict</span>(weld_simple_lm, <span class="at">newdata =</span> weld.new)</span>
<span id="cb386-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-8" tabindex="-1"></a>pred_quad_lm <span class="ot">&lt;-</span> <span class="fu">predict</span>(weld_quad_lm, <span class="at">newdata =</span> weld.new)</span>
<span id="cb386-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-9" tabindex="-1"></a></span>
<span id="cb386-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-10" tabindex="-1"></a></span>
<span id="cb386-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-11" tabindex="-1"></a><span class="co">#basic plot for relationship between variables </span></span>
<span id="cb386-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-12" tabindex="-1"></a><span class="fu">plot</span>(Diameter <span class="sc">~</span> Current, <span class="at">data =</span> welding)</span>
<span id="cb386-13"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-13" tabindex="-1"></a><span class="co">#add lines for each of the sets of predicted values</span></span>
<span id="cb386-14"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-14" tabindex="-1"></a><span class="fu">lines</span>(pred_simple_lm <span class="sc">~</span> weld.new<span class="sc">$</span>Current, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb386-15"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-15" tabindex="-1"></a><span class="fu">lines</span>(pred_quad_lm <span class="sc">~</span> weld.new<span class="sc">$</span>Current, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb386-16"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-16" tabindex="-1"></a><span class="co">#add a legend for clarity</span></span>
<span id="cb386-17"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-17" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Linear&quot;</span>, <span class="st">&quot;Quadratic&quot;</span>),</span>
<span id="cb386-18"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb386-18" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/welding%20quad%20predict%20and%20plot-1.png" width="672" /></p>
<p>The plot showing lines of best fit for both the simple linear model and the quadratic model demonstrate the improved fit of the quadratic model, with the added flexibility of the curve matching the trend of the data better.</p>
<p>This process can be extended for including higher degrees of polynomials in the regression models, although it is important to be wary of <strong>overfitting</strong> the model to the data as this risks the model only having use for inference to the original dataset.</p>
</div>
<div id="non-linear-regression" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Non-linear regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#non-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The relationships being explored are not always best described by a linear relationship. In these cases, the data can be transformed, for example using logarithms, square roots and exponentials, to fit a non-linear model which is more flexible, potentially explaining the relationship between variables better. For a regression model to be non-linear, <span class="math inline">\(Y\)</span> must be a non-linear function of the parameters (e.g. <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>), however, <span class="math inline">\(Y\)</span> can still be a linear function of the covariates <span class="math inline">\(x\)</span>.</p>
<p>The following are examples of non-linear regression models:</p>
<ul>
<li>Squared value of the <span class="math inline">\(\beta\)</span> coefficient: <span class="math display">\[Y_i = \beta_0 + \beta_1^2x_i + \epsilon_i.\]</span></li>
<li>Logarithmic: <span class="math display">\[\log(Y_i) = \beta_0 + \beta_1 x_i + \epsilon_i\]</span>
which implies <span class="math display">\[Y_i = \exp(\beta_0 + \beta_1 x_i + \epsilon_i)=\exp(\beta_0)\exp(\beta_1 x_i)\exp(\epsilon)\]</span>
a relationship which is multiplicative, meaning that a unit increase in <span class="math inline">\(x_i\)</span> corresponds to <span class="math inline">\(Y_i\)</span> being multiplied by a value of <span class="math inline">\(\exp(\beta x_i)\)</span>, instead of an additive effect of <span class="math inline">\(\beta x_i\)</span> like with a linear model.</li>
<li>Square root: <span class="math display">\[Y_i^{1/2}=\beta_0 + \beta_1 x_i + \epsilon_i.\]</span></li>
<li>Negative reciprocal: <span class="math display">\[-\frac{1}{Y_i}= \beta_0 + \beta_1 x_i + \epsilon_i.\]</span></li>
</ul>
<p>The function <code>nls()</code> can be used for non-linear regression models and estimate the parameters via a non-linear least squares approach (a non-linear approach to finding the line of best fit for the given data). To demonstrate this approach, the Michaelis-Menten equation for kinetics given below can be used, given that there is a non-linear relationship between the dependent variable and the parameters.</p>
<p><span class="math display">\[
Y_i = \frac{\beta_0 x_i}{\beta_1+x_i}
\]</span></p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-1" tabindex="-1"></a><span class="co">#simulate some data</span></span>
<span id="cb387-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb387-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-3" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb387-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-4" tabindex="-1"></a>y<span class="ot">&lt;-</span>((<span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">20</span>,<span class="dv">30</span>)<span class="sc">*</span>x)<span class="sc">/</span>(<span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">20</span>)<span class="sc">+</span>x)) <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb387-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-5" tabindex="-1"></a></span>
<span id="cb387-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-6" tabindex="-1"></a><span class="co">#model the data using the function nls(), if no start values are given, a </span></span>
<span id="cb387-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-7" tabindex="-1"></a><span class="co">#warning may occur, but R will just choose the start values itself instead</span></span>
<span id="cb387-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb387-8" tabindex="-1"></a>nonlinear_mod <span class="ot">&lt;-</span> <span class="fu">nls</span>(y <span class="sc">~</span> a<span class="sc">*</span>x<span class="sc">/</span>(b<span class="sc">+</span>x)) </span></code></pre></div>
<pre><code>## Warning in nls(y ~ a * x/(b + x)): No starting values specified for some parameters.
## Initializing &#39;a&#39;, &#39;b&#39; to &#39;1.&#39;.
## Consider specifying &#39;start&#39; or using a selfStart model</code></pre>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb389-1" tabindex="-1"></a><span class="co">#summary of the non-linear model</span></span>
<span id="cb389-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb389-2" tabindex="-1"></a><span class="fu">summary</span>(nonlinear_mod)</span></code></pre></div>
<pre><code>## 
## Formula: y ~ a * x/(b + x)
## 
## Parameters:
##   Estimate Std. Error t value Pr(&gt;|t|)    
## a  22.9682     0.1928  119.11   &lt;2e-16 ***
## b   4.9492     0.3010   16.44   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.023 on 98 degrees of freedom
## 
## Number of iterations to convergence: 6 
## Achieved convergence tolerance: 2.029e-07</code></pre>
<p>The summary function works in the same way as for the linear models, providing the estimated values of the model parameters, in this case, <span class="math inline">\(\beta_0=6.4946\)</span> and <span class="math inline">\(\beta_1 =1.0765\)</span>.</p>
<p>To visualise this equation with the non-linear regression model fitted, the function <code>plot()</code> can be used as with the linear models, with the addition of the function <code>lines()</code> as used with the polynomial regression models with an argument for the x-axis values and the predicted values.</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-1" tabindex="-1"></a><span class="co">#plot the data</span></span>
<span id="cb391-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-2" tabindex="-1"></a><span class="fu">plot</span>(x,y)</span>
<span id="cb391-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-3" tabindex="-1"></a><span class="co">#add a line of best fit</span></span>
<span id="cb391-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-4" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">predict</span>(nonlinear_mod), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb391-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-5" tabindex="-1"></a><span class="co">#add a linear regression line for comparison purposes</span></span>
<span id="cb391-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-6" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb391-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-7" tabindex="-1"></a><span class="co">#add a legend for clarity</span></span>
<span id="cb391-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-8" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Non-linear&quot;</span>, <span class="st">&quot;Linear&quot;</span>),</span>
<span id="cb391-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb391-9" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/plot%20non%20linear-1.png" width="672" /></p>
<p>It can be seen in the plot that the non-linear line fits the data very well, much better than the simple linear regression model added to the plot for comparison purposes.</p>
</div>
</div>
<div id="multiple-regression" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Multiple regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Multiple regression can be described as an extension of simple regression where you still only have one dependent variable but there are multiple independent variables. For <span class="math inline">\(p\)</span> independent variables, the model can be written as</p>
<p><span class="math display">\[ Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_p x_{ip} + \epsilon_i,\]</span>
where <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span> for <span class="math inline">\(i=1,...,n\)</span>.</p>
<p>An important assumption of multiple regression modelling is <strong>multicollinearity</strong>, meaning that it is assumed that the independent variables are not highly correlated with one another. If this assumption is not met, it can make identifying which variables better explain the dependent variable better much more challenging.</p>
<p>The <code>birth</code> dataset can be used to demonstrate multiple linear regression given that there are 2 independent variables included in the data, <code>Sex</code> and <code>Age</code>, modelled as follows.
<span class="math display">\[ Weight_i =\beta_0 + \beta_1 Sex_i + \beta_2 Age_i + \epsilon_i\]</span></p>
<p>To perform multiple linear regression in R, the function <code>lm()</code> can be used in the same way as for simple linear regression, however, with the additional variables given in the formula as in the code below.</p>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb392-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb392-1" tabindex="-1"></a><span class="co">#multiple linear regression</span></span>
<span id="cb392-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb392-2" tabindex="-1"></a>birth_multi_lm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Weight <span class="sc">~</span> Sex <span class="sc">+</span> Age, <span class="at">data =</span> birth)</span>
<span id="cb392-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb392-3" tabindex="-1"></a><span class="fu">summary</span>(birth_multi_lm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Sex + Age, data = birth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -257.49 -125.28  -58.44  169.00  303.98 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1447.24     784.26  -1.845   0.0791 .  
## Sex          -163.04      72.81  -2.239   0.0361 *  
## Age           120.89      20.46   5.908 7.28e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 177.1 on 21 degrees of freedom
## Multiple R-squared:   0.64,  Adjusted R-squared:  0.6057 
## F-statistic: 18.67 on 2 and 21 DF,  p-value: 2.194e-05</code></pre>
<p>The output from the summary function shows that both independent variables are statistically significant at the 5% significance level, and hence birth weight depends on both sex and gestational age of the baby. Interpreting the results is done in the same way as for simple models, with the estimates corresponding to the coefficients as follows:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span>=-1447.24</li>
<li><span class="math inline">\(\beta_1\)</span>=-163.04</li>
<li><span class="math inline">\(\beta_2\)</span>=120.89</li>
</ul>
<p>Through using the function <code>update()</code>, you can add or remove variables from a model without needing to re-fit the model yourself. This is particularly useful when you have a model with many parameters, where instead of needing to type out the model again with each of the parameters, you can simply update the existing model to either add another parameter or remove a parameter if it is not needed.</p>
<p>To remove a variable from a model, you use the function in the form <code>update(model, ~. - term)</code>. For example, to update the model given above to remove the covariate <code>Age</code>, you would use the below code.</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb394-1" tabindex="-1"></a><span class="co">#remove the Age covariate from the multiple linear regression model</span></span>
<span id="cb394-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb394-2" tabindex="-1"></a>birth_multi_lm2 <span class="ot">&lt;-</span> <span class="fu">update</span>(birth_multi_lm1, <span class="sc">~</span>. <span class="sc">-</span> Age)</span>
<span id="cb394-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb394-3" tabindex="-1"></a>birth_multi_lm2</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Sex, data = birth)
## 
## Coefficients:
## (Intercept)          Sex  
##      3136.7       -112.7</code></pre>
<p>Alternatively, if you wish to add a variable, you use the formula in the form <code>update(model, ~. + term)</code>. For example, to add the term for Age back into the model, you would use the below code, which results in the same model as originally fitted.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb396-1" tabindex="-1"></a><span class="co">#remove the Age covariate from the multiple linear regression model</span></span>
<span id="cb396-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb396-2" tabindex="-1"></a><span class="fu">update</span>(birth_multi_lm2, <span class="sc">~</span>. <span class="sc">+</span> Age)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Sex + Age, data = birth)
## 
## Coefficients:
## (Intercept)          Sex          Age  
##     -1447.2       -163.0        120.9</code></pre>
<p>The <code>update()</code> function also allows for the data being modelled to be updated through adding an argument for <code>data =</code>. This is demonstrated in the code below.</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-1" tabindex="-1"></a><span class="co">#create an example dataset</span></span>
<span id="cb398-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-2" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb398-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-3" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> y<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb398-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-4" tabindex="-1"></a>z1 <span class="ot">&lt;-</span> y<span class="sc">*</span><span class="dv">3</span></span>
<span id="cb398-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-5" tabindex="-1"></a>update_example1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x1, <span class="at">y =</span> y, <span class="at">z =</span> z1)</span>
<span id="cb398-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-6" tabindex="-1"></a></span>
<span id="cb398-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-7" tabindex="-1"></a><span class="co">#fit linear model</span></span>
<span id="cb398-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-8" tabindex="-1"></a>example_mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> z, <span class="at">data =</span> update_example1)</span>
<span id="cb398-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb398-9" tabindex="-1"></a><span class="fu">summary</span>(example_mod1)</span></code></pre></div>
<pre><code>## Warning in summary.lm(example_mod1): essentially perfect fit: summary may be unreliable</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x + z, data = update_example1)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -4.774e-15 -4.318e-16  4.340e-17  5.935e-16  3.439e-15 
## 
## Coefficients:
##               Estimate Std. Error    t value Pr(&gt;|t|)    
## (Intercept) -4.046e-15  1.160e-15 -3.488e+00  0.00282 ** 
## x           -3.823e-17  1.177e-17 -3.249e+00  0.00472 ** 
## z            3.333e-01  8.480e-17  3.931e+15  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.559e-15 on 17 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 1.368e+32 on 2 and 17 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-1" tabindex="-1"></a><span class="co">#create new dataset</span></span>
<span id="cb401-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-2" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> y<span class="sc">^</span><span class="dv">3</span></span>
<span id="cb401-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-3" tabindex="-1"></a>z2 <span class="ot">&lt;-</span> y<span class="sc">*</span><span class="dv">4</span></span>
<span id="cb401-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-4" tabindex="-1"></a>update_example2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x2, <span class="at">y =</span> y, <span class="at">z =</span> z2)</span>
<span id="cb401-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-5" tabindex="-1"></a></span>
<span id="cb401-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-6" tabindex="-1"></a><span class="co">#update the dataset in the model</span></span>
<span id="cb401-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-7" tabindex="-1"></a>example_mod2 <span class="ot">&lt;-</span> <span class="fu">update</span>(example_mod1, <span class="at">data =</span> update_example2)</span>
<span id="cb401-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb401-8" tabindex="-1"></a><span class="fu">summary</span>(example_mod2)</span></code></pre></div>
<pre><code>## Warning in summary.lm(example_mod2): essentially perfect fit: summary may be unreliable</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x + z, data = update_example2)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -3.681e-16 -1.410e-18  3.702e-17  6.826e-17  1.084e-16 
## 
## Coefficients:
##              Estimate Std. Error   t value Pr(&gt;|t|)    
## (Intercept) 0.000e+00  7.773e-17 0.000e+00        1    
## x           0.000e+00  2.849e-20 0.000e+00        1    
## z           2.500e-01  3.016e-18 8.289e+16   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.204e-16 on 17 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 2.293e+34 on 2 and 17 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="generalised-linear-regression" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Generalised linear regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#generalised-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For simple regression modelling, there is the assumption of normality for the dependent variable, however, this assumption is not always met, for example, with count data (e.g. number of people with a disease) which is often modelled with a Poisson distribution, or binary data (e.g. beetles killed or not killed) which is often modelled with a Bernoulli distribution. In these cases of non-normal data, alternative models are required, which is where generalised linear modelling is beneficial with its relaxed distributional assumption.</p>
<p>The generalised linear model is written in the form
<span class="math display">\[g(\mu_i) = \eta_i = \boldsymbol{x}_i^T \boldsymbol{\beta},\]</span>
where <span class="math inline">\(\mu_i=E(Y_i)\)</span> is the expected value of <span class="math inline">\(Y_i\)</span>, <span class="math inline">\(\eta_i\)</span> is the linear predictor and <span class="math inline">\(g(\mu_i)\)</span> is the <strong>link function</strong> between the distribution of <span class="math inline">\(\boldsymbol{Y}\)</span> and the linear predictor.</p>
<p>An important assumption for generalised linear regression is that the dependent variable <span class="math inline">\(\boldsymbol{Y}\)</span> is assumed to be independent and a member of the exponential family (e.g. normal, Poisson, Bernoulli, geometric, exponential, …).</p>
<p>The link function depends on the distribution of the data type and the dependent variable, where the table below provides the three main link functions and the corresponding data types and distributions.</p>
<div style="width: 100%; text-align: center; display: flex; justify-content: center;">
<table style="width:98%;">
<colgroup>
<col width="14%" />
<col width="33%" />
<col width="40%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
<tr class="even">
<th>Data type</th>
<th>Response family</th>
<th>Link</th>
<th>Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Continuous</td>
<td>Normal/Gaussian/log-normal/gamma</td>
<td><span class="math inline">\(g(\mu)=\mu\)</span></td>
<td>Identity</td>
</tr>
<tr class="even">
<td>Count</td>
<td>Poisson</td>
<td><span class="math inline">\(g(\mu)=\log(\mu)\)</span></td>
<td>Log</td>
</tr>
<tr class="odd">
<td>Binary</td>
<td>Bernoulli/binomial</td>
<td><span class="math inline">\(g(\mu)=\log\left(\frac{p}{1-p}\right)\)</span></td>
<td>Logit</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>To fit generalised linear models in R, the function <code>glm()</code> can be used, in a very similar way to the function <code>lm()</code> seen in earlier sections, but with the addition of a (exponential) <code>family</code> argument. The default family is normal, hence why if no family is specified, the functions <code>glm()</code> and <code>lm()</code> produce identical models. However, if the data is not normal, the exponential family that the data is a member of must be specified.</p>
<p>When dealing with count data, the Poisson log-linear model is most commonly used, taking the following form.
<span class="math display">\[ Y_i \sim Poisson(\mu_i), \text{ } \log(\mu_i)=\boldsymbol{x}_i^T \boldsymbol{\beta}\]</span>
It is important to note that the Poisson distribution assumes that the mean and variance are equal. If over-dispersion (the variance is greater than the mean) is present, a negative-binomial model may be preferable.</p>
<p>To demonstrate generalised linear modelling with count data, the <code>ccancer</code> dataset from the package <code>GLMsData</code> can be utilised. This dataset gives the count of deaths (<code>Count</code>) due to cancer within three different regions of Canada (<code>Region</code>), providing additional covariates for the gender of each individual (<code>Gender</code>) and the site of the cancer (<code>Site</code>). More information on this dataset can be found through using the help function.</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb404-1" tabindex="-1"></a><span class="co">#install GLMsData package</span></span>
<span id="cb404-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb404-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;GLMsData&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb405-1" tabindex="-1"></a><span class="co">#load the GLMsData package</span></span>
<span id="cb405-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb405-2" tabindex="-1"></a><span class="fu">library</span>(GLMsData)</span></code></pre></div>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb406-1" tabindex="-1"></a><span class="co">#import ccancer dataset</span></span>
<span id="cb406-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb406-2" tabindex="-1"></a><span class="fu">data</span>(ccancer)</span>
<span id="cb406-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb406-3" tabindex="-1"></a><span class="fu">head</span>(ccancer)</span></code></pre></div>
<pre><code>##   Count Gender  Region       Site Population
## 1  3500      M Ontario       Lung   11874400
## 2  1250      M Ontario Colorectal   11874400
## 3     0      M Ontario     Breast   11874400
## 4  1600      M Ontario   Prostate   11874400
## 5   540      M Ontario   Pancreas   11874400
## 6  2400      F Ontario       Lung   11874400</code></pre>
<p>To model this data, the function <code>glm()</code> can be used again, but with specifying the family argument as <code>family = poisson</code> as follows, where the following model is an intercept only model, including a <code>1</code> instead of any independent variables.</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb408-1" tabindex="-1"></a><span class="co">#fit the glm for the ccancer data to explore the effect of gender on the </span></span>
<span id="cb408-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb408-2" tabindex="-1"></a><span class="co">#count of cancer deaths</span></span>
<span id="cb408-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb408-3" tabindex="-1"></a>ccancer_glm1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(Count <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> <span class="st">&quot;poisson&quot;</span>, <span class="at">data =</span> ccancer)</span>
<span id="cb408-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb408-4" tabindex="-1"></a><span class="fu">summary</span>(ccancer_glm1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Count ~ 1, family = &quot;poisson&quot;, data = ccancer)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) 6.702984   0.006396    1048   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 35187  on 29  degrees of freedom
## Residual deviance: 35187  on 29  degrees of freedom
## AIC: 35380
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>Given that there are covariates included in this dataset, it is important to explore the relationship they may have with the response. The following model contains a main effect for gender, exploring the relationship between the gender of individuals and cancer deaths.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb410-1" tabindex="-1"></a><span class="co">#fit the glm for the ccancer data to explore the effect of gender on the </span></span>
<span id="cb410-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb410-2" tabindex="-1"></a><span class="co">#count of cancer deaths</span></span>
<span id="cb410-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb410-3" tabindex="-1"></a>ccancer_glm2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(Count <span class="sc">~</span> Gender, <span class="at">family =</span> <span class="st">&quot;poisson&quot;</span>, <span class="at">data =</span> ccancer)</span>
<span id="cb410-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb410-4" tabindex="-1"></a><span class="fu">summary</span>(ccancer_glm2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Count ~ Gender, family = &quot;poisson&quot;, data = ccancer)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) 6.621406   0.009422  702.77   &lt;2e-16 ***
## GenderM     0.157000   0.012831   12.24   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 35187  on 29  degrees of freedom
## Residual deviance: 35037  on 28  degrees of freedom
## AIC: 35232
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>It can be seen in this model that the inclusion of the covariate <code>Gender</code> is statistically significant, therefore there is a relationship between the gender of an individual and the count of cancer deaths in Canada.</p>
<div class="boxed" style="background-color: lightyellow; text-align: left; padding: 10px;">
<p><strong>Exercise:</strong> Fit a Poisson GLM using the <code>ccancer</code> dataset exploring the relationship between the count of cancer deaths and the covariates for the cancer site and region in Canada. Is the relationship between the dependent and independent variables significant?</p>
</div>
<p>Another example of generalised linear modelling with count data can be seen as follows using the <code>hodgkins</code> dataset which contains information on 583 patients with Hodgkin’s disease. Within this information is the number of patients (<code>count</code>) with each combination of the histological type of disease (<code>type</code>) and the response to the treatment (<code>rtreat</code>).</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb412-1" tabindex="-1"></a>hodgkins <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">count =</span> <span class="fu">c</span>(<span class="dv">74</span>, <span class="dv">18</span>, <span class="dv">12</span>, <span class="dv">68</span>, <span class="dv">16</span>, <span class="dv">12</span>, <span class="dv">154</span>, <span class="dv">54</span>, <span class="dv">58</span>, </span>
<span id="cb412-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb412-2" tabindex="-1"></a>                                 <span class="dv">18</span>, <span class="dv">10</span>, <span class="dv">44</span>),</span>
<span id="cb412-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb412-3" tabindex="-1"></a>                       <span class="at">type =</span> <span class="fu">c</span>(<span class="st">&quot;Lp&quot;</span>, <span class="st">&quot;Lp&quot;</span>, <span class="st">&quot;Lp&quot;</span>, <span class="st">&quot;Ns&quot;</span>, <span class="st">&quot;Ns&quot;</span>, <span class="st">&quot;Ns&quot;</span>, <span class="st">&quot;Mc&quot;</span>,</span>
<span id="cb412-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb412-4" tabindex="-1"></a>                                <span class="st">&quot;Mc&quot;</span>, <span class="st">&quot;Mc&quot;</span>, <span class="st">&quot;Ld&quot;</span>, <span class="st">&quot;Ld&quot;</span>, <span class="st">&quot;Ld&quot;</span>),</span>
<span id="cb412-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb412-5" tabindex="-1"></a>                       <span class="at">rtreat =</span> <span class="fu">c</span>(<span class="st">&quot;positive&quot;</span>, <span class="st">&quot;partial&quot;</span>, <span class="st">&quot;none&quot;</span>, <span class="st">&quot;positive&quot;</span>,</span>
<span id="cb412-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb412-6" tabindex="-1"></a>                                  <span class="st">&quot;partial&quot;</span>, <span class="st">&quot;none&quot;</span>, <span class="st">&quot;positive&quot;</span>, <span class="st">&quot;partial&quot;</span>,</span>
<span id="cb412-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb412-7" tabindex="-1"></a>                                  <span class="st">&quot;none&quot;</span>, <span class="st">&quot;positive&quot;</span>, <span class="st">&quot;partial&quot;</span>, <span class="st">&quot;none&quot;</span>))</span></code></pre></div>
<p>The information on the patients has been cross-classified, where the covariates <code>type</code> and <code>rtreat</code> are categorical variables with multiple levels each.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb413-1" tabindex="-1"></a><span class="co">#fit a glm to the hodgkins dataset including both covariates in the model</span></span>
<span id="cb413-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb413-2" tabindex="-1"></a>hodgkins_glm1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(count <span class="sc">~</span> type <span class="sc">+</span> rtreat, <span class="at">family =</span> poisson, <span class="at">data =</span> hodgkins)</span>
<span id="cb413-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb413-3" tabindex="-1"></a><span class="fu">summary</span>(hodgkins_glm1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = count ~ type + rtreat, family = poisson, data = hodgkins)
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      2.8251     0.1413  19.993   &lt;2e-16 ***
## typeLp           0.3677     0.1533   2.399   0.0165 *  
## typeMc           1.3068     0.1328   9.837   &lt;2e-16 ***
## typeNs           0.2877     0.1559   1.845   0.0650 .  
## rtreatpartial   -0.2513     0.1347  -1.866   0.0621 .  
## rtreatpositive   0.9131     0.1055   8.659   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 367.247  on 11  degrees of freedom
## Residual deviance:  68.295  on  6  degrees of freedom
## AIC: 143.66
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Alternatively, a generalised linear model can be fitted with both the main effects and an interaction. This model is known as the full or saturated model, where the interaction term can be included in addition to the main effects using a colon <code>:</code> between the variables you wish to include an interaction term for. This method is beneficial for when you just want to include an interaction, not necessarily the corresponding main effects, however, if you want to include both the interaction and corresponding main effects to a model, an asterisk <code>*</code> can be used between the chosen covariates. Both these methods are demonstrated below and return the same model.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb415-1" tabindex="-1"></a><span class="co">#fit the saturated Poisson GLM to the hodgkins dataset with a colon</span></span>
<span id="cb415-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb415-2" tabindex="-1"></a>hodgkins_glm2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(count <span class="sc">~</span> type <span class="sc">+</span> rtreat <span class="sc">+</span> type<span class="sc">:</span>rtreat, <span class="at">family =</span> poisson,</span>
<span id="cb415-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb415-3" tabindex="-1"></a>                     <span class="at">data =</span> hodgkins)</span>
<span id="cb415-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb415-4" tabindex="-1"></a><span class="fu">summary</span>(hodgkins_glm2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = count ~ type + rtreat + type:rtreat, family = poisson, 
##     data = hodgkins)
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)             3.7842     0.1508  25.101  &lt; 2e-16 ***
## typeLp                 -1.2993     0.3257  -3.990 6.62e-05 ***
## typeMc                  0.2763     0.1999   1.382 0.167031    
## typeNs                 -1.2993     0.3257  -3.990 6.62e-05 ***
## rtreatpartial          -1.4816     0.3503  -4.229 2.34e-05 ***
## rtreatpositive         -0.8938     0.2798  -3.195 0.001400 ** 
## typeLp:rtreatpartial    1.8871     0.5115   3.689 0.000225 ***
## typeMc:rtreatpartial    1.4101     0.3981   3.542 0.000397 ***
## typeNs:rtreatpartial    1.7693     0.5182   3.414 0.000640 ***
## typeLp:rtreatpositive   2.7130     0.4185   6.483 9.00e-11 ***
## typeMc:rtreatpositive   1.8703     0.3194   5.856 4.75e-09 ***
## typeNs:rtreatpositive   2.6284     0.4199   6.260 3.86e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 3.6725e+02  on 11  degrees of freedom
## Residual deviance: 1.9540e-14  on  0  degrees of freedom
## AIC: 87.363
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb417-1" tabindex="-1"></a><span class="co">#fit the saturated Poisson GLM to the hodgkins dataset with an asterisk</span></span>
<span id="cb417-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb417-2" tabindex="-1"></a>hodgkins_glm3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(count <span class="sc">~</span> type<span class="sc">*</span>rtreat, <span class="at">family =</span> poisson, <span class="at">data =</span> hodgkins)</span>
<span id="cb417-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb417-3" tabindex="-1"></a><span class="fu">summary</span>(hodgkins_glm3)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = count ~ type * rtreat, family = poisson, data = hodgkins)
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)             3.7842     0.1508  25.101  &lt; 2e-16 ***
## typeLp                 -1.2993     0.3257  -3.990 6.62e-05 ***
## typeMc                  0.2763     0.1999   1.382 0.167031    
## typeNs                 -1.2993     0.3257  -3.990 6.62e-05 ***
## rtreatpartial          -1.4816     0.3503  -4.229 2.34e-05 ***
## rtreatpositive         -0.8938     0.2798  -3.195 0.001400 ** 
## typeLp:rtreatpartial    1.8871     0.5115   3.689 0.000225 ***
## typeMc:rtreatpartial    1.4101     0.3981   3.542 0.000397 ***
## typeNs:rtreatpartial    1.7693     0.5182   3.414 0.000640 ***
## typeLp:rtreatpositive   2.7130     0.4185   6.483 9.00e-11 ***
## typeMc:rtreatpositive   1.8703     0.3194   5.856 4.75e-09 ***
## typeNs:rtreatpositive   2.6284     0.4199   6.260 3.86e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 3.6725e+02  on 11  degrees of freedom
## Residual deviance: 1.9540e-14  on  0  degrees of freedom
## AIC: 87.363
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<p>It can be seen from looking at the results from both the main effects model and the saturated model, particularly the <em>p</em>-values, that the terms in the saturated model are more statistically significant, indicating that the saturated model is a better fit for the data.
Additionally, through testing whether the interaction term is needed, you are able to test whether the covariates are independent from one another or whether they are correlated/associated. In this case, the inclusion of the interaction term improves the model and all interaction terms are statistically significant, therefore there is evidence that the covariates <code>type</code> and <code>rtreat</code> are independent from one another.</p>
<p>If the data is binary, meaning that there are only two possible outcomes, the family can be specified as <code>family = binomial</code> to fit a binomial logistic regression model with a logit link, the default link for a binomial family which assumes that the errors follow a logistic distribution. Alternatively, a probit link can be used, through changing the family argument to be <code>family = binomial(link="probit")</code>, which instead assumes that the errors follow a normal distribution, however, this is used less frequently.</p>
<p>The form of a binomial logistic regression model is given as
<span class="math display">\[Y_i|n_i, p_i \sim Binomial(n_i, p_i), \text{ logit}(p_i)=\log\left(\frac{p_i}{1-p_i}\right).\]</span></p>
<p>This can be seen in the code below using the <code>beetles</code> dataset, <span class="math inline">\(Y_i\)</span> is the number of beetles <code>killed</code>, <span class="math inline">\(n_i\)</span> is the number of beetles <code>exposed</code> and <span class="math inline">\(\boldsymbol{x}_i\)</span> is the <code>dose</code>.</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb419-1" tabindex="-1"></a>beetles <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">dose =</span> <span class="fu">c</span>(<span class="fl">1.6907</span>, <span class="fl">1.7242</span>, <span class="fl">1.7552</span>, <span class="fl">1.7842</span>, <span class="fl">1.8113</span>, <span class="fl">1.8369</span>, </span>
<span id="cb419-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb419-2" tabindex="-1"></a>                             <span class="fl">1.861</span>, <span class="fl">1.8839</span>), </span>
<span id="cb419-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb419-3" tabindex="-1"></a>                      <span class="at">exposed =</span> <span class="fu">c</span>(<span class="dv">59</span>, <span class="dv">60</span>, <span class="dv">62</span>, <span class="dv">56</span>, <span class="dv">63</span>, <span class="dv">59</span>, <span class="dv">62</span>, <span class="dv">60</span>),</span>
<span id="cb419-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb419-4" tabindex="-1"></a>                      <span class="at">killed =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">13</span>, <span class="dv">18</span>, <span class="dv">28</span>, <span class="dv">52</span>, <span class="dv">53</span>, <span class="dv">61</span>, <span class="dv">60</span>))</span></code></pre></div>
<p>There are two ways to fit the binomial logistic regression model. Firstly, is to model the proportion of “successes” (in this example, it is the proportion of beetles killed) and weight by the number of trials (in this example, it is the number of beetles exposed).</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb420-1" tabindex="-1"></a><span class="co">#compute the proportion of beetles killed</span></span>
<span id="cb420-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb420-2" tabindex="-1"></a>beetles<span class="sc">$</span>prop_killed <span class="ot">&lt;-</span> beetles<span class="sc">$</span>killed <span class="sc">/</span> beetles<span class="sc">$</span>exposed</span>
<span id="cb420-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb420-3" tabindex="-1"></a></span>
<span id="cb420-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb420-4" tabindex="-1"></a><span class="co">#fit a binomial logistic regression model</span></span>
<span id="cb420-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb420-5" tabindex="-1"></a>beetles_glm_props <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetles, <span class="at">family =</span> binomial,</span>
<span id="cb420-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb420-6" tabindex="-1"></a>                  <span class="at">weights =</span> exposed)</span>
<span id="cb420-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb420-7" tabindex="-1"></a><span class="fu">summary</span>(beetles_glm_props)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = prop_killed ~ dose, family = binomial, data = beetles, 
##     weights = exposed)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -60.717      5.181  -11.72   &lt;2e-16 ***
## dose          34.270      2.912   11.77   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 284.202  on 7  degrees of freedom
## Residual deviance:  11.232  on 6  degrees of freedom
## AIC: 41.43
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Alternatively, the independent variable can be given as a matrix with two columns, one for the number of “successes” and the other for “failures” (in this example, a success is a beetle killed and a failure is a beetle not killed).</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb422-1" tabindex="-1"></a><span class="co">#fit a binomial logistic regression model with two columns to response</span></span>
<span id="cb422-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb422-2" tabindex="-1"></a>beetles_glm_matrix <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">cbind</span>(killed, exposed <span class="sc">-</span> killed) <span class="sc">~</span> dose, </span>
<span id="cb422-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb422-3" tabindex="-1"></a>                          <span class="at">data =</span> beetles, <span class="at">family =</span> binomial)</span>
<span id="cb422-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb422-4" tabindex="-1"></a><span class="fu">summary</span>(beetles_glm_matrix)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(killed, exposed - killed) ~ dose, family = binomial, 
##     data = beetles)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -60.717      5.181  -11.72   &lt;2e-16 ***
## dose          34.270      2.912   11.77   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 284.202  on 7  degrees of freedom
## Residual deviance:  11.232  on 6  degrees of freedom
## AIC: 41.43
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>As seen from the summaries for the binomial logistic regression models from each approach, the approaches yield identical results, so it is unimportant which approach is taken.</p>
<!-- <div  -->
<!--   class="boxed" style="background-color: lightyellow; text-align: left; padding: 10px;">  -->
<!--   **Exercise:** Fit a linear model of proportion of beetles killed using `dose` as a dependent variable, adding weights for the number of beetles exposed in each group and plot the results. Does this model fit the data well? -->
<!-- </div> -->
</div>
<div id="model-predictions" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Model predictions<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#model-predictions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="predictions-with-the-formula-and-coefficients" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Predictions with the formula and coefficients<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#predictions-with-the-formula-and-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Values of the dependent variable can be predicted through inputting the coefficient estimates found from the model summaries into the model formulae, given values of the independent variable(s).</p>
<p>To demonstrate predictions using just the model formula and the resulting coefficient estimates, firstly the simple linear regression model with the <code>birth</code> dataset will be used. As a reminder, the model was given as follows, fitted with the <code>lm()</code> function in <code>R</code>.</p>
<p><span class="math display">\[\text{Weight}_i = \beta_0 + \beta_1\text{Age}_i + \epsilon_i\]</span></p>
<p>The coefficients from the linear model given by the <code>summary()</code> function can then be used to predict the value of the birth weight for a baby at a given gestational age.</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb424-1" tabindex="-1"></a><span class="co">#summary of the birth weight simple linear regression model</span></span>
<span id="cb424-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb424-2" tabindex="-1"></a><span class="fu">summary</span>(birth_simple_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Weight ~ Age, data = birth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -262.03 -158.29    8.35   88.15  366.50 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -1485.0      852.6  -1.742   0.0955 .  
## Age            115.5       22.1   5.228 3.04e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 192.6 on 22 degrees of freedom
## Multiple R-squared:  0.554,  Adjusted R-squared:  0.5338 
## F-statistic: 27.33 on 1 and 22 DF,  p-value: 3.04e-05</code></pre>
<p>Given the coefficient estimates from the model, the birth weight of a baby for a given gestational age can be predicted using the following formula.</p>
<p><span class="math display">\[ \text{Weight}_i = -1485.0 + 115.5 \times \text{Age}_i\]</span></p>
<p>Therefore, for example, a baby of gestational age 37.5 weeks, the birth weight is predicted as <span class="math display">\[Weight_i=-1485.0 + 115.5 \times 37.5 = 2846.25g.\]</span></p>
<p>This method of prediction does not just work on simple linear regression models but can be used for regression modelling in general. For example, the multiple regression model for the <code>birth</code> dataset <code>birth_multi_lm1</code>, which has the following formula.</p>
<p><span class="math display">\[ Weight_i =\beta_0 + \beta_1 Sex_i + \beta_2 Age_i + \epsilon_i\]</span></p>
<p>If for example, you wanted to predict the birth weight of a baby girl at a gestational age of 38 weeks, you would use the following formula.</p>
<p><span class="math display">\[Weight = -1447.24 -163.04\times 1+120.89\times 38 = 2983.54g\]</span></p>
<div class="boxed" style="background-color: lightyellow; text-align: left; padding: 10px;">
<p><strong>Exercise:</strong> What is the expected birth weight for a baby boy at a gestational age of 39.5 weeks?</p>
</div>
<p>This method of prediction also works with generalised linear models using the results from a model fitted with the <code>glm()</code> function. To demonstrate this, the Poisson GLM fitted to the <code>ccancer</code> dataset exploring the relationship between gender and counts of cancer deaths is used. As a reminder, the model summary output is as follows.</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb426-1" tabindex="-1"></a><span class="co">#GLM for ccancer data gender vs count</span></span>
<span id="cb426-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb426-2" tabindex="-1"></a><span class="fu">summary</span>(ccancer_glm2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Count ~ Gender, family = &quot;poisson&quot;, data = ccancer)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) 6.621406   0.009422  702.77   &lt;2e-16 ***
## GenderM     0.157000   0.012831   12.24   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 35187  on 29  degrees of freedom
## Residual deviance: 35037  on 28  degrees of freedom
## AIC: 35232
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>Using the resulting coefficient estimates from this model in the formula below to estimate the count of cancer deaths for a given gender. Since the log-link was used for this model, the coefficients require exponentiation in order to transform the log-count to just the count.</p>
<p><span class="math display">\[
\begin{aligned}
\log(\hat{\mu}) &amp;= 6.621406 + 0.157000 \times x_1 \\
\hat{\mu} &amp;= \exp( 6.621406 + 0.157000 \times x_1)
\end{aligned}
\]</span>
where <span class="math inline">\(x_1=0\)</span> if the individual is female and <span class="math inline">\(x_1=1\)</span> if the individual is male.</p>
<p>Using this formula, the expected count of cancer deaths for women in from the dataset is <span class="math inline">\(\hat{\mu}=exp( 6.621406 + 0.157000)=879\)</span> and for men is <span class="math inline">\(\hat{\mu}=exp( 6.621406)=751\)</span>.</p>
</div>
<div id="predictions-with-functions" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Predictions with functions<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#predictions-with-functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As mentioned in previous sections, you can also predict values using functions, particularly the <code>predict()</code> function. To use this, include the model you wish to predict from as an argument, in addition to values of data you wish to predict the values of the dependent variable from as <code>newdata</code>.</p>
<p>The use of this function is demonstrated in the code below, where for the <code>birth</code> dataset, birth weight is predicted for a range of values from the quadratic model, <code>birth_quad_lm2</code>, fitted with the <code>lm()</code> function.</p>
<p>Firstly, a new dataset needs to be created. This dataset needs to contain the value(s) for which the dependent variable will be predicted using. If for example you wish to estimate the birth weight of a baby with gestational ages 36.5, 37.5 and 38.5, you can create a new dataset containing just these values, as in the code given below.</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb428-1" tabindex="-1"></a><span class="co">#made a new dataset</span></span>
<span id="cb428-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb428-2" tabindex="-1"></a>birth.new1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Age =</span> <span class="fu">c</span>(<span class="fl">36.5</span>, <span class="fl">37.5</span>, <span class="fl">38.5</span>))</span>
<span id="cb428-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb428-3" tabindex="-1"></a>birth.new1</span></code></pre></div>
<pre><code>##    Age
## 1 36.5
## 2 37.5
## 3 38.5</code></pre>
<p>Then, the predict function can be used, including the name of the model, <code>birth_quad_lm2</code>, and the new dataset to predict from, <code>birth.new1</code>.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb430-1" tabindex="-1"></a><span class="co">#use the predict function</span></span>
<span id="cb430-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb430-2" tabindex="-1"></a>birth_predict_quad1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(birth_quad_lm2, <span class="at">newdata =</span> birth.new1)</span></code></pre></div>
<p>The values of these predictions can be given as a table for ease of viewing using the <code>data.table()</code> function in the <code>data.table</code> package. To use this function, include the variables you wish to display as arguments and assign the variables names in the function for clarity.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb431-1" tabindex="-1"></a><span class="co">#install data.table package</span></span>
<span id="cb431-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb431-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;data.table&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb432-1" tabindex="-1"></a><span class="co">#load the data.table package</span></span>
<span id="cb432-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb432-2" tabindex="-1"></a><span class="fu">library</span>(data.table)</span></code></pre></div>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb433-1" tabindex="-1"></a><span class="co">#create a table for the predictions</span></span>
<span id="cb433-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb433-2" tabindex="-1"></a><span class="fu">data.table</span>(birth.new1, <span class="at">Weight =</span> birth_predict_quad1)</span></code></pre></div>
<pre><code>##      Age   Weight
##    &lt;num&gt;    &lt;num&gt;
## 1:  36.5 2733.896
## 2:  37.5 2832.927
## 3:  38.5 2943.894</code></pre>
<p>Alternatively, a range of values can be given as the new dataset for assessing the fit of a given model. To demonstrate this, the birth weight will be predicted for a sequence of gestational age values, starting from the minimum observed age to the maximum observed age with 50 values in total.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb435-1" tabindex="-1"></a><span class="co">#made a new dataset</span></span>
<span id="cb435-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb435-2" tabindex="-1"></a>birth.new2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Age=</span><span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">min</span>(birth<span class="sc">$</span>Age), </span>
<span id="cb435-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb435-3" tabindex="-1"></a>                                   <span class="at">to =</span> <span class="fu">max</span>(birth<span class="sc">$</span>Age),</span>
<span id="cb435-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb435-4" tabindex="-1"></a>                                   <span class="at">length.out =</span> <span class="dv">50</span>))</span>
<span id="cb435-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb435-5" tabindex="-1"></a><span class="fu">head</span>(birth.new2)</span></code></pre></div>
<pre><code>##        Age
## 1 35.00000
## 2 35.14286
## 3 35.28571
## 4 35.42857
## 5 35.57143
## 6 35.71429</code></pre>
<p>Then, the predict function can be used, including the name of the model, <code>birth_quad_lm2</code>, and the new dataset to predict from, <code>birth.new2</code>.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb437-1" tabindex="-1"></a><span class="co">#use the predict function</span></span>
<span id="cb437-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb437-2" tabindex="-1"></a>birth_predict_quad2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(birth_quad_lm2, <span class="at">newdata =</span> birth.new2)</span>
<span id="cb437-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb437-3" tabindex="-1"></a>birth_predict_quad2</span></code></pre></div>
<pre><code>##        1        2        3        4        5        6        7        8        9       10       11 
## 2607.732 2618.590 2629.693 2641.038 2652.627 2664.460 2676.537 2688.857 2701.421 2714.228 2727.279 
##       12       13       14       15       16       17       18       19       20       21       22 
## 2740.574 2754.112 2767.894 2781.919 2796.188 2810.701 2825.457 2840.457 2855.700 2871.187 2886.918 
##       23       24       25       26       27       28       29       30       31       32       33 
## 2902.892 2919.110 2935.572 2952.277 2969.226 2986.418 3003.854 3021.534 3039.457 3057.624 3076.034 
##       34       35       36       37       38       39       40       41       42       43       44 
## 3094.688 3113.586 3132.727 3152.112 3171.741 3191.613 3211.729 3232.088 3252.691 3273.537 3294.628 
##       45       46       47       48       49       50 
## 3315.961 3337.539 3359.360 3381.424 3403.733 3426.284</code></pre>
<p>To demonstrate the fit of this model visually, create a plot depicting the relationship between the two variables being explored, with the predicted values added to the plot. If the model fits the data well, the predicted values line should match the trend of the data well.</p>
<p>For comparative purposes, a line is added for the simple linear regression for this data to demonstrate the difference in fit of the two models and how the quadratic model fits the data better.</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-1" tabindex="-1"></a><span class="co">#basic plot for relationship between variables </span></span>
<span id="cb439-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-2" tabindex="-1"></a><span class="fu">plot</span>(Weight <span class="sc">~</span> Age, <span class="at">data =</span> birth)</span>
<span id="cb439-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-3" tabindex="-1"></a><span class="co">#add lines for each of the sets of predicted values</span></span>
<span id="cb439-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-4" tabindex="-1"></a><span class="fu">lines</span>(birth_predict_quad2 <span class="sc">~</span> birth.new2<span class="sc">$</span>Age, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb439-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-5" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">predict</span>(birth_simple_lm, <span class="at">newdata =</span> birth.new2) <span class="sc">~</span> birth.new2<span class="sc">$</span>Age, </span>
<span id="cb439-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-6" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb439-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-7" tabindex="-1"></a><span class="co">#add a legend for clarity</span></span>
<span id="cb439-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-8" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Quadratic&quot;</span>, <span class="st">&quot;Linear&quot;</span>),</span>
<span id="cb439-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb439-9" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/predict%20plot-1.png" width="672" /></p>
<p>As with the other method for predictions, this method also works with generalised linear models fitted with the <code>glm()</code> function. To demonstrate this, the binomial logistic regression model fitted to the <code>beetles</code> dataset is used.</p>
<p>For example, predicting in the same way as before but for doses of 1.7 and 1.8, the following code would be used.</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb440-1" tabindex="-1"></a><span class="co">#create a new data frame to predict with doses of 1.7 and 1.8</span></span>
<span id="cb440-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb440-2" tabindex="-1"></a>beetles_newdata1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">dose =</span> <span class="fu">c</span>(<span class="fl">1.7</span>, <span class="fl">1.8</span>))</span>
<span id="cb440-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb440-3" tabindex="-1"></a></span>
<span id="cb440-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb440-4" tabindex="-1"></a><span class="co">#predict function</span></span>
<span id="cb440-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb440-5" tabindex="-1"></a><span class="fu">predict</span>(beetles_glm_props, <span class="at">newdata =</span> beetles_newdata1)</span></code></pre></div>
<pre><code>##          1          2 
## -2.4579008  0.9691318</code></pre>
<p>However, these predicted values are not what is expected for the probability of death. This is due to the default <code>type</code> of the predict function being <code>type = link</code> which returns predicted values of <span class="math inline">\(\text{logit}(p(x))\)</span>. To return the predicted values of the probabilities instead, <code>type = "response"</code> needs to be added as an argument, as follows.</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb442-1" tabindex="-1"></a><span class="co">#predict the probabilities</span></span>
<span id="cb442-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb442-2" tabindex="-1"></a>beetles_predict_glm <span class="ot">&lt;-</span> <span class="fu">predict</span>(beetles_glm_props, <span class="at">newdata =</span> beetles_newdata1,</span>
<span id="cb442-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb442-3" tabindex="-1"></a>                               <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb442-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb442-4" tabindex="-1"></a>beetles_predict_glm</span></code></pre></div>
<pre><code>##          1          2 
## 0.07886269 0.72494641</code></pre>
<p>These predictions are much more what you would expect for probabilities, given that they are between 0 and 1. For more information on probability, see Module 5.</p>
<p>The fit of this GLM can be assessed in the same way as for the models fitted using the <code>lm()</code> function, through predicting values for a wider range of values and fitting the predicted values to a plot. To demonstrate the goodness-of-fit of the GLM and why it is important to fit a GLM over a simple linear regression model, a linear model is fitted with weights added for the number of beetles exposed, with the line of best fit of this linear regression model also added to the plot.</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-1" tabindex="-1"></a><span class="co">#fit a simple linear regression model for the beetles data</span></span>
<span id="cb444-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-2" tabindex="-1"></a>beetles_simple_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(prop_killed <span class="sc">~</span> dose , <span class="at">data =</span> beetles, <span class="at">weights =</span> exposed)</span>
<span id="cb444-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-3" tabindex="-1"></a></span>
<span id="cb444-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-4" tabindex="-1"></a><span class="co">#create a new dataset</span></span>
<span id="cb444-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-5" tabindex="-1"></a>beetles_newdata2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">dose =</span> <span class="fu">seq</span>(<span class="fu">min</span>(beetles<span class="sc">$</span>dose) <span class="sc">-</span> .<span class="dv">2</span>, </span>
<span id="cb444-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-6" tabindex="-1"></a>                                          <span class="fu">max</span>(beetles<span class="sc">$</span>dose) <span class="sc">+</span> .<span class="dv">2</span>,</span>
<span id="cb444-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-7" tabindex="-1"></a>                                          <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb444-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-8" tabindex="-1"></a></span>
<span id="cb444-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-9" tabindex="-1"></a><span class="co">#plot the relationship between the dosage and proportion of beetles killed</span></span>
<span id="cb444-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-10" tabindex="-1"></a><span class="fu">plot</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetles, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">1.5</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">1.6</span>, <span class="dv">2</span>),</span>
<span id="cb444-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-11" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Proportion killed&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;dose&quot;</span>)</span>
<span id="cb444-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-12" tabindex="-1"></a><span class="co">#add a line of best fit for the simple linear regression model</span></span>
<span id="cb444-13"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-13" tabindex="-1"></a><span class="fu">abline</span>(beetles_simple_lm, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb444-14"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-14" tabindex="-1"></a><span class="co">#add a line for the predicted values from the GLM</span></span>
<span id="cb444-15"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-15" tabindex="-1"></a><span class="fu">lines</span>(beetles_newdata2<span class="sc">$</span>dose,  <span class="fu">predict</span>(beetles_glm_props, </span>
<span id="cb444-16"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-16" tabindex="-1"></a>                                      <span class="at">newdata =</span> beetles_newdata2,</span>
<span id="cb444-17"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-17" tabindex="-1"></a>                                      <span class="at">type =</span> <span class="st">&quot;response&quot;</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb444-18"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-18" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb444-19"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-19" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Linear model&quot;</span>, <span class="st">&quot;Logistic GLM&quot;</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb444-20"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb444-20" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/beetles%20glm%20fit%20plot-1.png" width="672" /></p>
<p>It is clear to see from this plot that the GLM fits much better than the linear model, given that for the linear model, at a dosage of 1.6, the proportion of beetles killed is actually negative, and that for a dosage of 1.9, the proportion of beetles killed is greater than 1, neither are logistically possible proportions. However, for the GLM, the proportion of beetles killed is always between the values of 0 and 1. For example, for the GLM, at a dosage of 1.6, instead of having a negative proportion, the proportion is just very close to 0 meaning that it is unlikely for any beetles to be killed, with the opposite occurring at a dosage of 1.9 where the proportion is very close to 1. Beyond the linear model not being realistically feasible for certain values of dosage, the line of best fit also does not fit the trend of the observed points as well as the GLM.</p>
</div>
</div>
<div id="model-selection" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Model selection<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#model-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="accuracy-and-precision" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Accuracy and precision<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#accuracy-and-precision" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the main goals when modelling is to produce the best fitting models with the least amount of error. One type of error is observational error, made up of <strong>accuracy</strong> and <strong>precision</strong>, and can be used to measure results. Accuracy can be defined as the distance between the observed/estimated results and the true values, and precision can be defined as the spread of the observed/estimated results. In an ideal situation, you would want the observations to be close together and close to the true values.</p>
<p>A visual representation of accuracy and precision can be seen in the figure below, where the graphs depict the 4 different combinations of the observational error types.</p>
<div class="figure" style="text-align: center">
<img src="figures/4_images/accuracy%20and%20precision.png" alt="Visual examples of accuracy and precision" width="80%" />
<p class="caption">
(#fig:image accuracy and precision)Visual examples of accuracy and precision
</p>
</div>
<p>There are multiple ways of testing the accuracy and precision of a model, for example the Akaike information criterion which assesses the goodness-of-fit of a model, which could be described as assessing the comparative accuracy when paired with at least one other model. This method and others are be discussed in this module.</p>
</div>
<div id="akaike-information-criterion" class="section level3 hasAnchor" number="4.6.2">
<h3><span class="header-section-number">4.6.2</span> Akaike information criterion<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#akaike-information-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>Akaike information criterion</strong> (<strong>AIC</strong>) estimates the proportional quality of one model compared to another through assessing the quality predictions. It uses the bias-variance trade-off to identify which model is preferred for the given data, taking into consideration the accuracy of the model’s predictions via the log-likelihood and the complexity of the model via a penalty term for the number of parameters within the model. Formally, the AIC is given as
<span class="math display">\[\text{AIC}=-2\ell + 2p,\]</span>
where <span class="math inline">\(\ell\)</span> is the log-likelihood of a model and <span class="math inline">\(p\)</span> is the number of parameters in the model.</p>
<p>Given that the AIC statistic is essentially a measure of both bias and variance, when comparing two models fitted to the same data, the model with the smallest AIC value is the better fitting model for the data.</p>
<p>To find the AIC statistic in <code>R</code> for a given model, the value can found using the function <code>AIC()</code> with the desired model included as an argument, or if fitting a GLM, the function <code>summary()</code> provides the AIC statistic in the output.</p>
<div class="figure" style="text-align: center">
<img src="figures/4_images/AIC%20summary.png" alt="Reading the AIC statistic from a GLM sumamry" width="80%" />
<p class="caption">
(#fig:image AIC)Reading the AIC statistic from a GLM sumamry
</p>
</div>
<p>To demonstrate the <code>AIC()</code> function, the AIC statistics can be found for both the linear and quadratic regression models for the birth weight data as follows.</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb445-1" tabindex="-1"></a><span class="co">#AIC value of linear regression model</span></span>
<span id="cb445-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb445-2" tabindex="-1"></a><span class="fu">AIC</span>(birth_simple_lm)</span></code></pre></div>
<pre><code>## [1] 324.53</code></pre>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb447-1" tabindex="-1"></a><span class="co">#AIC value of quadratic regression model</span></span>
<span id="cb447-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb447-2" tabindex="-1"></a><span class="fu">AIC</span>(birth_multi_lm1)</span></code></pre></div>
<pre><code>## [1] 321.3909</code></pre>
<p>The AIC statistic for the more complex model is smaller, supporting previously made conclusions that the multiple regression model is a better fitting regression model for the birth weight data compared to the simple linear regression model.</p>
</div>
<div id="bayesian-information-criterion" class="section level3 hasAnchor" number="4.6.3">
<h3><span class="header-section-number">4.6.3</span> Bayesian information criterion<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#bayesian-information-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>Bayesian information criterion</strong> (<strong>BIC</strong>), is an alternative information to the AIC,and also uses the bias-variance trade-off. Unlike the AIC however, it uses the number of observations in the dataset in the computation of the penalty term. As a result of this difference, the BIC has a larger penalty term than the AIC and penalises complex models more than the AIC. The formula for the BIC is given below.</p>
<p><span class="math display">\[\text{BIC}=-2\ell + p \times \log(n),\]</span>
where <span class="math inline">\(\ell\)</span> is the log-likelihood of a model, <span class="math inline">\(p\)</span> is the number of parameters in the model and <span class="math inline">\(n\)</span> is the number of observations in the dataset.</p>
<p>To compute the BIC statistic in <code>R</code> for a given model, the <code>BIC()</code> function can be used in much the same way as for computing the AIC statistic. Demonstrated below with the birth weight data.</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb449-1" tabindex="-1"></a><span class="co">#BIC value of linear regression model</span></span>
<span id="cb449-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb449-2" tabindex="-1"></a><span class="fu">BIC</span>(birth_simple_lm)</span></code></pre></div>
<pre><code>## [1] 328.0642</code></pre>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb451-1" tabindex="-1"></a><span class="co">#BIC value of quadratic regression model</span></span>
<span id="cb451-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb451-2" tabindex="-1"></a><span class="fu">BIC</span>(birth_multi_lm1)</span></code></pre></div>
<pre><code>## [1] 326.1031</code></pre>
<p>These results agree with previous conclusions, that the more complex model, the multuple regression model, fits the data best given that the BIC value for this model is smaller.</p>
<p>Given the differences in the AIC and BIC, for a smaller dataset, the AIC might be more appropriate since it doesn’t penalise the more complex models as harshly. However, if the dataset is large, then the BIC may be more appropriate for preventing overfitting.</p>
</div>
<div id="r-squared-statistic" class="section level3 hasAnchor" number="4.6.4">
<h3><span class="header-section-number">4.6.4</span> R-squared statistic<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#r-squared-statistic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <span class="math inline">\(R^2\)</span> or <strong>R-squared</strong> statistic, also called the <strong>coefficient of determination</strong>, is a measure of goodness-of-fit of a given regression model through measuring the proportion of variance from the dependent variable that is explained by the independent variable(s).</p>
<p>There are two main components of the R-squared statistic, the sum of squares of the residuals and total sum of squares, both of which measure variation in the data, where squared values are used to account for fitted values being both above and below the true values.</p>
<p>To compute these measures of variation, let <span class="math inline">\(\boldsymbol{y}=y_1,...,y_n\)</span> be a dataset with corresponding fitted values <span class="math inline">\(\boldsymbol{\hat{y}}=\hat{y}_1,...,\hat{y}_n,\)</span>. The residuals can be described as the estimates of unobservable error, or the difference between the observed and fitted values, then given as <span class="math inline">\(r_i= y_i - \hat{y}_i\)</span>.</p>
<p>The sum of squares of the residuals (the sum of the squared distance between the observed values and the fitted values) is computed through summing the squared values of the residuals as follows:
<span class="math display">\[RSS = \sum_{i=1}^n (y_i-\hat{y}_i)^2 = \sum_{i=1}^n r_i^2.\]</span></p>
<p>The total sum of squares (the sum of the squared distance between the observed values and the overall mean) follows the same structure as follows:
<span class="math display">\[TSS = \sum_{i=1}^n (y_i - \bar{y})^2,\]</span>
where <span class="math inline">\(\bar{y}= \sum_{i=1}^n y_i\)</span> is the overall mean of the observed values.</p>
<p>The R-squared statistic is then computed using the following formula:
<span class="math display">\[ R^2 = 1-\frac{RSS}{TSS},\]</span>
and takes a value between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>.</p>
<p>Given that the better fitting a model is, the smaller the difference between the observed and fitted values is and hence the smaller the RSS value is, a better fitting model will have a larger R-squared value, with the perfectly fitting model having an RSS value of 0 and an R-squared value of 1. Therefore, when comparing the goodness-of-fit of two or more models, the model with the R-squared statistic value closest to 1 is the better fitting model for the given data.</p>
<p>The values for the R-squared statistics from models in <code>R</code> can be found directly through using the <code>summary()</code> function using the code <code>summary()$r.squared</code>.</p>
<p>For example, this function can be used with the linear and quadratic regression models for the welding data to find out which model fits the data better.</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb453-1" tabindex="-1"></a><span class="co">#R-squared statistic for the linear regression model</span></span>
<span id="cb453-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb453-2" tabindex="-1"></a><span class="fu">summary</span>(weld_simple_lm)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9622726</code></pre>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb455-1" tabindex="-1"></a><span class="co">#R-squared statistic for the quadratic regression model</span></span>
<span id="cb455-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb455-2" tabindex="-1"></a><span class="fu">summary</span>(weld_quad_lm)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9761461</code></pre>
<p>Whilst both of the R-squared statistics are high, the value for the quadratic model is slightly higher, supporting previous conclusions that the quadratic model fits the data better and hence the quadratic model should be used.</p>
</div>
<div id="analysis-of-variance" class="section level3 hasAnchor" number="4.6.5">
<h3><span class="header-section-number">4.6.5</span> Analysis of variance<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#analysis-of-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Analysis of variance (<strong>ANOVA</strong>) is a statistical test used to assess the relationship between the dependent variable and one or more independent variables.</p>
<p>To produce an ANOVA table, the function <code>anova()</code> can be used in <code>R</code>. If only one model is given as the argument, it will indicate as to whether the terms in the given model are significant. This is demonstrated below with the simple linear model for the <code>welding</code> data.</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb457-1" tabindex="-1"></a><span class="co">#produce an ANOVA table for simple model for welding data</span></span>
<span id="cb457-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb457-2" tabindex="-1"></a><span class="fu">anova</span>(weld_simple_lm)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Diameter
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Current    1 19.6203 19.6203  484.61 5.529e-15 ***
## Residuals 19  0.7692  0.0405                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="figure" style="text-align: center">
<img src="figures/4_images/anova1.png" alt="Understanding the ANOVA table" width="80%" />
<p class="caption">
(#fig:image ANOVA 1)Understanding the ANOVA table
</p>
</div>
<p>It can be seen from the results that the <em>p</em>-value is very small, and much smaller than the standard 5% significance level indicating that current does have an impact on diameter, and therefore the term for current should remain in the model.</p>
<p>However, you can also test which model fits the data best by including multiple models as arguments. This is demonstrated in the <code>R</code> code below, with a comparison between the simple linear model and quadratic model for the <code>welding</code> dataset.</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb459-1" tabindex="-1"></a><span class="co">#produce an ANOVA table for the simple and quadratic models for the welding data</span></span>
<span id="cb459-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb459-2" tabindex="-1"></a><span class="fu">anova</span>(weld_simple_lm,weld_quad_lm)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Diameter ~ Current
## Model 2: Diameter ~ Current + I(Current^2)
##   Res.Df     RSS Df Sum of Sq      F   Pr(&gt;F)   
## 1     19 0.76924                                
## 2     18 0.48637  1   0.28287 10.469 0.004589 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="figure" style="text-align: center">
<img src="figures/4_images/anova2.png" alt="Understanding the ANOVA table" width="80%" />
<p class="caption">
(#fig:image ANOVA 2)Understanding the ANOVA table
</p>
</div>
<p>The <em>p</em>-value given in the ANOVA table is smaller than <span class="math inline">\(0.05\)</span>, which is the typical significance value chosen, indicating that there is evidence that the addition of the quadratic term is significant. Therefore, there is evidence that the quadratic model better explains the relationship between the diameter and current comparatively to the simple model.</p>
</div>
<div id="likelihood-ratio-testing" class="section level3 hasAnchor" number="4.6.6">
<h3><span class="header-section-number">4.6.6</span> Likelihood ratio testing<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#likelihood-ratio-testing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Likelihood ratio testing can be used to compare the fit of two models when the models are nested. In other words, if one model is a special case of the other where at least one parameter is removed from the model. The likelihood ratio test (LRT) helps to decide whether to reject the null hypothesis or not where the null hypothesis assumes that the nested model is at least as good as the more complex model.</p>
<p>The likelihood ratio test (LRT) statistic can be computed using the following formula
<span class="math display">\[ \lambda = - 2 \times (\ell(\text{model 1}) - \ell(\text{model 2})),\]</span>
where model 1 is nested in model 2 and <span class="math inline">\(\hat{\ell}()\)</span> is the log-likelihood for the model given in the brackets.</p>
<p>To perform the likelihood ratio test, a constant, <span class="math inline">\(c\)</span>, is chosen to determine the significance level of the test. If the corresponding <em>p</em>-value to <span class="math inline">\(\lambda\)</span> is less than <span class="math inline">\(c\)</span>, then there is evidence to reject the null hypothesis and the complex model is preferred, otherwise, if the <em>p</em>-value is greater than or equal to <span class="math inline">\(c\)</span>, there is evidence to not reject the null hypothesis and the nested model is preferred.</p>
<p>The LRT can be conducted manually, through first computing the value of <span class="math inline">\(\lambda\)</span> through using the function <code>logLik()</code> in the equation with an argument for the chosen model to compute the log-likelihood of the chosen model.</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb461-1" tabindex="-1"></a><span class="co">#compute lambda</span></span>
<span id="cb461-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb461-2" tabindex="-1"></a>llmod1 <span class="ot">&lt;-</span> <span class="fu">logLik</span>(birth_simple_lm)</span>
<span id="cb461-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb461-3" tabindex="-1"></a>llmod2 <span class="ot">&lt;-</span> <span class="fu">logLik</span>(birth_multi_lm1)</span>
<span id="cb461-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb461-4" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>(llmod1 <span class="sc">-</span> llmod2)</span></code></pre></div>
<p>The corresponding <em>p</em>-value can then be computed through using the function <code>pchisq()</code> which computes the chi-squared distribution function for the arguments included. In this case, to compute the <em>p</em>-value, input the value of <span class="math inline">\(\lambda\)</span>, the degrees of freedom (the difference between the degrees of freedom for the nested and complex models, given by the <code>logLik()</code> function) and set <code>lower.tail = FALSE</code> as arguments.</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb462-1" tabindex="-1"></a><span class="co">#compute the corresponding p-value</span></span>
<span id="cb462-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb462-2" tabindex="-1"></a><span class="fu">pchisq</span>(lambda[<span class="dv">1</span>], <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.02339251</code></pre>
<p>Given that the resulting <em>p</em>-value is less than <span class="math inline">\(0.05\)</span>, the most common significance level, there is evidence that the more complex model is preferred and that the null hypothesis should be rejected.</p>
<p>Alternatively, the function <code>lrtest()</code> within the package <code>lmtest</code> can be used to perform a likelihood ratio test. An example of this with the <code>birth</code> dataset is as follows.</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb464-1" tabindex="-1"></a><span class="co">#install lmtest package</span></span>
<span id="cb464-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb464-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;lmtest&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb465-1" tabindex="-1"></a><span class="co">#load the lmtest package</span></span>
<span id="cb465-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb465-2" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span></code></pre></div>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb466-1" tabindex="-1"></a><span class="co">#perform a likelihood ratio test on the simple and multiple regression models</span></span>
<span id="cb466-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb466-2" tabindex="-1"></a><span class="fu">lrtest</span>(birth_simple_lm, birth_multi_lm1)</span></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: Weight ~ Age
## Model 2: Weight ~ Sex + Age
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)  
## 1   3 -159.26                       
## 2   4 -156.69  1 5.1391    0.02339 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>It can be seen that the results from the function <code>lrtest()</code> are the same as computing the LRT manually, with the <em>p</em>-values being the same. Once again, there is therefore evidence that the null hypothesis should be rejected and that the more complex, multiple regression model is preferred, supporting the evidence of the AIC results.</p>
<p>The final most common way that a LRT can be done in <code>R</code> is through using the <code>anova()</code> function again, but this time specifying <code>test = "LRT"</code> as an additional argument.</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb468-1" tabindex="-1"></a><span class="co">#likelihood ratio test with anova</span></span>
<span id="cb468-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb468-2" tabindex="-1"></a><span class="fu">anova</span>(birth_simple_lm, birth_multi_lm1, <span class="at">test =</span> <span class="st">&quot;LRT&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Weight ~ Age
## Model 2: Weight ~ Sex + Age
##   Res.Df    RSS Df Sum of Sq Pr(&gt;Chi)  
## 1     22 816074                        
## 2     21 658771  1    157304  0.02514 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This method is conducted slightly differently, hence the slight variation in the <em>p</em>-value, however, the test is also valid and also indicates that the more complex model is preferred.</p>
</div>
</div>
<div id="stepwise-regression" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Stepwise regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#stepwise-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is always important to find out which model fits the data best. When the data only has one or two covariates, using the methods discussed so far this module, it can be a simple process of fitting each of the models and using the evaluation methods to select the best fitting model. However, once the data has more than a couple covariates available, this process becomes more lengthy. This is when stepwise regression comes in useful, although it does not guarantee to select the best model.</p>
<p>This regression is a step-by-step iterative regression that looks at how the fit of a model changes when a variable is added or removed (depending on which direction you go in), testing the significance of the variable, in an automated process to select the best model with the data available. There are three approaches that can be taken with stepwise regression, the first being the way that people typically take manually and that is <strong>forward stepwise regression</strong>. For the forward approach, the process starts with the intercept-only model, adding one term at a time, testing its significance and keeping that term in the model if it is significant. The second approach is <strong>backward stepwise regression</strong>. For the backward approach, the same idea is used but the process starts with the saturated (full) model, removing terms one at a time and testing whether that term was significant through its impact on the model and the model’s fit. Finally is the <strong>bidirectional</strong>, or <strong>both-ways stepwise regression</strong>, which is a combination of both forward and backward regression to test which terms should be included or excluded. This is done by starting with the intercept-only model and adding sequentially adding terms that are deemed statistically significant, and after each new term is added, any terms which are no longer statistically significant are removed.</p>
<p>There are multiple ways of conducting stepwise regression in <code>R</code>, however, the most common approach is to use either the function <code>stepAIC()</code> from the <code>MASS</code> package or the function <code>step()</code> from the <code>stats</code> package, both functions used in the same way (although <code>step()</code> is a simplified version of <code>stepAIC()</code>). These methods of stepwise regression use the AIC by default to choose the best fitting model, with a model (either a <code>lm()</code> or <code>glm()</code> object) inputted as the object argument and the direction used chosen by adding the argument <code>direction =</code> and inputting one of <code>"both"</code>, <code>"backward"</code> or <code>"forward"</code> as the direction of choice.</p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb470-1" tabindex="-1"></a><span class="co">#install MASS package</span></span>
<span id="cb470-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb470-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;MASS&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb471-1" tabindex="-1"></a><span class="co">#load the MASS package</span></span>
<span id="cb471-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb471-2" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code></pre></div>
<p>To fit the full or saturated model in <code>R</code>, instead of needing to type out each of the terms manually, after the tilde (<code>~</code>), you can put a full stop (<code>.</code>) in place of the terms which will add main effects for each covariate available in the data.</p>
<p>The <code>mtcars</code> dataset from the <code>datasets</code> package used introduced in Module 2 will be used to demonstrate the different approaches to stepwise regression given that there are many covariates available in the data. To find out more about the dataset itself, search for the <code>mtcars</code> help file with <code>?mtcars</code>.</p>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb472-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-1" tabindex="-1"></a><span class="co">#&#39;mtcars&#39; is a data set available in the &#39;datasets&#39; package with data on </span></span>
<span id="cb472-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-2" tabindex="-1"></a><span class="co">#11 different aspects of auto mobiles for 32 auto mobiles from the 1974 Motor </span></span>
<span id="cb472-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-3" tabindex="-1"></a><span class="co">#Trend US magazine</span></span>
<span id="cb472-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-4" tabindex="-1"></a><span class="fu">library</span>(datasets)</span>
<span id="cb472-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-5" tabindex="-1"></a></span>
<span id="cb472-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-6" tabindex="-1"></a><span class="co">#information on the dataset in the &#39;Help&#39; pane</span></span>
<span id="cb472-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-7" tabindex="-1"></a>?mtcars</span>
<span id="cb472-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-8" tabindex="-1"></a></span>
<span id="cb472-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-9" tabindex="-1"></a><span class="co">#load data and assign to &#39;cars_data&#39;</span></span>
<span id="cb472-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb472-10" tabindex="-1"></a>cars_data <span class="ot">&lt;-</span> mtcars</span></code></pre></div>
<div id="forward-stepwise-regression" class="section level3 hasAnchor" number="4.7.1">
<h3><span class="header-section-number">4.7.1</span> Forward stepwise regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#forward-stepwise-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To perform forward stepwise regression, you need to start from the intercept-only model as terms are added sequentially. Therefore, the first step is to fit the intercept-only model to the data.</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb473-1" tabindex="-1"></a><span class="co">#fit the saturated model</span></span>
<span id="cb473-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb473-2" tabindex="-1"></a>cars_initial <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> cars_data)</span>
<span id="cb473-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb473-3" tabindex="-1"></a><span class="fu">summary</span>(cars_initial)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ 1, data = cars_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.6906 -4.6656 -0.8906  2.7094 13.8094 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   20.091      1.065   18.86   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.027 on 31 degrees of freedom</code></pre>
<p>Then, to use the <code>stepAIC()</code> function, the direction argument needs to be specified as <code>direction = "forward"</code> and the range of models (lower and upper) to be assessed specified in the <code>scope</code> argument. If no <code>scope</code> argument is specified, the initial model is used as upper model, so to explore more than just the intercept-only model with forward stepwise regression, the initial model should be included as the <code>lower</code> scope and the saturated model as the <code>upper</code> scope. Therefore, the saturated model should also be fitted prior to performing the stepwise regression</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb475-1" tabindex="-1"></a><span class="co">#fit the saturated model</span></span>
<span id="cb475-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb475-2" tabindex="-1"></a>cars_saturated <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> ., <span class="at">data =</span> cars_data)</span>
<span id="cb475-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb475-3" tabindex="-1"></a><span class="fu">summary</span>(cars_saturated)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ ., data = cars_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4506 -1.6044 -0.1196  1.2193  4.6271 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 12.30337   18.71788   0.657   0.5181  
## cyl         -0.11144    1.04502  -0.107   0.9161  
## disp         0.01334    0.01786   0.747   0.4635  
## hp          -0.02148    0.02177  -0.987   0.3350  
## drat         0.78711    1.63537   0.481   0.6353  
## wt          -3.71530    1.89441  -1.961   0.0633 .
## qsec         0.82104    0.73084   1.123   0.2739  
## vs           0.31776    2.10451   0.151   0.8814  
## am           2.52023    2.05665   1.225   0.2340  
## gear         0.65541    1.49326   0.439   0.6652  
## carb        -0.19942    0.82875  -0.241   0.8122  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.65 on 21 degrees of freedom
## Multiple R-squared:  0.869,  Adjusted R-squared:  0.8066 
## F-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07</code></pre>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb477-1" tabindex="-1"></a><span class="co">#fit the forwards stepwise regression</span></span>
<span id="cb477-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb477-2" tabindex="-1"></a>cars_forward <span class="ot">&lt;-</span> <span class="fu">stepAIC</span>(cars_initial, <span class="at">direction =</span> <span class="st">&quot;forward&quot;</span>,</span>
<span id="cb477-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb477-3" tabindex="-1"></a>                        <span class="at">scope =</span> <span class="fu">list</span>(<span class="at">lower =</span> cars_initial, </span>
<span id="cb477-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb477-4" tabindex="-1"></a>                                     <span class="at">upper =</span> cars_saturated))</span></code></pre></div>
<pre><code>## Start:  AIC=115.94
## mpg ~ 1
## 
##        Df Sum of Sq     RSS     AIC
## + wt    1    847.73  278.32  73.217
## + cyl   1    817.71  308.33  76.494
## + disp  1    808.89  317.16  77.397
## + hp    1    678.37  447.67  88.427
## + drat  1    522.48  603.57  97.988
## + vs    1    496.53  629.52  99.335
## + am    1    405.15  720.90 103.672
## + carb  1    341.78  784.27 106.369
## + gear  1    259.75  866.30 109.552
## + qsec  1    197.39  928.66 111.776
## &lt;none&gt;              1126.05 115.943
## 
## Step:  AIC=73.22
## mpg ~ wt
## 
##        Df Sum of Sq    RSS    AIC
## + cyl   1    87.150 191.17 63.198
## + hp    1    83.274 195.05 63.840
## + qsec  1    82.858 195.46 63.908
## + vs    1    54.228 224.09 68.283
## + carb  1    44.602 233.72 69.628
## + disp  1    31.639 246.68 71.356
## &lt;none&gt;              278.32 73.217
## + drat  1     9.081 269.24 74.156
## + gear  1     1.137 277.19 75.086
## + am    1     0.002 278.32 75.217
## 
## Step:  AIC=63.2
## mpg ~ wt + cyl
## 
##        Df Sum of Sq    RSS    AIC
## + hp    1   14.5514 176.62 62.665
## + carb  1   13.7724 177.40 62.805
## &lt;none&gt;              191.17 63.198
## + qsec  1   10.5674 180.60 63.378
## + gear  1    3.0281 188.14 64.687
## + disp  1    2.6796 188.49 64.746
## + vs    1    0.7059 190.47 65.080
## + am    1    0.1249 191.05 65.177
## + drat  1    0.0010 191.17 65.198
## 
## Step:  AIC=62.66
## mpg ~ wt + cyl + hp
## 
##        Df Sum of Sq    RSS    AIC
## &lt;none&gt;              176.62 62.665
## + am    1    6.6228 170.00 63.442
## + disp  1    6.1762 170.44 63.526
## + carb  1    2.5187 174.10 64.205
## + drat  1    2.2453 174.38 64.255
## + qsec  1    1.4010 175.22 64.410
## + gear  1    0.8558 175.76 64.509
## + vs    1    0.0599 176.56 64.654</code></pre>
<p>The output from the stepwise regression demonstrates the process clearly, starting with no covariates in the model and adding each of the covariates to the intercept-only model one at a time, selecting the covariate which results in the lowest AIC value, in this case <code>wt</code>.
The process is then repeated, adding each of the remaining covariates one at a time to the intercept and main effect for weight model, selecting the model which results in the lowest AIC value, in this case <code>cyl</code>. Repeating this process until adding any more covariates no longer improves the fit of the model results in the final model.</p>
<p>It can be seen that the resulting model from the forward stepwise regression includes the covariates <code>wt</code>, <code>cyl</code> and <code>hp</code> as terms in the linear model, meaning that the weight, number of cylinders and the horsepower of the car all improve the fit of the model according to the AIC when exploring the relationship between the covariates and the response, miles per gallon.</p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb479-1" tabindex="-1"></a><span class="co">#summary of the forward stepwise regression model </span></span>
<span id="cb479-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb479-2" tabindex="-1"></a><span class="fu">summary</span>(cars_forward)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + cyl + hp, data = cars_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9290 -1.5598 -0.5311  1.1850  5.8986 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 38.75179    1.78686  21.687  &lt; 2e-16 ***
## wt          -3.16697    0.74058  -4.276 0.000199 ***
## cyl         -0.94162    0.55092  -1.709 0.098480 .  
## hp          -0.01804    0.01188  -1.519 0.140015    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.512 on 28 degrees of freedom
## Multiple R-squared:  0.8431, Adjusted R-squared:  0.8263 
## F-statistic: 50.17 on 3 and 28 DF,  p-value: 2.184e-11</code></pre>
<p>The output from the summary of the forward stepwise regression model indicates that whilst this model produced the lowest AIC value, not all of the terms are statistically significant using the <em>p</em>-values at the 95% significance level. It is important to explore this when using stepwise regression as you do not want to include covariates unnecessarily in your model.</p>
</div>
<div id="backward-stepwise-regression" class="section level3 hasAnchor" number="4.7.2">
<h3><span class="header-section-number">4.7.2</span> Backward stepwise regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#backward-stepwise-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To perform backward stepwise regression, use the <code>stepAIC()</code> function, adding the argument <code>direction = "backward"</code>. Backward stepwise regression starts from the saturated model so this model should be inputted as the object, and since the saturated is the upper model, there is no need to add an argument for <code>scope</code>.</p>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb481-1" tabindex="-1"></a><span class="co">#fit the backward stepwise regression</span></span>
<span id="cb481-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb481-2" tabindex="-1"></a>cars_backward <span class="ot">&lt;-</span> <span class="fu">stepAIC</span>(cars_saturated, <span class="at">direction =</span> <span class="st">&quot;backward&quot;</span>)</span></code></pre></div>
<pre><code>## Start:  AIC=70.9
## mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb
## 
##        Df Sum of Sq    RSS    AIC
## - cyl   1    0.0799 147.57 68.915
## - vs    1    0.1601 147.66 68.932
## - carb  1    0.4067 147.90 68.986
## - gear  1    1.3531 148.85 69.190
## - drat  1    1.6270 149.12 69.249
## - disp  1    3.9167 151.41 69.736
## - hp    1    6.8399 154.33 70.348
## - qsec  1    8.8641 156.36 70.765
## &lt;none&gt;              147.49 70.898
## - am    1   10.5467 158.04 71.108
## - wt    1   27.0144 174.51 74.280
## 
## Step:  AIC=68.92
## mpg ~ disp + hp + drat + wt + qsec + vs + am + gear + carb
## 
##        Df Sum of Sq    RSS    AIC
## - vs    1    0.2685 147.84 66.973
## - carb  1    0.5201 148.09 67.028
## - gear  1    1.8211 149.40 67.308
## - drat  1    1.9826 149.56 67.342
## - disp  1    3.9009 151.47 67.750
## - hp    1    7.3632 154.94 68.473
## &lt;none&gt;              147.57 68.915
## - qsec  1   10.0933 157.67 69.032
## - am    1   11.8359 159.41 69.384
## - wt    1   27.0280 174.60 72.297
## 
## Step:  AIC=66.97
## mpg ~ disp + hp + drat + wt + qsec + am + gear + carb
## 
##        Df Sum of Sq    RSS    AIC
## - carb  1    0.6855 148.53 65.121
## - gear  1    2.1437 149.99 65.434
## - drat  1    2.2139 150.06 65.449
## - disp  1    3.6467 151.49 65.753
## - hp    1    7.1060 154.95 66.475
## &lt;none&gt;              147.84 66.973
## - am    1   11.5694 159.41 67.384
## - qsec  1   15.6830 163.53 68.200
## - wt    1   27.3799 175.22 70.410
## 
## Step:  AIC=65.12
## mpg ~ disp + hp + drat + wt + qsec + am + gear
## 
##        Df Sum of Sq    RSS    AIC
## - gear  1     1.565 150.09 63.457
## - drat  1     1.932 150.46 63.535
## &lt;none&gt;              148.53 65.121
## - disp  1    10.110 158.64 65.229
## - am    1    12.323 160.85 65.672
## - hp    1    14.826 163.35 66.166
## - qsec  1    26.408 174.94 68.358
## - wt    1    69.127 217.66 75.350
## 
## Step:  AIC=63.46
## mpg ~ disp + hp + drat + wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## - drat  1     3.345 153.44 62.162
## - disp  1     8.545 158.64 63.229
## &lt;none&gt;              150.09 63.457
## - hp    1    13.285 163.38 64.171
## - am    1    20.036 170.13 65.466
## - qsec  1    25.574 175.67 66.491
## - wt    1    67.572 217.66 73.351
## 
## Step:  AIC=62.16
## mpg ~ disp + hp + wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## - disp  1     6.629 160.07 61.515
## &lt;none&gt;              153.44 62.162
## - hp    1    12.572 166.01 62.682
## - qsec  1    26.470 179.91 65.255
## - am    1    32.198 185.63 66.258
## - wt    1    69.043 222.48 72.051
## 
## Step:  AIC=61.52
## mpg ~ hp + wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## - hp    1     9.219 169.29 61.307
## &lt;none&gt;              160.07 61.515
## - qsec  1    20.225 180.29 63.323
## - am    1    25.993 186.06 64.331
## - wt    1    78.494 238.56 72.284
## 
## Step:  AIC=61.31
## mpg ~ wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## &lt;none&gt;              169.29 61.307
## - am    1    26.178 195.46 63.908
## - qsec  1   109.034 278.32 75.217
## - wt    1   183.347 352.63 82.790</code></pre>
<p>The output from the backward stepwise regression also demonstrates the process, starting with the saturated model and removing one covariate at a time, selecting the model which results in the lowest AIC value, repeating this process until removing another covariate from the model no longer decreases the AIC value.</p>
<p>The resulting model from backward stepwise regression includes the covariates <code>wt</code>, <code>qsec</code> and <code>am</code>, meaning that weight, 1/4 mile time and transmission all improve the fit of the model according to the AIC value. This is a different model produced than when using forward stepwise regression, which is also why it is important to still look at the summary output for the model to assess whether the terms themselves are statistically significant and hence whether they have a notable impact on the response.</p>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb483-1" tabindex="-1"></a><span class="co">#summary of backward stepwise model</span></span>
<span id="cb483-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb483-2" tabindex="-1"></a><span class="fu">summary</span>(cars_backward)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + qsec + am, data = cars_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4811 -1.5555 -0.7257  1.4110  4.6610 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   9.6178     6.9596   1.382 0.177915    
## wt           -3.9165     0.7112  -5.507 6.95e-06 ***
## qsec          1.2259     0.2887   4.247 0.000216 ***
## am            2.9358     1.4109   2.081 0.046716 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.459 on 28 degrees of freedom
## Multiple R-squared:  0.8497, Adjusted R-squared:  0.8336 
## F-statistic: 52.75 on 3 and 28 DF,  p-value: 1.21e-11</code></pre>
<p>In this case, the summary output indicates that each of the terms included in the backward stepwise regression model are all statistically significant at the 95% level and hence should be included in the model as they impact the response variable.</p>
</div>
<div id="both-ways-stepwise-regression" class="section level3 hasAnchor" number="4.7.3">
<h3><span class="header-section-number">4.7.3</span> Both ways stepwise regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#both-ways-stepwise-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To perform both ways stepwise regression, use the <code>stepAIC()</code> function, adding the argument <code>direction = "both"</code>.</p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb485-1" tabindex="-1"></a><span class="co">#fit the both ways stepwise regression</span></span>
<span id="cb485-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb485-2" tabindex="-1"></a>cars_both <span class="ot">&lt;-</span> <span class="fu">stepAIC</span>(cars_saturated, <span class="at">direction =</span> <span class="st">&quot;both&quot;</span>)</span></code></pre></div>
<pre><code>## Start:  AIC=70.9
## mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb
## 
##        Df Sum of Sq    RSS    AIC
## - cyl   1    0.0799 147.57 68.915
## - vs    1    0.1601 147.66 68.932
## - carb  1    0.4067 147.90 68.986
## - gear  1    1.3531 148.85 69.190
## - drat  1    1.6270 149.12 69.249
## - disp  1    3.9167 151.41 69.736
## - hp    1    6.8399 154.33 70.348
## - qsec  1    8.8641 156.36 70.765
## &lt;none&gt;              147.49 70.898
## - am    1   10.5467 158.04 71.108
## - wt    1   27.0144 174.51 74.280
## 
## Step:  AIC=68.92
## mpg ~ disp + hp + drat + wt + qsec + vs + am + gear + carb
## 
##        Df Sum of Sq    RSS    AIC
## - vs    1    0.2685 147.84 66.973
## - carb  1    0.5201 148.09 67.028
## - gear  1    1.8211 149.40 67.308
## - drat  1    1.9826 149.56 67.342
## - disp  1    3.9009 151.47 67.750
## - hp    1    7.3632 154.94 68.473
## &lt;none&gt;              147.57 68.915
## - qsec  1   10.0933 157.67 69.032
## - am    1   11.8359 159.41 69.384
## + cyl   1    0.0799 147.49 70.898
## - wt    1   27.0280 174.60 72.297
## 
## Step:  AIC=66.97
## mpg ~ disp + hp + drat + wt + qsec + am + gear + carb
## 
##        Df Sum of Sq    RSS    AIC
## - carb  1    0.6855 148.53 65.121
## - gear  1    2.1437 149.99 65.434
## - drat  1    2.2139 150.06 65.449
## - disp  1    3.6467 151.49 65.753
## - hp    1    7.1060 154.95 66.475
## &lt;none&gt;              147.84 66.973
## - am    1   11.5694 159.41 67.384
## - qsec  1   15.6830 163.53 68.200
## + vs    1    0.2685 147.57 68.915
## + cyl   1    0.1883 147.66 68.932
## - wt    1   27.3799 175.22 70.410
## 
## Step:  AIC=65.12
## mpg ~ disp + hp + drat + wt + qsec + am + gear
## 
##        Df Sum of Sq    RSS    AIC
## - gear  1     1.565 150.09 63.457
## - drat  1     1.932 150.46 63.535
## &lt;none&gt;              148.53 65.121
## - disp  1    10.110 158.64 65.229
## - am    1    12.323 160.85 65.672
## - hp    1    14.826 163.35 66.166
## + carb  1     0.685 147.84 66.973
## + vs    1     0.434 148.09 67.028
## + cyl   1     0.414 148.11 67.032
## - qsec  1    26.408 174.94 68.358
## - wt    1    69.127 217.66 75.350
## 
## Step:  AIC=63.46
## mpg ~ disp + hp + drat + wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## - drat  1     3.345 153.44 62.162
## - disp  1     8.545 158.64 63.229
## &lt;none&gt;              150.09 63.457
## - hp    1    13.285 163.38 64.171
## + gear  1     1.565 148.53 65.121
## + cyl   1     1.003 149.09 65.242
## + vs    1     0.645 149.45 65.319
## + carb  1     0.107 149.99 65.434
## - am    1    20.036 170.13 65.466
## - qsec  1    25.574 175.67 66.491
## - wt    1    67.572 217.66 73.351
## 
## Step:  AIC=62.16
## mpg ~ disp + hp + wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## - disp  1     6.629 160.07 61.515
## &lt;none&gt;              153.44 62.162
## - hp    1    12.572 166.01 62.682
## + drat  1     3.345 150.09 63.457
## + gear  1     2.977 150.46 63.535
## + cyl   1     2.447 150.99 63.648
## + vs    1     1.121 152.32 63.927
## + carb  1     0.011 153.43 64.160
## - qsec  1    26.470 179.91 65.255
## - am    1    32.198 185.63 66.258
## - wt    1    69.043 222.48 72.051
## 
## Step:  AIC=61.52
## mpg ~ hp + wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## - hp    1     9.219 169.29 61.307
## &lt;none&gt;              160.07 61.515
## + disp  1     6.629 153.44 62.162
## + carb  1     3.227 156.84 62.864
## + drat  1     1.428 158.64 63.229
## - qsec  1    20.225 180.29 63.323
## + cyl   1     0.249 159.82 63.465
## + vs    1     0.249 159.82 63.466
## + gear  1     0.171 159.90 63.481
## - am    1    25.993 186.06 64.331
## - wt    1    78.494 238.56 72.284
## 
## Step:  AIC=61.31
## mpg ~ wt + qsec + am
## 
##        Df Sum of Sq    RSS    AIC
## &lt;none&gt;              169.29 61.307
## + hp    1     9.219 160.07 61.515
## + carb  1     8.036 161.25 61.751
## + disp  1     3.276 166.01 62.682
## + cyl   1     1.501 167.78 63.022
## + drat  1     1.400 167.89 63.042
## + gear  1     0.123 169.16 63.284
## + vs    1     0.000 169.29 63.307
## - am    1    26.178 195.46 63.908
## - qsec  1   109.034 278.32 75.217
## - wt    1   183.347 352.63 82.790</code></pre>
<p>The results from the output of the both ways stepwise regression are the same as that from the backward stepwise regression in this instance, indicating that the model with the covariates <code>wt</code>, <code>qsec</code> and <code>am</code> results in the lowest AIC value.</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb487-1" tabindex="-1"></a><span class="co">#summary of both ways stepwise model</span></span>
<span id="cb487-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb487-2" tabindex="-1"></a><span class="fu">summary</span>(cars_both)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + qsec + am, data = cars_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4811 -1.5555 -0.7257  1.4110  4.6610 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   9.6178     6.9596   1.382 0.177915    
## wt           -3.9165     0.7112  -5.507 6.95e-06 ***
## qsec          1.2259     0.2887   4.247 0.000216 ***
## am            2.9358     1.4109   2.081 0.046716 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.459 on 28 degrees of freedom
## Multiple R-squared:  0.8497, Adjusted R-squared:  0.8336 
## F-statistic: 52.75 on 3 and 28 DF,  p-value: 1.21e-11</code></pre>
<p>Whilst the results are the same as previously seen, it is still important to check the significance of the covariates in the final model to ensure that you are not including covariates which are not significant at the 95% (or otherwise chosen) significance level as this would indicate that the covariate does not have a significant impact on the response variable. In this case, the summary output indicates that each of the terms are statistically significant and therefore should not be removed from the model.</p>
</div>
</div>
<div id="cross-validation" class="section level2 hasAnchor" number="4.8">
<h2><span class="header-section-number">4.8</span> Cross-validation<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As mentioned previously, when choosing a model, it is important to avoid overfitting. This occurs when the model of interest is fitted too well on the given data and does not perform well on any other, unseen data. Cross-validation (CV) is a resampling method that is used to assess the performance of the model of interest on unseen data. The general idea using the validation approach is to divide the available dataset into 2 sets, the <strong>training set</strong> and the <strong>validation set</strong>. The former is used to fit the model, essentially <em>training</em> the model using the training dataset, where the resulting fitted values are used to predict responses for the observations that are in the validation dataset. These predictions are then used to test the generalised fit of the model of interest. This results in a much more generalised assessment of the model’s performance which gives a better idea of how it will perform with a new unseen dataset, instead of just the dataset used to train the model. There are multiple ways to perform cross-validation, in this section, <em>k</em>-fold cross-validation and leave-one-out cross-validation (LOOCV) will be discussed.</p>
<div id="k-fold-cross-validation" class="section level3 hasAnchor" number="4.8.1">
<h3><span class="header-section-number">4.8.1</span> <em>k</em>-fold cross-validation<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#k-fold-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the more widely-used approaches to cross-validation is that of the <em>k</em>-fold approach. To perform <em>k</em>-fold CV, the available dataset is partitioned into <span class="math inline">\(K\)</span> approximately equal-sized, non-overlapping (sub)sets, known as <strong>folds</strong>. Commonly, the choice of <span class="math inline">\(K\)</span> is either 5 or 10.</p>
<p>Once the data is partitioned, for each <span class="math inline">\(k=1,\cdots K\)</span>, fold <span class="math inline">\(k\)</span> is removed from the overall data and the model is fitted using the training set which is made up of the remaining <span class="math inline">\(K-1\)</span> folds Once the model has been fitted, the predictions can be found using the validation set which is the <span class="math inline">\(k\)</span>th fold that was originally removed. After this process is repeated for each of the <span class="math inline">\(K\)</span> folds, the results are combined to find the cross-validation error where the lower the value of the CV error the better the generalised fit of the model.</p>
The process is demonstrated visually in the below figure, where the complete dataset is partitioned into <span class="math inline">\(K=5\)</span> folds.
<div class="figure" style="text-align: center">
<img src="figures/4_images/k-fold%20cv.png" alt="Visual example of k-fold cross-validation" width="80%" />
<p class="caption">
(#fig:image k-fold)Visual example of k-fold cross-validation
</p>
</div>
<p>To demonstrate the method in <code>R</code>, the <code>Auto</code> dataset from the <code>ISLR</code> package will be used. This dataset contains information on 392 vehicles, where for this example, the covariates for miles per gallon (<code>mpg</code>) and horsepower (<code>horsepower</code>) are of interest.</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb489-1" tabindex="-1"></a><span class="co">#install ISLR package</span></span>
<span id="cb489-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb489-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;ISLR&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb490-1" tabindex="-1"></a><span class="co">#load the ISLR package</span></span>
<span id="cb490-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb490-2" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span></code></pre></div>
<p>To compute the <em>k</em>-fold cross-validation error, the function <code>cv.glm()</code> from the <code>boot</code> package can be used, with arguments for the dataset, the model being tested and the number of folds. From the results, the <code>delta[1]</code> coefficient can be subset in order to extract the CV error from the results. Since the partitioning into the folds is a random process, to obtain reproducible results, the seed needs to be set with the function <code>set.seed()</code>.</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb491-1" tabindex="-1"></a><span class="co">#install boot package</span></span>
<span id="cb491-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb491-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;boot&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb492-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb492-1" tabindex="-1"></a><span class="co">#load the boot package</span></span>
<span id="cb492-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb492-2" tabindex="-1"></a><span class="fu">library</span>(boot)</span></code></pre></div>
<p>In this data, the response (<code>mpg</code>) is assumed to follow a normal distribution and hence a GLM can be fitted to explore the relationship between the miles per gallon and horsepower with the default value for the family argument. Additionally, the number of folds for this example is chosen to be <span class="math inline">\(K=10\)</span>.</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-1" tabindex="-1"></a><span class="co">#load the Auto dataset</span></span>
<span id="cb493-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-2" tabindex="-1"></a><span class="fu">data</span>(Auto)</span>
<span id="cb493-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-3" tabindex="-1"></a></span>
<span id="cb493-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-4" tabindex="-1"></a><span class="co">#set the seed</span></span>
<span id="cb493-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb493-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-6" tabindex="-1"></a></span>
<span id="cb493-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-7" tabindex="-1"></a><span class="co">#fit a linear model </span></span>
<span id="cb493-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-8" tabindex="-1"></a>Auto_simple_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(mpg <span class="sc">~</span> horsepower, <span class="at">data =</span> Auto)</span>
<span id="cb493-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-9" tabindex="-1"></a></span>
<span id="cb493-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-10" tabindex="-1"></a><span class="co">#find the k-fold CV error for this model fit</span></span>
<span id="cb493-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-11" tabindex="-1"></a>kfold_CV_error1 <span class="ot">&lt;-</span> <span class="fu">cv.glm</span>(Auto, Auto_simple_glm, <span class="at">K =</span> <span class="dv">10</span>)<span class="sc">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb493-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb493-12" tabindex="-1"></a>kfold_CV_error1</span></code></pre></div>
<pre><code>## [1] 24.13555</code></pre>
<p>However, since there is no reference point for the value of CV error besides the smaller the error the better, it is important to fit alternative models to select which model has the best generalised fit.</p>
<p>Below is code which fits a series of models with the <code>polynomial()</code> function including polynomials for the horsepower argument ranging from degree 1 to degree 5</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-1" tabindex="-1"></a><span class="co">#set the seed</span></span>
<span id="cb495-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb495-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-3" tabindex="-1"></a></span>
<span id="cb495-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-4" tabindex="-1"></a><span class="co">#create the empty variable </span></span>
<span id="cb495-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-5" tabindex="-1"></a>kfold_CV_error2 <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb495-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-6" tabindex="-1"></a></span>
<span id="cb495-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-7" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>){</span>
<span id="cb495-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-8" tabindex="-1"></a>  Auto_poly_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(mpg<span class="sc">~</span><span class="fu">poly</span>(horsepower,<span class="dv">5</span>), <span class="at">data =</span> Auto) </span>
<span id="cb495-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-9" tabindex="-1"></a>  kfold_CV_error2[i] <span class="ot">&lt;-</span> <span class="fu">cv.glm</span>(Auto, Auto_poly_glm, <span class="at">K =</span> <span class="dv">10</span>)<span class="sc">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb495-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-10" tabindex="-1"></a>}</span>
<span id="cb495-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-11" tabindex="-1"></a></span>
<span id="cb495-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb495-12" tabindex="-1"></a>kfold_CV_error2</span></code></pre></div>
<pre><code>## [1] 18.93963 18.92569 19.06507 19.40166 18.99473</code></pre>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb497-1" tabindex="-1"></a><span class="co">#which model has the lowest error</span></span>
<span id="cb497-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb497-2" tabindex="-1"></a><span class="fu">which.min</span>(kfold_CV_error2)</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb499-1" tabindex="-1"></a><span class="co">#plot the results for a visual illustration</span></span>
<span id="cb499-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb499-2" tabindex="-1"></a><span class="fu">plot</span>(kfold_CV_error2, <span class="at">xlab =</span> <span class="st">&quot;Polynomial degree&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;k-fold CV error&quot;</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/k-fold%20CV%20poly-1.png" width="672" /></p>
<p>The results from the <em>k</em>-fold cross-validation indicate that the quadratic model has the lowest CV error and is therefore the model that should be used.</p>
</div>
<div id="leave-one-out-cross-validation" class="section level3 hasAnchor" number="4.8.2">
<h3><span class="header-section-number">4.8.2</span> Leave-one-out cross-validation<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#leave-one-out-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Leave-one-out cross-validation can be described as a special case of <em>k</em>-fold cross-validation in the instance where the number of folds chosen is equal to the number of observations in the available dataset, <span class="math inline">\(K=n\)</span>. This leads to each subset, or fold, containing a single observation only. This means that instead of removing a set of observations from the dataset each time the model is fitted, a singular observation is removed and the remaining data is used for fitting the model. Given the nature of this approach, it is not appropriate when datasets are very large due to the high computational cost associated to fitting the same number of models as observations in the data.</p>
<p>This process is demonstrated visually in the figure below.</p>
<div class="figure" style="text-align: center">
<img src="figures/4_images/loocv.png" alt="Visual example of leave-one-out cross-validation" width="80%" />
<p class="caption">
(#fig:image LOOCV)Visual example of leave-one-out cross-validation
</p>
</div>
<p>To perform LOOCV in <code>R</code>, the process is very similar to that of <em>k</em>-fold CV fitting a GLM and then using the function <code>cv.glm()</code> to perform the cross-validation. However, instead of defining the argument <code>K</code>, this is left blank as the default value is set equal to <span class="math inline">\(n\)</span>, the number of observations in the dataset. This is demonstrated below with the <code>Auto</code> dataset again.</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-1" tabindex="-1"></a><span class="co">#set the seed</span></span>
<span id="cb500-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb500-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-3" tabindex="-1"></a></span>
<span id="cb500-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-4" tabindex="-1"></a><span class="co">#fit a linear model </span></span>
<span id="cb500-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-5" tabindex="-1"></a>Auto_simple_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(mpg <span class="sc">~</span> horsepower, <span class="at">data =</span> Auto)</span>
<span id="cb500-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-6" tabindex="-1"></a></span>
<span id="cb500-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-7" tabindex="-1"></a><span class="co">#find the k-fold CV error for this model fit</span></span>
<span id="cb500-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-8" tabindex="-1"></a>LOOCV_error1 <span class="ot">&lt;-</span> <span class="fu">cv.glm</span>(Auto, Auto_simple_glm)<span class="sc">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb500-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb500-9" tabindex="-1"></a>LOOCV_error1</span></code></pre></div>
<pre><code>## [1] 24.23151</code></pre>
<p>As with the <em>k</em>-fold cross-validation approach, the value of the CV error of one model on its own does not indicate as to which model is best. The same example as given for the <em>k</em>-fold approach is provided below, where the LOOCV error is given for multiple polynomial models ranging from degree 1 to degree 5.</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-1" tabindex="-1"></a><span class="co">#set the seed</span></span>
<span id="cb502-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb502-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-3" tabindex="-1"></a></span>
<span id="cb502-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-4" tabindex="-1"></a><span class="co">#create the empty variable </span></span>
<span id="cb502-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-5" tabindex="-1"></a>LOOCV_error2 <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb502-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-6" tabindex="-1"></a></span>
<span id="cb502-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-7" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>){</span>
<span id="cb502-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-8" tabindex="-1"></a>  Auto_poly_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, <span class="dv">5</span>), <span class="at">data =</span> Auto) </span>
<span id="cb502-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-9" tabindex="-1"></a>  LOOCV_error2[i] <span class="ot">&lt;-</span> <span class="fu">cv.glm</span>(Auto, Auto_poly_glm)<span class="sc">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb502-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-10" tabindex="-1"></a>}</span>
<span id="cb502-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-11" tabindex="-1"></a></span>
<span id="cb502-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb502-12" tabindex="-1"></a>LOOCV_error2</span></code></pre></div>
<pre><code>## [1] 19.03321 19.03321 19.03321 19.03321 19.03321</code></pre>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb504-1" tabindex="-1"></a><span class="co">#which model has the lowest error</span></span>
<span id="cb504-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb504-2" tabindex="-1"></a><span class="fu">which.min</span>(LOOCV_error2)</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb506-1" tabindex="-1"></a><span class="co">#plot the results for a visual illustration</span></span>
<span id="cb506-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb506-2" tabindex="-1"></a><span class="fu">plot</span>(LOOCV_error2, <span class="at">xlab =</span> <span class="st">&quot;Polynomial degree&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;LOOCV error&quot;</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/LOOCV%20poly-1.png" width="672" /></p>
<p>The results for this approach indicate that the simple linear regression model is best for this data, however, the plot demonstrates that there is much less of a difference in the error between each of the different polynomial GLMs compared the corresponding <em>k</em>-fold errors.</p>
</div>
</div>
<div id="hierarchical-regression" class="section level2 hasAnchor" number="4.9">
<h2><span class="header-section-number">4.9</span> Hierarchical regression<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#hierarchical-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- The data modelled so far this module has all been of the same *level* due to **complete pooling**, where it is assumed the data cannot be grouped or ordered and therefore is treated together. The case of **no pooling** is when data can be grouped and a model is fit for each group individually, leading to the models only performing for the observed groupings. Somewhere in between these two pooling types is **partial pooling** which is where hierarchical modelling comes into play, where the data can be grouped (with a hierarchical data structure) but information is still shared between groups allowing for both between-group and within-group variability to be accounted for.  -->
<p>The data modelled so far this module has all been of the same <em>level</em>, and the assumption of independence between observations is upheld. However, when data is multi-level/hierarchical, clustered or longitudinal, this assumption is not upheld and alternative modelling methods are required. This is where linear mixed modelling (incorporating both fixed and random effects) and hierarchical regression are used, enabling for the relationship between different variables at different levels to be explored.</p>
<div id="data-structure" class="section level3 hasAnchor" number="4.9.1">
<h3><span class="header-section-number">4.9.1</span> Data structure<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#data-structure" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A hierarchical data structure is where level 1 is <strong>nested</strong> in level 2, which is nested in level 3 and so on, where information can be shared between groups (also called <strong>clusters</strong>). When this information is shared, information on both between-group and within-group variability is provided, where typically the variation between groups is due to factors which are not measured but differ from one group to another.</p>
<p>This hierarchical data structure is seen for example, when there is data on people within settlements within regions (3 levels), households within communities (2 levels) or pupils within schools within districts (3 levels). The former example is given in the below figure as a visual example of what a hierarchical data structure looks like.</p>
<div class="figure" style="text-align: center">
<img src="figures/4_images/hier%20data.png" alt="Visual example of a hierarchical data structure" width="80%" />
<p class="caption">
(#fig:image hierarchical school structure)Visual example of a hierarchical data structure
</p>
</div>
<p>It is important to account for the different levels in hierarchical data in order to make reliable and correct inferences. For example, if the vaccine status of individual people within a region is of interest where the people are grouped by settlements, each settlement forms a <strong>cluster</strong>. It is reasonable to assume that the vaccine status within a settlement (or cluster) is not independent, but is actually correlated. This can be due to a number of factors, for instance it is reasonable to assume that people within the same settlement will have similar (physical) access to the medical centre and therefore vaccines due to having approximately the same distance to a medical centre. Another factor could be that people within the same settlement can be more likely to hold similar beliefs to one another compared to those from another settlement.</p>
<p>Another example of this importance can be seen in the school example where pupils are nested within schools within districts. If the response is the pupil’s performance in school, this will not only depend on the individual pupil’s own characteristics and intelligence, but also the school they are in and the district that the school is in. For example, private schools and grammar schools typically have better performance than standard state schools, and schools in wealthy districts typically also have better performance than schools in districts with overall lower socio-economic status.</p>
<p>This example of pupils being nested within schools is seen in the <code>exam</code> dataset where there is information on different test scores, including GCSE scores (<code>GCSEscore</code>), London Reading test scores (<code>LRTscore</code>), and Verbal Reasoning test score band (<code>VRTsband</code>, levels for top 25%, middle 50% and bottom 25%) for pupils in different schools (<code>SchoolID</code>) in addition to the sex (<code>Sex</code>, levels for male and female) of each pupil and the type of school (<code>sch.type</code>, levels for mixed, male-only and female-only schools).</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-1" tabindex="-1"></a><span class="co">#import the exam dataset</span></span>
<span id="cb507-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-2" tabindex="-1"></a>exam <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="fu">paste0</span>(data_path,<span class="st">&#39;exam.txt&#39;</span>), <span class="at">sep =</span> <span class="st">&quot; &quot;</span>, <span class="at">header =</span> <span class="cn">FALSE</span>,</span>
<span id="cb507-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-3" tabindex="-1"></a>                <span class="at">colClasses =</span> <span class="fu">c</span>(<span class="st">&quot;factor&quot;</span>,<span class="st">&quot;double&quot;</span>,<span class="st">&quot;double&quot;</span>,<span class="st">&quot;factor&quot;</span>,</span>
<span id="cb507-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-4" tabindex="-1"></a>                             <span class="st">&quot;factor&quot;</span>,<span class="st">&quot;factor&quot;</span>))</span>
<span id="cb507-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-5" tabindex="-1"></a></span>
<span id="cb507-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-6" tabindex="-1"></a><span class="co">#set column names</span></span>
<span id="cb507-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-7" tabindex="-1"></a><span class="fu">colnames</span>(exam) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;SchoolID&quot;</span>,<span class="st">&quot;GCSEscore&quot;</span>,<span class="st">&quot;LRTscore&quot;</span>,<span class="st">&quot;Sex&quot;</span>,<span class="st">&quot;VRTband&quot;</span>,<span class="st">&quot;sch.type&quot;</span>)</span>
<span id="cb507-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-8" tabindex="-1"></a></span>
<span id="cb507-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-9" tabindex="-1"></a><span class="co">#set levels of factor variables</span></span>
<span id="cb507-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-10" tabindex="-1"></a><span class="fu">levels</span>(exam<span class="sc">$</span>Sex) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Male&quot;</span>,<span class="st">&quot;Female&quot;</span>)</span>
<span id="cb507-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-11" tabindex="-1"></a><span class="fu">levels</span>(exam<span class="sc">$</span>VRTband) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Top25&quot;</span>,<span class="st">&quot;Middle50&quot;</span>,<span class="st">&quot;Bottom25&quot;</span>)</span>
<span id="cb507-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb507-12" tabindex="-1"></a><span class="fu">levels</span>(exam<span class="sc">$</span>sch.type) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Mixed&quot;</span>,<span class="st">&quot;Males-only&quot;</span>,<span class="st">&quot;Females-only&quot;</span>)</span></code></pre></div>
<p>To perform hierarchical modelling in <code>R</code>, functions from the <code>lme4</code>, <code>nlme</code> or <code>glme</code> packages can be used. They both perform similar tasks but do have some differences, detailed below.</p>
<ul>
<li><code>lme4</code>
<ul>
<li><code>lmer()</code>: fits linear mixed-effects models, similar to the <code>lm()</code> function but allows for random effects</li>
<li><code>glmer()</code>: fits generalised linear mixed-effects models, similar to the <code>glm()</code> function but allows for random effects</li>
<li><code>nlmer()</code>: fits non-linear mixed-effects models</li>
</ul></li>
<li><code>nlme</code>
<ul>
<li><code>lme()</code>: fits linear mixed-effects models, similar to the <code>lm()</code> function but allows for random effects</li>
<li><code>nlme()</code>: fits non-linear mixed-effects models
-<code>glme</code>
-<code>glme()</code>: fits generalised linear mixed-effects models, similar to the <code>glm()</code> function but allows for random effects</li>
</ul></li>
</ul>
<p>To begin with, the <code>lme</code> function will be used and has the general structure of <code>lme(y~x, random = ~)</code> where <code>y~x</code> relates to the fixed part of the model and <code>random=~</code> relates to the random part of the module. The default method of fitting the model is <code>REML</code>, which is a restricted maximum likelihood approach used to have unbiased variance components, however, this can be changed to use the maximum likelihood approach through adding the argument <code>method = 'ML'</code>.</p>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb508-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb508-1" tabindex="-1"></a><span class="co">#install nlme package</span></span>
<span id="cb508-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb508-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;nlme&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb509-1" tabindex="-1"></a><span class="co">#load the nlme package</span></span>
<span id="cb509-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb509-2" tabindex="-1"></a><span class="fu">library</span>(nlme)</span></code></pre></div>
</div>
<div id="variance-partition-coefficient" class="section level3 hasAnchor" number="4.9.2">
<h3><span class="header-section-number">4.9.2</span> Variance partition coefficient<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#variance-partition-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One method of identifying how important group level differences are is looking at the <strong>variance partition coefficient (VPC)</strong>, which identifies how much of the total variance is due to the level 2 variance, being the difference between groups.</p>
<p>For the random intercepts modelling, the VPC is computed using the following formula.</p>
<p><span class="math display">\[\text{VPC} = \frac{\text{Level 2 variance}}{\text{Total variance}}\]</span></p>
<p>Given that the VPC is a proportion, it must be between 0 and 1, <span class="math inline">\(0 \leq \text{VPC} \geq 1\)</span>, where</p>
<p><span class="math display">\[
\text{VPC} =
\begin{cases}
0 &amp; \text{ if there is no group effect } (\sigma^2_u=0), \\
1 &amp; \text{ if there is no within group differences } (\sigma^2_e=0)
\end{cases}
\]</span></p>
<div class="figure" style="text-align: center">
<img src="figures/4_images/VPC.png" alt="Visual example of VPC equalling 0 and 1 respectively" width="80%" />
<p class="caption">
(#fig:VPC example)Visual example of VPC equalling 0 and 1 respectively
</p>
</div>
</div>
<div id="random-intercepts-modelling" class="section level3 hasAnchor" number="4.9.3">
<h3><span class="header-section-number">4.9.3</span> Random intercepts modelling<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#random-intercepts-modelling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Random intercepts modelling takes into account that observations come from different groups through using a random group level effect, where the general notation for the form of the (2-level) model is as follows.</p>
<p><span class="math display">\[ y_{ij} = u_j +e_{ij}, \]</span>
where <span class="math inline">\(i\)</span> is the index for level 1, <span class="math inline">\(j\)</span> is the index for level 2 and</p>
<ul>
<li><span class="math inline">\(u_j\)</span>: group level effect (random effect)
<ul>
<li>Normally distributed: <span class="math inline">\(u_j \sim N(0, \sigma^2_u)\)</span> where <span class="math inline">\(\sigma^2_u\)</span> is the between-groups variance</li>
<li>Independence: <span class="math inline">\(\text{cov}(u_j, u_{k})=0\)</span></li>
</ul></li>
<li><span class="math inline">\(e_{ij}\)</span>: individual level error (random error)
<ul>
<li>Normally distributed: <span class="math inline">\(e_{ij} \sim N(0, \sigma^2_e)\)</span> where <span class="math inline">\(\sigma^2_e\)</span> is the within-groups variance</li>
<li>Independence: <span class="math inline">\(\text{cov}(e_{ij}, e_{kj})=0\)</span></li>
</ul></li>
</ul>
<p>It is also assumed that there is independence between the random effects and random errors (<span class="math inline">\(\text{cov}(e_{ij}, u_{j})=\text{cov}(e_{ij}, u_{k})=0\)</span>) and independence between the group level effects (<span class="math inline">\(u\)</span>) and the covariates (<span class="math inline">\(X\)</span>).</p>
<p>The random effect for the group level accounts for the difference between groups by “shifting” the intercept up or down by a random amount <span class="math inline">\(u_j\)</span> characteristic of each group.</p>
<p>Using the <code>exam</code> dataset, an empty 2-level random intercepts model can be fitted to explore the GCSE scores of pupils by different schools. If no covariates are included, an empty model is fitted, taking the following form.</p>
<p><span class="math display">\[ \text{GCSE}_{ij} = u_j + e_{ij}.\]</span></p>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb510-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb510-1" tabindex="-1"></a><span class="co">#fit the empty random intercepts model to the exam dataset</span></span>
<span id="cb510-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb510-2" tabindex="-1"></a>exam_emptyRI <span class="ot">&lt;-</span> <span class="fu">lme</span>(GCSEscore <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">random =</span> <span class="sc">~</span><span class="dv">1</span><span class="sc">|</span>SchoolID, <span class="at">method =</span> <span class="st">&#39;ML&#39;</span>, </span>
<span id="cb510-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb510-3" tabindex="-1"></a>                    <span class="at">data =</span> exam)</span>
<span id="cb510-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb510-4" tabindex="-1"></a><span class="fu">summary</span>(exam_emptyRI)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: exam 
##        AIC      BIC    logLik
##   11014.71 11027.33 -5505.355
## 
## Random effects:
##  Formula: ~1 | SchoolID
##         (Intercept)  Residual
## StdDev:   0.4106958 0.9207448
## 
## Fixed effects:  GCSEscore ~ -1 
## [1] Value     Std.Error DF        t-value   p-value  
## &lt;0 rows&gt; (or 0-length row.names)
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -3.948756027 -0.653647311  0.009080812  0.693656002  3.656266940 
## 
## Number of Observations: 4059
## Number of Groups: 65</code></pre>
<div class="figure" style="text-align: center">
<img src="figures/4_images/emptyRI.png" alt="Interpreting the summary output" width="80%" />
<p class="caption">
(#fig:empty lme summary)Interpreting the summary output
</p>
</div>
<p>To compute the estimated total variance for the two-level random intercepts model the variance components for both the random effects and the error terms must be summed, where both components are provided by the summary output for the model.</p>
<p><span class="math display">\[\hat{\sigma}_u^2 +\hat{\sigma}_e^2 = 0.411^2 + 0.921^2 = 1.017.\]</span>
To investigate the significance of the group level differences, the VPC can be computed using the above total variance and the level 2 variance as follows.</p>
<p><span class="math display">\[ \text{VPC} =\frac{\sigma^2_u}{\sigma^2_u+\sigma^2_e} = \frac{0.411^2}{1.017} = 0.166,\]</span></p>
<p>which can be interpreted as the level 2 variability (between schools) accounts for 16.6% of the total variability observed in the GCSE scores of the pupils.</p>
<p>For a random intercepts model, the VPC is equal to the expected correlation between 2 randomly selected observations that belong to the same group, also known as the <strong>intra-class correlation</strong>. This means that a for VPC of 0.166 for the random intercepts model above, the expected correlation between the GCSE scores of 2 randomly selected pupils within the same school is 0.166.</p>
</div>
<div id="random-intercepts-mixed-effects-modelling" class="section level3 hasAnchor" number="4.9.4">
<h3><span class="header-section-number">4.9.4</span> Random intercepts mixed-effects modelling<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#random-intercepts-mixed-effects-modelling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Random intercepts mixed modelling takes into account that observations come from different groups through using <em>both</em> fixed and random effects, where the general notation for the form of the (2-level) model is as follows.</p>
<p><span class="math display">\[ y_{ij} = \beta_0 + \beta_1x_{ij} + u_j +e_{ij}, \]</span>
where <span class="math inline">\(i\)</span> is the index for level 1, <span class="math inline">\(j\)</span> is the index for level 2 and</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>: overall intercept (fixed effect)</li>
<li><span class="math inline">\(\beta_1\)</span>: overall slope (fixed effect)</li>
<li><span class="math inline">\(u_j\)</span>: group level effect (random effect)
<ul>
<li>Normally distributed: <span class="math inline">\(u_j \sim N(0, \sigma^2_u)\)</span> where <span class="math inline">\(\sigma^2_u\)</span> is the between-groups variance</li>
<li>Independence: <span class="math inline">\(\text{cov}(u_j, u_{k})=0\)</span></li>
</ul></li>
<li><span class="math inline">\(e_{ij}\)</span>: individual level error (random error)
<ul>
<li>Normally distributed: <span class="math inline">\(e_{ij} \sim N(0, \sigma^2_e)\)</span> where <span class="math inline">\(\sigma^2_e\)</span> is the within-groups variance</li>
<li>Independence: <span class="math inline">\(\text{cov}(e_{ij}, e_{kj})=0\)</span></li>
</ul></li>
</ul>
<p>It is also assumed that there is independence between the random effects and random errors (<span class="math inline">\(\text{cov}(e_{ij}, u_{j})=\text{cov}(e_{ij}, u_{k})=0\)</span>) and independence between the group level effects (<span class="math inline">\(u\)</span>) and the covariates (<span class="math inline">\(X\)</span>).</p>
<p>As with the random intercepts only modelling, the random effect for the group level accounts for the difference between groups by “shifting” the intercept up or down by a random amount <span class="math inline">\(u_j\)</span> characteristic of each group.</p>
<p>Using the <code>exam</code> dataset, an empty 2-level random intercepts mixed model can be fitted to explore the GCSE scores of pupils by different schools. The empty model that has only an intercept term (no covariates) for the fixed effects and a random intercept for the random effects takes the following form.</p>
<p><span class="math display">\[ \text{GCSE}_{ij} = \beta_0 + u_j + e_{ij},\]</span></p>
<p>which can be re-written as</p>
<p><span class="math display">\[ \text{GCSE}_i = \beta_{0j} + e_{i},\]</span>
where <span class="math inline">\(\beta_{0j}=\beta_0+u_j\)</span> is the intercept for school <span class="math inline">\(j\)</span>.</p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb512-1" tabindex="-1"></a><span class="co">#fit the empty random intercepts model to the exam dataset</span></span>
<span id="cb512-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb512-2" tabindex="-1"></a>exam_empty2lvlMRI <span class="ot">&lt;-</span> <span class="fu">lme</span>(GCSEscore <span class="sc">~</span> <span class="dv">1</span>, <span class="at">random =</span> <span class="sc">~</span><span class="dv">1</span><span class="sc">|</span>SchoolID, <span class="at">method =</span> <span class="st">&#39;ML&#39;</span>, </span>
<span id="cb512-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb512-3" tabindex="-1"></a>                    <span class="at">data =</span> exam)</span>
<span id="cb512-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb512-4" tabindex="-1"></a><span class="fu">summary</span>(exam_empty2lvlMRI)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: exam 
##        AIC      BIC    logLik
##   11016.65 11035.58 -5505.324
## 
## Random effects:
##  Formula: ~1 | SchoolID
##         (Intercept)  Residual
## StdDev:   0.4106567 0.9207391
## 
## Fixed effects:  GCSEscore ~ 1 
##                   Value  Std.Error   DF    t-value p-value
## (Intercept) -0.01316707 0.05363399 3994 -0.2454986  0.8061
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -3.94711015 -0.64856012  0.01168106  0.69918450  3.65782427 
## 
## Number of Observations: 4059
## Number of Groups: 65</code></pre>
<p>To compute the estimated total variance for the two-level random intercepts mixed-effects model the variance components for both the random effects and the error terms must be summed, where both components are provided by the summary output for the model.</p>
<p><span class="math display">\[\hat{\sigma}_u^2 +\hat{\sigma}_e^2 = 0.411^2 + 0.921^2 = 1.017,\]</span>
which is the same total variance as found from the empty random intercepts model above, indicating that adding the (fixed effect) intercept does not alter the total variance seen. This means that the VPC is also the same as in the empty RI model.</p>
<p>As with the other types of modelling covered in this module, covariates can also be included in a random intercepts model. To see which (continuous) covariates might have a relationship with GCSE score, the <code>pairs()</code> function can be used with the dataset as an argument to produce a matrix of scatter plots.</p>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb514-1" tabindex="-1"></a><span class="co">#produce pairs plot for exam data</span></span>
<span id="cb514-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb514-2" tabindex="-1"></a><span class="fu">pairs</span>(exam)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/pairs%20exam-1.png" width="672" /></p>
<p>The resulting scatter plots indicate that there may be a strong relationship between the GCSE score and LRT score of the pupils, so this covariate will be added to the random intercepts model, resulting in the following model.</p>
<p><span class="math display">\[ \text{GCSE}_{ij} = \beta_0 + \beta_1\text{LRT}_{ij} + u_j + e_{ij},\]</span>
where the mean of GCSE is allowed to vary across schools after adjusting by LRT in addition to the assumption that the effect for LRT is the same for all schools. Given that this is a random intercept model and there is no random slope component, this model creates parallel cluster-specific (school-specific) lines which have different intercepts. To fit this model in <code>R</code>, the <code>lme</code> function can be used again but with the addition of a fixed effect term for LRT.</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb515-1" tabindex="-1"></a><span class="co">#fit the random intercept model to the exam data with a covariate for LRTscore</span></span>
<span id="cb515-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb515-2" tabindex="-1"></a>exam_2lvlMRI1 <span class="ot">&lt;-</span> <span class="fu">lme</span>(GCSEscore <span class="sc">~</span> LRTscore, <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span><span class="sc">|</span>SchoolID, <span class="at">method =</span> <span class="st">&#39;ML&#39;</span>,</span>
<span id="cb515-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb515-3" tabindex="-1"></a>                <span class="at">data =</span> exam)</span>
<span id="cb515-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb515-4" tabindex="-1"></a><span class="fu">summary</span>(exam_2lvlMRI1)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: exam 
##        AIC      BIC    logLik
##   9365.243 9390.478 -4678.622
## 
## Random effects:
##  Formula: ~1 | SchoolID
##         (Intercept)  Residual
## StdDev:    0.303528 0.7521509
## 
## Fixed effects:  GCSEscore ~ LRTscore 
##                 Value  Std.Error   DF  t-value p-value
## (Intercept) 0.0023908 0.04003256 3993  0.05972  0.9524
## LRTscore    0.5633712 0.01246847 3993 45.18365  0.0000
##  Correlation: 
##          (Intr)
## LRTscore 0.008 
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -3.71622343 -0.63042350  0.02866066  0.68442610  3.26797827 
## 
## Number of Observations: 4059
## Number of Groups: 65</code></pre>
<p>The summary output for this model contains the same information as for the empty random intercepts model, with the addition of coefficient and correlation information for the LRT covariate. The coefficient estimate indicates that for a pupil with an average LRT score, the estimated overall mean of standardised GCSE score is 0.002, but for each unit increase in the LRT score, the expected standardised GCSE score of a pupil will increase by 0.563.</p>
<p>Looking at the variance for this model, the within-group (within-school) variance has reduced meaning that the heterogeneity (difference) in the reading abilities of the pupils explains some of the heterogeneity in the GCSE scores. The between-group variance is also reduced, leading to the total variance reducing to <span class="math inline">\(\hat{\sigma}^2_u+\hat{\sigma}^2_e = 0.304^2+0.752^2 = 0.658\)</span>.</p>
<p>The updated VPC is also reduced slightly, computed as</p>
<p><span class="math display">\[ \text{VPC} =\frac{\sigma^2_u}{\sigma^2_u+\sigma^2_e} = \frac{0.304^2}{0.658} = 0.140,\]</span>
meaning that 14% of the total variability observed in the GCSE scores can be attributed to the variability between schools, once controlled by the London Reading Test scores.</p>
<p>The model fit information for this model indicates that it is a better fit than the empty random intercept model, with lower AIC and BIC values. In addition, the variance for both the random effects and random error are smaller due to the addition of a covariate which aids in explaining some of the variability seen in the data.</p>
<p>To demonstrate how the school level impacts the intercept of the model, a random selection of schools can be taken and the corresponding lines of best fit can be plotted. To do this, predicted values need to be computed, where from the model above, two types of predicted values can be computed:</p>
<ul>
<li>Population average predicted values: (unconditional inference) beneficial for making predictions for groups not included in the available data since only the coefficient estimates for the fixed part of the model are used.</li>
<li>Group-specific predicted values: (conditional inference) beneficial for making predictions for groups included in the available data since the coefficient estimates for both the fixed and random parts of the model are used.</li>
</ul>
<p>To obtain these predicted values, the <code>fitted()</code> function can be used in a similar way to the <code>predict()</code> function introduced earlier in this module, however, instead of including a new dataset in the function, a level argument is included, where <code>level = 0</code> computes the population average predicted values and <code>level = 1</code> computes the group-specific predicted values.</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb517-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-1" tabindex="-1"></a><span class="fu">attach</span>(exam)</span>
<span id="cb517-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-2" tabindex="-1"></a><span class="co">#identify the unique schools and record their types</span></span>
<span id="cb517-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-3" tabindex="-1"></a>unique_school <span class="ot">&lt;-</span> <span class="fu">unique</span>(exam[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">6</span>)])</span>
<span id="cb517-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-4" tabindex="-1"></a><span class="co">#sample 6 of the schools</span></span>
<span id="cb517-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb517-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-6" tabindex="-1"></a>sampled_school <span class="ot">&lt;-</span> <span class="fu">sample</span>(unique_school<span class="sc">$</span>SchoolID, <span class="dv">6</span>)</span>
<span id="cb517-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-7" tabindex="-1"></a></span>
<span id="cb517-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-8" tabindex="-1"></a><span class="co">#school-specific predicted values from model with covariate for LRTscore</span></span>
<span id="cb517-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-9" tabindex="-1"></a>fitted1 <span class="ot">&lt;-</span> <span class="fu">fitted</span>(exam_2lvlMRI1, <span class="at">level=</span><span class="dv">1</span>)</span>
<span id="cb517-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-10" tabindex="-1"></a></span>
<span id="cb517-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-11" tabindex="-1"></a><span class="co">#subset original data for the 6 sampled schools</span></span>
<span id="cb517-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-12" tabindex="-1"></a>subset_school <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(exam[SchoolID <span class="sc">%in%</span> sampled_school, ],</span>
<span id="cb517-13"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-13" tabindex="-1"></a>                            <span class="at">fit1 =</span> fitted1[SchoolID <span class="sc">%in%</span> sampled_school])</span>
<span id="cb517-14"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-14" tabindex="-1"></a></span>
<span id="cb517-15"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-15" tabindex="-1"></a><span class="co">#plot the GCSE and LRT scores for the sampled schools with lines of best fit</span></span>
<span id="cb517-16"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-16" tabindex="-1"></a><span class="fu">plot</span>(subset_school<span class="sc">$</span>LRTscore, subset_school<span class="sc">$</span>GCSEscore, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="fl">0.2</span>,</span>
<span id="cb517-17"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-17" tabindex="-1"></a>     <span class="at">col=</span><span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(sampled_school)), <span class="at">xlab =</span> <span class="st">&quot;LRT score&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;GCSE&quot;</span>)</span>
<span id="cb517-18"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-18" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(sampled_school)){</span>
<span id="cb517-19"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-19" tabindex="-1"></a>  <span class="fu">lines</span>(subset_school<span class="sc">$</span>LRTscore[subset_school<span class="sc">$</span>SchoolID <span class="sc">==</span> sampled_school[i]],</span>
<span id="cb517-20"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-20" tabindex="-1"></a>        subset_school<span class="sc">$</span>fit1[subset_school<span class="sc">$</span>SchoolID <span class="sc">==</span> sampled_school[i]], </span>
<span id="cb517-21"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-21" tabindex="-1"></a>        <span class="at">col =</span> i, <span class="at">lty =</span> <span class="dv">1</span>)</span>
<span id="cb517-22"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-22" tabindex="-1"></a>}</span>
<span id="cb517-23"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-23" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">table</span>(exam<span class="sc">$</span>SchoolID) <span class="co">#sizes by school</span></span>
<span id="cb517-24"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-24" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>,<span class="at">legend=</span><span class="fu">paste</span>(sampled_school, <span class="st">&quot;(&quot;</span>,n[sampled_school], <span class="st">&quot;)&quot;</span>) ,</span>
<span id="cb517-25"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb517-25" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(sampled_school)), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="fl">0.7</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/exam%20plot%20random%20schools-1.png" width="672" /></p>
<p>The plot provides the school-specific predicted values for 6 randomly selected schools, where it can be seen that the higher the LRT score, the higher the GCSE score for all of the schools, where the slope of each school-specific line is the same. However, the intercept for each school varies due to the random intercept included in the model, where on average, the school with ID number 1 has the highest GCSE scores, and the school with ID number 23 has the lowest GCSE scores.</p>
</div>
<div id="random-slope-mixed-effects-modelling" class="section level3 hasAnchor" number="4.9.5">
<h3><span class="header-section-number">4.9.5</span> Random slope mixed-effects modelling<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#random-slope-mixed-effects-modelling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Random slope (and intercepts) mixed-effects modelling is an extension of random intercepts modelling that also allows for the relationship between the dependent and independent variables to differ for each group, meaning that not only can the intercept differ by group, but so can the slope. This difference is accounted for through an additional random effect for the slope which acts as an interaction between the group and the independent variable <span class="math inline">\(X\)</span>, leading to lines which are not parallel as in the random intercepts modelling. The general notation for the (2-level) model is as follows.</p>
<p><span class="math display">\[ y_{ij} = \beta_0 + \beta_1x_{ij} + u_{0j} + u_{1j}x_{ij} + e_{ij}, \]</span>
where <span class="math inline">\(i\)</span> is the index for level <span class="math inline">\(1\)</span>, <span class="math inline">\(j\)</span> is the index for level <span class="math inline">\(2\)</span> and</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>: overall intercept (fixed effect)</li>
<li><span class="math inline">\(\beta_1\)</span>: overall slope (fixed effect)</li>
<li><span class="math inline">\(u_{0j}\)</span>: group level intercept (random effect)
<ul>
<li>Normally distributed: <span class="math inline">\(u_{0j} \sim N(0, \sigma^2_{u0})\)</span> where <span class="math inline">\(\sigma^2_u\)</span> is the between-groups variance</li>
<li>Independence (across groups): <span class="math inline">\(\text{cov}(u_{0j}, u_{0jk})=0\)</span></li>
</ul></li>
<li><span class="math inline">\(u_{1j}\)</span> group level slope (random effect)
<ul>
<li>Normally distributed: <span class="math inline">\(u_{1j} \sim N(0, \sigma^2_{u1})\)</span></li>
<li>Independence (across groups): <span class="math inline">\(\text{cov}(u_{1j}, u_{1jk})=0\)</span></li>
</ul></li>
<li><span class="math inline">\(e_{ij}\)</span>: individual level error (random error)
<ul>
<li>Normally distributed: <span class="math inline">\(e_{ij} \sim N(0, \sigma^2_e)\)</span> where <span class="math inline">\(\sigma^2_e\)</span> is the within-groups variance</li>
<li>Independence: <span class="math inline">\(\text{cov}(e_{ij}, e_{kj})=\text{cov}(e_{ij}, u_{0j})=\text{cov}(e_{ij}, u_{1j})=0\)</span></li>
</ul></li>
</ul>
<p>It is also assumed that the random intercept and random slope are dependent within a group, <span class="math inline">\(\text{cov}(u_{0j}, u_{1j})=\sigma_{u01}\)</span>. Additionally, the inclusion of the random slope means that there is heterogeneous variance, meaning that the variance is not constant as it is in the random intercepts modelling (variance in random slopes modelling is a quadratic function of x).</p>
<p>Using the <code>exam</code> dataset, the 2-level random slopes model can be fitted to explore the GCSE scores of pupils by different schools, controlling for the LRT score of the pupils and allowing for the relationship between GCSE score and LRT score to differ by school, with the model taking the following form.</p>
<p><span class="math display">\[ GCSE_{ij} = \beta_0 + \beta_1 \times LRTscore_{ij} + u_{0j} + u_{1j}\times LRTscore_{ij} + e_{ij},\]</span></p>
<p>which can be rewritten as</p>
<p><span class="math display">\[GCSE_{ij} = \beta_{0ij} + \beta_{1j}\times LRTscore_{ij},\]</span>
where <span class="math inline">\(\beta_{0ij}=\beta_0 + u_{0j}+e_{ij}\)</span> and <span class="math inline">\(\beta_{1j}=\beta_1+u_{1j}\)</span>.</p>
<p>To incorporate this random slope into the model in <code>R</code>, the random slope term can be included in the <code>random</code> argument in the <code>lme()</code> function after the random intercept term. This is seen in the <code>R</code> code as follows.</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb518-1" tabindex="-1"></a><span class="co">#fit the random slope mixed model to the exam dataset</span></span>
<span id="cb518-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb518-2" tabindex="-1"></a>exam_2lvlMRS <span class="ot">&lt;-</span> <span class="fu">lme</span>(GCSEscore <span class="sc">~</span> LRTscore, <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> LRTscore <span class="sc">|</span> SchoolID,</span>
<span id="cb518-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb518-3" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">&#39;ML&#39;</span>, <span class="at">data =</span> exam)</span>
<span id="cb518-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb518-4" tabindex="-1"></a><span class="fu">summary</span>(exam_2lvlMRS)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: exam 
##        AIC      BIC    logLik
##   9328.871 9366.723 -4658.435
## 
## Random effects:
##  Formula: ~1 + LRTscore | SchoolID
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr  
## (Intercept) 0.3007321 (Intr)
## LRTscore    0.1205728 0.497 
## Residual    0.7440807       
## 
## Fixed effects:  GCSEscore ~ LRTscore 
##                  Value  Std.Error   DF   t-value p-value
## (Intercept) -0.0115037 0.03979185 3993 -0.289097  0.7725
## LRTscore     0.5567295 0.01994265 3993 27.916526  0.0000
##  Correlation: 
##          (Intr)
## LRTscore 0.365 
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -3.83128151 -0.63248819  0.03403727  0.68320736  3.45615474 
## 
## Number of Observations: 4059
## Number of Groups: 65</code></pre>
<p>Population average (or unconditional) inference can be done simply through interpreting the results from the summary output. For example, over the whole population of the schools, if a pupil has an average LRT score (LRT score = 0), the pupil is expected to get a GCSE score of <span class="math inline">\(-0.012\)</span>. Additionally, over the whole population of the schools, for each unit increase in the LRT score, the expected GCSE score of a pupil increases by 0.557.</p>
<p>To test if the additional random slope parameter is significant, a likelihood ratio test can be conducted, computing the log-likelihood values with the function <code>logLik()</code> and using the function <code>pchisq()</code> to find the corresponding <span class="math inline">\(p\)</span>-value.</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb520-1" tabindex="-1"></a><span class="co">#compute lambda</span></span>
<span id="cb520-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb520-2" tabindex="-1"></a>llmod1 <span class="ot">&lt;-</span> <span class="fu">logLik</span>(exam_2lvlMRI1)</span>
<span id="cb520-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb520-3" tabindex="-1"></a>llmod2 <span class="ot">&lt;-</span> <span class="fu">logLik</span>(exam_2lvlMRS)</span>
<span id="cb520-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb520-4" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>(llmod1 <span class="sc">-</span> llmod2)</span>
<span id="cb520-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb520-5" tabindex="-1"></a></span>
<span id="cb520-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb520-6" tabindex="-1"></a><span class="co">#compute the corresponding p-value (df = 2 because of the additional terms)</span></span>
<span id="cb520-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb520-7" tabindex="-1"></a><span class="fu">pchisq</span>(lambda[<span class="dv">1</span>], <span class="at">df =</span> <span class="dv">2</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 1.711123e-09</code></pre>
<p>The resulting <span class="math inline">\(p\)</span>-value is approximately zero, meaning that it is much smaller than the 5% significance level, indicating that the additional term for the random slope is highly significant. The interpretation of this result is that there is evidence that the effect that the LRT scores have on GCSE scores varies across the schools.</p>
<p>Alternatively, an ANOVA table can be used to test the significance as follows.</p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb522-1" tabindex="-1"></a><span class="co">#anova of two models</span></span>
<span id="cb522-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb522-2" tabindex="-1"></a><span class="fu">anova</span>(exam_2lvlMRI1, exam_2lvlMRS)</span></code></pre></div>
<pre><code>##               Model df      AIC      BIC    logLik   Test  L.Ratio p-value
## exam_2lvlMRI1     1  4 9365.243 9390.478 -4678.622                        
## exam_2lvlMRS      2  6 9328.871 9366.723 -4658.435 1 vs 2 40.37223  &lt;.0001</code></pre>
<p>Where the results from the ANOVA table also indicate that the addition of the random slope is significant.</p>
<p>Given the additional terms involved with random slopes modelling, the VPC formula changes, with the resulting formula as follows.</p>
<p><span class="math display">\[ \text{VPC}(x) = \frac{\text{Level 2 variance}}{\text{Total variance}} = \frac{\text{Var}(u_{0j}+u_{1j}x_{ij})}{\text{Var}(u_{0j}+u_{1j}x_{ij}+e_{ij})}=\frac{\sigma^2_{u0}+2x_{ij}\sigma_{u01}+x_{ij}^2\sigma^2_{u1}}{\sigma^2_{u0}+2x_{ij}\sigma_{u01}+x_{ij}^2\sigma^2_{u1}+\sigma^2_e}, \]</span>
where each of the variance and covariance terms can be found from reading the summary output of the model in the random effects part. The VPC is also dependent on the value of <span class="math inline">\(x\)</span> and a quadratic function of <span class="math inline">\(x\)</span>, unlike with the random intercepts models where the VPC is independent of <span class="math inline">\(x\)</span> so is constant across the different values of <span class="math inline">\(x\)</span>.</p>
<div class="figure" style="text-align: center">
<img src="figures/4_images/RSoutput.png" alt="Interpreting the summary output" width="80%" />
<p class="caption">
(#fig:lme RS summary)Interpreting the summary output
</p>
</div>
<p><span class="math display">\[\text{VPC(LRTscore)} = \frac{\sigma^2_{u0}+2x\sigma_{u01}+x^2\sigma^2_{u1}}{\sigma^2_{u0}+2x\sigma_{u01}+x^2\sigma^2_{u1}+\sigma^2_e} = \frac{0.301^2 + 2\times \text{LRTscore}_{ij} \times 0.497 + \text{LRTscore}_{ij}^2 \times 0.121^2}{0.301^2 + 2\times \text{LRTscore}_{ij} \times 0.497 + \text{LRTscore}_{ij}^2 \times 0.121^2 + 0.744^2},\]</span>
which is dependent on the LRT score.</p>
<p>As with the random intercepts mixed-effects model, the results from the random slopes mixed-effects model can be plotted to visually demonstrate the effect that the additional terms have on the models. This is done in the same way as before, through randomly sampling a selection of schools, computing the conditional predicted values with the <code>fitted()</code> function and plotting the results with a line of best fit for each of the sampled schools.</p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-1" tabindex="-1"></a><span class="co">#identify the unique schools and record their types</span></span>
<span id="cb524-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-2" tabindex="-1"></a>unique_school <span class="ot">&lt;-</span> <span class="fu">unique</span>(exam[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">6</span>)])</span>
<span id="cb524-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-3" tabindex="-1"></a><span class="co">#sample 6 of the schools</span></span>
<span id="cb524-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb524-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-5" tabindex="-1"></a>sampled_school <span class="ot">&lt;-</span> <span class="fu">sample</span>(unique_school<span class="sc">$</span>SchoolID, <span class="dv">6</span>)</span>
<span id="cb524-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-6" tabindex="-1"></a></span>
<span id="cb524-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-7" tabindex="-1"></a><span class="co">#school-specific predicted values from model with covariate for LRTscore</span></span>
<span id="cb524-8"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-8" tabindex="-1"></a>fitted2 <span class="ot">&lt;-</span> <span class="fu">fitted</span>(exam_2lvlMRS, <span class="at">level =</span> <span class="dv">1</span>)</span>
<span id="cb524-9"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-9" tabindex="-1"></a></span>
<span id="cb524-10"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-10" tabindex="-1"></a><span class="co">#subset original data for the 6 sampled schools</span></span>
<span id="cb524-11"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-11" tabindex="-1"></a>subset_school2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(exam[SchoolID <span class="sc">%in%</span> sampled_school,],</span>
<span id="cb524-12"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-12" tabindex="-1"></a>                            <span class="at">fit2 =</span> fitted2[SchoolID <span class="sc">%in%</span> sampled_school])</span>
<span id="cb524-13"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-13" tabindex="-1"></a></span>
<span id="cb524-14"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-14" tabindex="-1"></a><span class="co">#plot the GCSE and LRT scores for the sampled schools with lines of best fit</span></span>
<span id="cb524-15"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-15" tabindex="-1"></a><span class="fu">plot</span>(subset_school2<span class="sc">$</span>LRTscore, subset_school2<span class="sc">$</span>GCSEscore, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="fl">0.2</span>,</span>
<span id="cb524-16"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-16" tabindex="-1"></a>     <span class="at">col=</span><span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(sampled_school)), <span class="at">xlab =</span> <span class="st">&quot;LRT score&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;GCSE&quot;</span>)</span>
<span id="cb524-17"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-17" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(sampled_school)){</span>
<span id="cb524-18"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-18" tabindex="-1"></a>  <span class="fu">lines</span>(subset_school2<span class="sc">$</span>LRTscore[subset_school2<span class="sc">$</span>SchoolID <span class="sc">==</span> sampled_school[i]],</span>
<span id="cb524-19"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-19" tabindex="-1"></a>        subset_school2<span class="sc">$</span>fit2[subset_school2<span class="sc">$</span>SchoolID <span class="sc">==</span> sampled_school[i]], </span>
<span id="cb524-20"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-20" tabindex="-1"></a>        <span class="at">col =</span> i, <span class="at">lty =</span> <span class="dv">1</span>)</span>
<span id="cb524-21"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-21" tabindex="-1"></a>}</span>
<span id="cb524-22"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-22" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">table</span>(exam<span class="sc">$</span>SchoolID) <span class="co">#sizes by school</span></span>
<span id="cb524-23"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-23" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span><span class="fu">paste</span>(sampled_school, <span class="st">&quot;(&quot;</span>,n[sampled_school], <span class="st">&quot;)&quot;</span>) ,</span>
<span id="cb524-24"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb524-24" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(sampled_school)), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="fl">0.7</span>)</span></code></pre></div>
<p><img src="WorldPop_Training_Manual_files/figure-html/exam%20plot%20random%20schools%20RS-1.png" width="672" /></p>
<p>The plot provides the school-specific predicted values for 6 randomly selected schools, where the same trend between LRT score and GSCE score is seen as before (the higher the LRT score the higher the GCSE score), however, the effect that LRT score has on GCSE score changes depending on the school. For example, the slope for the school with ID number 1 has a steeper slope than that of the school with ID number 23, indicating that for school 1, a higher LRT score has more of an impact on the pupil’s GCSE score than for school 23.</p>
</div>
<div id="adding-an-extra-level" class="section level3 hasAnchor" number="4.9.6">
<h3><span class="header-section-number">4.9.6</span> Adding an extra level<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#adding-an-extra-level" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When there are only 2 levels in a model, it is assumed that the level 2 groups are independent of each other. However, this is not always the case, and this is where it is important to add a level 3 group. When there are three levels, <span class="math inline">\(i\)</span> corresponds to level 1, <span class="math inline">\(j\)</span> corresponds to level 2 and <span class="math inline">\(k\)</span> corresponds to level 3. There are two cases for random structure in 3-level models which are important to distinguish between given that they are specified differently in the <code>lme()</code> function in <code>R</code>.</p>
<p><strong>Case 1:</strong> The first case for the 3-level mixed-effects model form is that where the models at all 3 of the levels are equal. This can mean that there are either only random intercepts at each level or there are random intercepts and random slopes at each level.
The general form of the 3-level random intercepts mixed-effects model where there are only random intercepts at each level is given as follows.</p>
<p><span class="math display">\[y_{ijk} = \beta_0 + \beta_1x_{ijk} + v_{0k} + u_{0jk} + e_{0ijk}, \]</span>
which can be rewritten as</p>
<p><span class="math display">\[ y_{ijk} = \beta_{0ijk} + \beta_{1}x_{ijk},\]</span>
where <span class="math inline">\(\beta_{0ijk} = \beta_0 + v_{0k} + u_{0jk} + e_{ijk}\)</span>. Then, the general form of the 3-level random slopes mixed-effects model where there are random intercepts and random slopes at each level is given as follows.</p>
<p><span class="math display">\[y_{ijk} = \beta_0 + \beta_1x_{ijk} + v_{0k}+ v_{1k}x_{ijk} + u_{0jk} + u_{1jk}x_{ijk} + e_{0ijk}, \]</span>
which can be rewritten as</p>
<p><span class="math display">\[ y_{ijk} = \beta_{0ijk} + \beta_{1jk}x_{ijk},\]</span></p>
<p>where <span class="math inline">\(\beta_{0ijk} = \beta_0 + v_{0k} + u_{0jk} + e_{ijk}\)</span> and <span class="math inline">\(\beta_{1jk} = \beta_1 + v_{1k} + u_{1jk}\)</span>.</p>
<p><strong>Case 2:</strong> The second case for the 3-level mixed-effects model form is when the models at some levels are different, for example, if only the second level has a random slope, but all levels have a random intercept. The general form of this model is given as follows.</p>
<p><span class="math display">\[y_{ijk} = \beta_0 + \beta_1x_{ijk} + v_{0k} + u_{0jk} + u_{1jk}x_{ijk} + e_{0ijk}, \]</span>
which can be rewritten as</p>
<p><span class="math display">\[ y_{ijk} = \beta_{0ijk} + \beta_{1jk}x_{ijk},\]</span>
where <span class="math inline">\(\beta_{0ijk} = \beta_0 + v_{0k} + u_{0jk} + e_{ijk}\)</span> and <span class="math inline">\(\beta_{1jk} = \beta_1 + u_{1jk}\)</span>.</p>
<p>When using the <code>lme()</code> function in <code>R</code>, the random structure in the first case is specified as <code>random = ~ () | level3/level2</code>, compared to the second case where the random structure is specified as <code>random = list(~ | ~ | ~ |)</code>. These differences are explored in this section with application to the <code>exam</code> dataset example, where pupils are nested within schools, and schools can be grouped by district, and schools within the same district share common characteristics. The indices of each level are then given as pupil <span class="math inline">\(i\)</span> is nested in school <span class="math inline">\(j\)</span> which is nested in district <span class="math inline">\(k\)</span>.</p>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb525-1" tabindex="-1"></a><span class="co">#add district level to the exam data</span></span>
<span id="cb525-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb525-2" tabindex="-1"></a>district <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="fu">paste0</span>(data_path, <span class="st">&#39;exam_district.csv&#39;</span>), <span class="at">header =</span> <span class="cn">FALSE</span>)</span>
<span id="cb525-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb525-3" tabindex="-1"></a><span class="fu">colnames</span>(district) <span class="ot">&lt;-</span> <span class="st">&quot;district&quot;</span></span>
<span id="cb525-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb525-4" tabindex="-1"></a>exam[, <span class="dv">7</span>] <span class="ot">&lt;-</span> district</span></code></pre></div>
<p><strong>Case 1:</strong> The 3-level mixed-effects model with random intercepts only is given as follows.
<span class="math display">\[GCSE_{ijk} =( \beta_0 +  v_{0k} + u_{0jk} ) + \beta_1 LRTscore_{ijk} + e_{0ijk},\]</span></p>
<p>which is fitted in <code>R</code> using the <code>lme()</code> function in the following code.</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb526-1" tabindex="-1"></a><span class="co">#fit the 3-level random intercepts only model</span></span>
<span id="cb526-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb526-2" tabindex="-1"></a>exam_3lvlMRI <span class="ot">&lt;-</span> <span class="fu">lme</span>(GCSEscore <span class="sc">~</span> LRTscore, </span>
<span id="cb526-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb526-3" tabindex="-1"></a>                   <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span><span class="sc">|</span>district<span class="sc">/</span>SchoolID, </span>
<span id="cb526-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb526-4" tabindex="-1"></a>                   <span class="at">method =</span> <span class="st">&#39;ML&#39;</span>, <span class="at">data =</span> exam)</span>
<span id="cb526-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb526-5" tabindex="-1"></a><span class="fu">summary</span>(exam_3lvlMRI)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: exam 
##        AIC     BIC    logLik
##   9418.347 9449.89 -4704.174
## 
## Random effects:
##  Formula: ~1 | district
##         (Intercept)
## StdDev:  0.05137938
## 
##  Formula: ~1 | SchoolID %in% district
##         (Intercept)  Residual
## StdDev:    0.276128 0.7530999
## 
## Fixed effects:  GCSEscore ~ LRTscore 
##                  Value  Std.Error   DF  t-value p-value
## (Intercept) -0.0168807 0.03176277 3934 -0.53146  0.5951
## LRTscore     0.5660127 0.01249837 3934 45.28692  0.0000
##  Correlation: 
##          (Intr)
## LRTscore 0.011 
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -3.73839940 -0.63848886  0.02900113  0.67849607  3.28534013 
## 
## Number of Observations: 4059
## Number of Groups: 
##               district SchoolID %in% district 
##                     20                    124</code></pre>
<p>The 3-level mixed-effects model with random intercepts and random slopes at each level is given as follows.
<span class="math display">\[GCSE_{ijk} = (\beta_0  + v_{0k} + u_{0jk})+ (\beta_1 + v_{1k}  + u_{1jk})LRTscore_{ijk} + e_{0ijk},\]</span></p>
<p>which is fitted in <code>R</code> using the <code>lme()</code> function in the following code.</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb528-1" tabindex="-1"></a><span class="co">#fit the 3-level random intercepts only model</span></span>
<span id="cb528-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb528-2" tabindex="-1"></a>exam_3lvlMRS <span class="ot">&lt;-</span> <span class="fu">lme</span>(GCSEscore <span class="sc">~</span> LRTscore, </span>
<span id="cb528-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb528-3" tabindex="-1"></a>                   <span class="at">random =</span> <span class="sc">~</span> (<span class="dv">1</span> <span class="sc">+</span> LRTscore) <span class="sc">|</span> district<span class="sc">/</span>SchoolID,</span>
<span id="cb528-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb528-4" tabindex="-1"></a>                   <span class="at">data =</span> exam, <span class="at">method =</span> <span class="st">&#39;ML&#39;</span>,</span>
<span id="cb528-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb528-5" tabindex="-1"></a>                   <span class="at">control =</span> <span class="fu">lmeControl</span>(<span class="at">opt =</span> <span class="st">&quot;optim&quot;</span>)) </span>
<span id="cb528-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb528-6" tabindex="-1"></a></span>
<span id="cb528-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb528-7" tabindex="-1"></a><span class="fu">summary</span>(exam_3lvlMRS)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: exam 
##        AIC      BIC    logLik
##   9390.575 9447.353 -4686.287
## 
## Random effects:
##  Formula: ~(1 + LRTscore) | district
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev     Corr  
## (Intercept) 0.03629237 (Intr)
## LRTscore    0.02284358 0.284 
## 
##  Formula: ~(1 + LRTscore) | SchoolID %in% district
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr  
## (Intercept) 0.2755233 (Intr)
## LRTscore    0.1141072 0.465 
## Residual    0.7449016       
## 
## Fixed effects:  GCSEscore ~ LRTscore 
##                  Value  Std.Error   DF   t-value p-value
## (Intercept) -0.0247791 0.03045501 3934 -0.813631  0.4159
## LRTscore     0.5621427 0.01795309 3934 31.311754  0.0000
##  Correlation: 
##          (Intr)
## LRTscore 0.282 
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -3.86834331 -0.62985398  0.03307898  0.67616436  3.46720448 
## 
## Number of Observations: 4059
## Number of Groups: 
##               district SchoolID %in% district 
##                     20                    124</code></pre>
<p><strong>Case 2:</strong> The 3-level mixed-effects model with random intercepts for all levels and a random slope for level 2 is given as follows.
<span class="math display">\[GCSE_{ijk} = (\beta_0 + v_{0k} + u_{0jk}) + (\beta_1 + u_{1jk}) LRTscore_{ijk} + e_{0ijk},\]</span></p>
<p>which is fitted in <code>R</code> using the <code>lme()</code> function in the following code.</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb530-1" tabindex="-1"></a><span class="co">#fit the 3-level random intercepts only model</span></span>
<span id="cb530-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb530-2" tabindex="-1"></a>exam_3lvlMRIS <span class="ot">&lt;-</span> <span class="fu">lme</span>(GCSEscore <span class="sc">~</span> LRTscore, </span>
<span id="cb530-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb530-3" tabindex="-1"></a>                   <span class="at">random =</span> <span class="fu">list</span>( <span class="sc">~</span> <span class="dv">1</span><span class="sc">|</span>district, <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> LRTscore<span class="sc">|</span>SchoolID), </span>
<span id="cb530-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb530-4" tabindex="-1"></a>                   <span class="at">method =</span> <span class="st">&#39;ML&#39;</span>, <span class="at">data =</span> exam,                   </span>
<span id="cb530-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb530-5" tabindex="-1"></a>                   <span class="at">control =</span> <span class="fu">lmeControl</span>(<span class="at">opt =</span> <span class="st">&quot;optim&quot;</span>)) </span>
<span id="cb530-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb530-6" tabindex="-1"></a></span>
<span id="cb530-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb530-7" tabindex="-1"></a><span class="fu">summary</span>(exam_3lvlMRIS)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: exam 
##        AIC      BIC    logLik
##   9386.671 9430.832 -4686.336
## 
## Random effects:
##  Formula: ~1 | district
##         (Intercept)
## StdDev:  0.01850324
## 
##  Formula: ~1 + LRTscore | SchoolID %in% district
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr  
## (Intercept) 0.2773087 (Intr)
## LRTscore    0.1170200 0.466 
## Residual    0.7448742       
## 
## Fixed effects:  GCSEscore ~ LRTscore 
##                  Value  Std.Error   DF  t-value p-value
## (Intercept) -0.0249776 0.02955805 3934 -0.84504  0.3981
## LRTscore     0.5612958 0.01718500 3934 32.66196  0.0000
##  Correlation: 
##          (Intr)
## LRTscore 0.282 
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -3.8691875 -0.6306811  0.0325292  0.6732546  3.4644060 
## 
## Number of Observations: 4059
## Number of Groups: 
##               district SchoolID %in% district 
##                     20                    124</code></pre>
<p>As with the other modelling approaches, the a likelihood ratio test can be used to check the significance, in this case of the 3rd level by comparing the 2-level random slopes model created above with the 3-level model with random intercepts at each level and a random slope at the school level.</p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb532-1" tabindex="-1"></a><span class="co">#compute lambda</span></span>
<span id="cb532-2"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb532-2" tabindex="-1"></a>llmod1 <span class="ot">&lt;-</span> <span class="fu">logLik</span>(exam_2lvlMRS)</span>
<span id="cb532-3"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb532-3" tabindex="-1"></a>llmod2 <span class="ot">&lt;-</span> <span class="fu">logLik</span>(exam_3lvlMRIS)</span>
<span id="cb532-4"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb532-4" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>(llmod1<span class="sc">-</span>llmod2)</span>
<span id="cb532-5"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb532-5" tabindex="-1"></a></span>
<span id="cb532-6"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb532-6" tabindex="-1"></a><span class="co">#compute the corresponding p-value (df = 1 because of the additional term)</span></span>
<span id="cb532-7"><a href="introduction-to-statistical-modelling-with-implementation-in-r.html#cb532-7" tabindex="-1"></a><span class="fu">pchisq</span>(lambda[<span class="dv">1</span>], <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Which indicates that the addition of the district as a 3rd level is not significant given that the resulting <span class="math inline">\(p\)</span>-value is not less than the 5% significance level.</p>
<!-- ## Cameroon application -->
<!-- ```{r cameroon example} -->
<!-- Data_CMR <- read.csv(paste0(data_path,"CMR/Pop_Data_Complete.csv")) -->
<!-- Data_CMR$Density = Data_CMR$Total_Pop/Data_CMR$Total_Building_Count -->
<!-- Data_CMR$LDensity = log(Data_CMR$Density) -->
<!-- Data_CMR$y = Data_CMR$LDensity -->
<!-- fit <- lm(Data_CMR$y ~ Data_CMR$x3, random = ~1, data = Data_CMR) -->
<!-- summary(fit) -->
<!-- ``` -->
<!-- The total variance is given as $\text{Var}(v_{0k} + u_{0jk} + e_{ijk}) = \sigma^2_{v0} + \sigma^2_{u0}+ \sigma^2_{e0}$ under the assumption of independence between $v$, $u$ and $e$, with correlation between two schools in the same district given as  -->
<!-- $$ \frac{\sigma^2_{v0}}{\sigma^2_{v0} + \sigma^2_{u0}+ \sigma^2_{e0}},$$ -->
<!-- and correlation between two pupils in the same school given as -->
<!-- $$\frac{\sigma^2_{v0} + \sigma^2_{u0}}{\sigma^2_{v0} + \sigma^2_{u0}+ \sigma^2_{e0}}.$$ -->
<!-- ## End of module exercises -->
</div>
</div>
<div id="useful-resources-3" class="section level2 hasAnchor" number="4.10">
<h2><span class="header-section-number">4.10</span> Useful resources<a href="introduction-to-statistical-modelling-with-implementation-in-r.html#useful-resources-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Statistical modelling: <a href="https://tjfisher19.github.io/introStatModeling/">Introduction to Statistical Modeling</a></li>
<li>Linear regression: <a href="https://www.datacamp.com/tutorial/simple-linear-regression">Simple Linear Regression: Everything You Need to Know</a></li>
<li>Polynomial regression: <a href="https://builtin.com/machine-learning/polynomial-regression">Polynomial Regression: An Introduction</a></li>
<li>Non-linear regression: <a href="https://www.geeksforgeeks.org/non-linear-regression-examples-ml/">GeeksforGeeks</a></li>
<li>Generalised linear regression: <a href="https://www.geeksforgeeks.org/generalized-linear-models/">GeeksforGeeks</a></li>
<li>Model predictions: <a href="https://www.dataquest.io/blog/statistical-learning-for-predictive-modeling-r/">Using Linear Regression for Predictive Modeling in R</a></li>
<li>Model selection: <a href="https://bookdown.org/animestina/intro_stats_rms/model-selection.html">Model Selection</a></li>
<li>Stepwise regression: <a href="https://www.r-bloggers.com/2023/12/a-complete-guide-to-stepwise-regression-in-r/">A Complete Guide to Stepwise Regression in R</a></li>
<li>Stepwise regression: <a href="https://www.geeksforgeeks.org/stepwise-regression-in-r/">GeeksforGeeks</a></li>
<li>Cross-validation:<a href="https://www.geeksforgeeks.org/cross-validation-in-r-programming/">GeeksforGeeks</a></li>
<li>Hierarchical regression: <a href="https://methodenlehre.github.io/intro-to-rstats/hierarchical-linear-models.html">Hierarchical Linear Models</a></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="working-with-spatial-data-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="probability-theory-and-applications.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
